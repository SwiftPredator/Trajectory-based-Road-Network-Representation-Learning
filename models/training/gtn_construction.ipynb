{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import GTNModel, GAEModel, Node2VecModel, GCNEncoder, Traj2Vec\n",
    "from evaluation.tasks import TravelTimeEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e94d91c2a1a4a548ef6dd07225ca349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceed593fcef4db1a0dab585d9bab56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c848d0c85b74ed9a57f524706a54d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0250e6d12548179cc1f4a46852b4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24730fc7115b47d7b80b737a455883ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/generator/road_network.py:188: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df[\"x\"] = df.geometry.centroid.x / 100  # normalize to -2/2\n",
      "/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/generator/road_network.py:189: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df[\"y\"] = df.geometry.centroid.y / 100  # normalize to -1/1\n"
     ]
    }
   ],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "trajectory = Trajectory(\"../../datasets/trajectories/Porto/road_segment_map_final.csv\", nrows=1000).generate_TTE_datatset()\n",
    "\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "data = network.generate_road_segment_pyg_dataset(traj_data=traj_features.copy(), drop_labels=[\"highway_enc\"])\n",
    "data2 = network.generate_road_segment_pyg_dataset(traj_data=traj_features.copy(), drop_labels=[\"highway_enc\"], include_coords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:04, 23826.95it/s]\n"
     ]
    }
   ],
   "source": [
    "m = Traj2Vec.map_traj_to_node_ids(trajectory[\"seg_seq\"].values, network, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2844. 2845. 2847. 1476. 1479. 1481. 1486. 1494. 1499. 1505.]\n"
     ]
    }
   ],
   "source": [
    "print(m[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False_no_selfloops_smoothed.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.83439517 0.00781896 0.15778587 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(adj[108, 130:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  6 16  9]\n",
      " [ 0  2  6 16  9]\n",
      " [ 0  2  6 16  9]\n",
      " ...\n",
      " [ 0  2  6 16  9]\n",
      " [ 0  2  6 16  9]\n",
      " [ 0  2  6 16  9]]\n"
     ]
    }
   ],
   "source": [
    "walks = Traj2Vec.traj_walk(adj, 5, 10000*[0], 10)\n",
    "print(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 108, 136,  78,  69,  74],\n",
       "       [100, 108, 136,  78,  69,  74],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  73],\n",
       "       [100, 108, 136,  78,  69,  76],\n",
       "       [100, 108, 138,  89,  68,  69],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  76],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  74],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  75],\n",
       "       [100, 108, 136,  78,  69,  74],\n",
       "       [100, 108, 136,  78,  69,  75]], dtype=uint32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from _walker import random_walks as _random_walks\n",
    "from scipy import sparse\n",
    "\n",
    "A = sparse.csr_matrix(adj)\n",
    "indptr = A.indptr.astype(np.uint32)\n",
    "indices = A.indices.astype(np.uint32)\n",
    "weights = A.data.astype(np.float32)\n",
    "\n",
    "_random_walks(indptr, indices, weights, [100,100,100], 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2Vec(\n",
    "            data,\n",
    "            network,\n",
    "            adj,\n",
    "            embedding_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_negative_samples=10,\n",
    "        ).to(device)\n",
    "loader = traj2vec.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(traj2vec.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, avg_loss: 2.1407772922783757\n",
      "Epoch: 10, avg_loss: 1.4511424391457204\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "for e in range(50):\n",
    "    traj2vec.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = traj2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss += total_loss / len(loader)\n",
    "    if e > 0 and e % 5 == 0:\n",
    "        print(\"Epoch: {}, avg_loss: {}\".format(e, avg_loss / e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = None\n",
    "data = T.OneHotDegree(128)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1544234/1544234 [11:21<00:00, 2267.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.gtn.GTNModel at 0x7f8dd1e89f40>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# precalc adj matrices\n",
    "GTNModel(data, device, network, trajectory, k=1, bidirectional=False, add_self_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\")\n",
    "model2 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "model3 = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\")\n",
    "model4 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "model5 = Node2VecModel(data, device=device, q=4, p=1)\n",
    "\n",
    "models.extend([(model, 5000), (model2, 5000), (model3, 5000), (model4, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_data.edge_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, avg_loss: 1.1346867181277005\n",
      "Epoch: 40, avg_loss: 0.9276655710647613\n",
      "Epoch: 1000, avg_loss: 1.0282853301167487\n",
      "Epoch: 2000, avg_loss: 1.0185488188266754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# for k in [1]:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m#     model.train(epochs=1000)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m \u001b[39m#     models.append(model)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m model3\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=9'>10</a>\u001b[0m model2\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal01/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#ch0000006vscode-remote?line=10'>11</a>\u001b[0m models\u001b[39m.\u001b[39mextend([model, model2, model3])\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/gtn.py:62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m self.optimizer.step()\n\u001b[1;32m     61\u001b[0m avg_loss += loss.item()\n\u001b[0;32m---> 62\u001b[0m \n\u001b[1;32m     63\u001b[0m if e > 0 and e % 1000 == 0:\n\u001b[1;32m     64\u001b[0m     print(\"Epoch: {}, avg_loss: {}\".format(e, avg_loss / e))\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/gtn.py:80\u001b[0m, in \u001b[0;36mrecon_loss\u001b[0;34m(self, z, pos_edge_index, neg_edge_index)\u001b[0m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m         return pos_loss + neg_loss\n\u001b[0;32m---> 80\u001b[0m \n\u001b[1;32m     81\u001b[0m     def transform_data(self, data, adj):\n\u001b[1;32m     82\u001b[0m         G = nx.from_numpy_array(adj.T, create_using=nx.DiGraph)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch_geometric/utils/negative_sampling.py:81\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m     79\u001b[0m idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):  \u001b[39m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     rnd \u001b[39m=\u001b[39m sample(population, sample_size, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misin(rnd, idx)\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m neg_idx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch_geometric/utils/negative_sampling.py:239\u001b[0m, in \u001b[0;36msample\u001b[0;34m(population, k, device)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39marange(population, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(random\u001b[39m.\u001b[39;49msample(\u001b[39mrange\u001b[39;49m(population), k), device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/random.py:470\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    468\u001b[0m             j \u001b[39m=\u001b[39m randbelow(n)\n\u001b[1;32m    469\u001b[0m         selected_add(j)\n\u001b[0;32m--> 470\u001b[0m         result[i] \u001b[39m=\u001b[39m population[j]\n\u001b[1;32m    471\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "models = []\n",
    "# for k in [1]:\n",
    "#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\n",
    "#     model.train(epochs=1000)\n",
    "#     models.append(model)\n",
    "\n",
    "model3.train(epochs=50)\n",
    "model.train(epochs=5000)\n",
    "model2.train(epochs=5000)\n",
    "models.extend([model, model2, model3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.model(model.train_data.x, model.train_data.edge_traj_index, model.train_data.edge_weight)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gtn/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load node2vec emb\n",
    "model5.load_model(\"../model_states/node2vec/model.pt\")\n",
    "z2 = model5.load_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.004720325767994\n",
      "Epoch: 2000, avg_loss: 1.0040359412431716\n",
      "Epoch: 3000, avg_loss: 1.0038682837287585\n",
      "Epoch: 4000, avg_loss: 1.0037380935698748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47076854460100853\n",
      "Epoch: 500, avg_loss: 1.1095781285762787\n",
      "Epoch: 1000, avg_loss: 1.084949031829834\n",
      "Epoch: 1500, avg_loss: 1.0755179046789805\n",
      "Epoch: 2000, avg_loss: 1.070435450911522\n",
      "Epoch: 2500, avg_loss: 1.0669233219146728\n",
      "Epoch: 3000, avg_loss: 1.064109513839086\n",
      "Epoch: 3500, avg_loss: 1.0617583968298776\n",
      "Epoch: 4000, avg_loss: 1.0598457372486592\n",
      "Epoch: 4500, avg_loss: 1.058286092042923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46090861267519745\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "for m, e in models:\n",
    "    m.train(epochs=e)\n",
    "    z = np.concatenate((m.load_emb(), z2), axis=1)\n",
    "    X = z # embedding for each node\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X_test, y=y_test, scoring=scorer, cv=5)))\n",
    "#print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.0043522388935089\n",
      "Epoch: 2000, avg_loss: 1.0037227797210218\n",
      "Epoch: 3000, avg_loss: 1.0034920635620752\n",
      "Epoch: 4000, avg_loss: 1.0033518871963023\n",
      "5.99349780632178\n",
      "Epoch: 500, avg_loss: 1.0476357510089875\n",
      "Epoch: 1000, avg_loss: 1.0465151098966599\n",
      "Epoch: 1500, avg_loss: 1.0461387006441751\n",
      "Epoch: 2000, avg_loss: 1.0458801525235175\n",
      "Epoch: 2500, avg_loss: 1.0457478744506836\n",
      "Epoch: 3000, avg_loss: 1.0456344858407973\n",
      "Epoch: 3500, avg_loss: 1.0455226311343058\n",
      "Epoch: 4000, avg_loss: 1.0454531234800815\n",
      "Epoch: 4500, avg_loss: 1.0453718082374996\n",
      "12.711964787733887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "for m, e in models:\n",
    "    m.train(epochs=e)\n",
    "    z = np.concatenate((m.load_emb(), z2), axis=1)\n",
    "    \n",
    "    decoder = linear_model.LinearRegression(fit_intercept=True)\n",
    "    X = z\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    decoder.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.mean_absolute_error)\n",
    "    print(np.mean(cross_val_score(estimator=decoder, X=X_test, y=y_test, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.045148916721344\n",
      "Epoch: 2000, avg_loss: 1.03021847063303\n",
      "Epoch: 3000, avg_loss: 1.0241406110127766\n",
      "Epoch: 4000, avg_loss: 1.0199422906637192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 50864.55742421875\n",
      "Average training loss in episode 1: 11063.43037890625\n",
      "Average training loss in episode 2: 10701.5946421875\n",
      "Average training loss in episode 3: 10436.82530234375\n",
      "Average training loss in episode 4: 10404.15393515625\n",
      "{'MSE': 10890.384121063082, 'MAE': 77.89907491512298}\n",
      "Epoch: 500, avg_loss: 1.1090960187911987\n",
      "Epoch: 1000, avg_loss: 1.084807618021965\n",
      "Epoch: 1500, avg_loss: 1.075443676551183\n",
      "Epoch: 2000, avg_loss: 1.0704160868525505\n",
      "Epoch: 2500, avg_loss: 1.066892796421051\n",
      "Epoch: 3000, avg_loss: 1.0641022146145502\n",
      "Epoch: 3500, avg_loss: 1.061758977310998\n",
      "Epoch: 4000, avg_loss: 1.0598157776892185\n",
      "Epoch: 4500, avg_loss: 1.0582583843072255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 54722.13613359375\n",
      "Average training loss in episode 1: 11236.265759375\n",
      "Average training loss in episode 2: 10853.59340703125\n",
      "Average training loss in episode 3: 10688.203209375\n",
      "Average training loss in episode 4: 10539.04138359375\n",
      "{'MSE': 10031.258017285565, 'MAE': 72.28723308506012}\n",
      "Epoch: 1000, avg_loss: 1.0441334484815596\n",
      "Epoch: 2000, avg_loss: 1.0296621508598327\n",
      "Epoch: 3000, avg_loss: 1.0237164240280787\n",
      "Epoch: 4000, avg_loss: 1.0195346966534853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 50588.34421953125\n",
      "Average training loss in episode 1: 10549.6311484375\n",
      "Average training loss in episode 2: 10186.04148515625\n",
      "Average training loss in episode 3: 10002.2188078125\n",
      "Average training loss in episode 4: 9819.9819453125\n",
      "{'MSE': 9690.250556952038, 'MAE': 69.61260110340119}\n",
      "Epoch: 500, avg_loss: 1.1103951952457427\n",
      "Epoch: 1000, avg_loss: 1.0852545927762984\n",
      "Epoch: 1500, avg_loss: 1.0757227824529012\n",
      "Epoch: 2000, avg_loss: 1.070557082772255\n",
      "Epoch: 2500, avg_loss: 1.0670235564231874\n",
      "Epoch: 3000, avg_loss: 1.0641985115210215\n",
      "Epoch: 3500, avg_loss: 1.0618425526959556\n",
      "Epoch: 4000, avg_loss: 1.0599095394313336\n",
      "Epoch: 4500, avg_loss: 1.058354919195175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 51748.0354640625\n",
      "Average training loss in episode 1: 10670.295603125\n",
      "Average training loss in episode 2: 10200.783571875\n",
      "Average training loss in episode 3: 9998.93963671875\n",
      "Average training loss in episode 4: 9882.82310546875\n",
      "{'MSE': 9565.640754853855, 'MAE': 71.05846968574524}\n"
     ]
    }
   ],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "for i, (m, e) in enumerate(models):\n",
    "    m.train(epochs=e)\n",
    "    z = m.load_emb()\n",
    "    if i >= 2:\n",
    "        z = np.concatenate((z, z2), axis=1)\n",
    "\n",
    "    print(travel_time_est.evaluate(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

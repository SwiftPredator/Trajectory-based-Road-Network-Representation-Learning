{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from evaluation.tasks import (DestinationPrediciton, NextLocationPrediciton,\n",
    "                              TravelTimeEstimation)\n",
    "from generator import RoadNetwork, Trajectory\n",
    "from models import (GAEModel, GCNEncoder, GTCModel, GTNModel, Node2VecModel,\n",
    "                    SRN2VecModel, Traj2VecModel)\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "traj_train = pd.read_pickle(\n",
    "    f\"../../datasets/trajectories/Porto/traj_train_test_split/train_69.pkl\"\n",
    ")\n",
    "traj_train[\"seg_seq\"] = traj_train[\"seg_seq\"].map(np.array)\n",
    "traj_test = pd.read_pickle(\n",
    "    f\"../../datasets/trajectories/Porto/traj_train_test_split/test_69.pkl\"\n",
    ")\n",
    "traj_test[\"seg_seq\"] = traj_test[\"seg_seq\"].map(np.array)\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "data_roadclf = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=None)\n",
    "data_rest = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=None)\n",
    "\n",
    "adj = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_2.gz\")\n",
    "# adj_k3 = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_3.gz\")\n",
    "adj_sample = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False_no_selfloops_smoothed.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(trajectory, test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create init emb from gtc and traj2vec concat\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2VecModel(data_rest, network, adj=adj, device=device, emb_dim=128)\n",
    "traj2vec.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "gtc = GTCModel(data_rest, device, network, None, adj=adj)\n",
    "gtc.load_model(\"../model_states/gtc/model_base.pt\")\n",
    "node2vec = Node2VecModel(data_rest, device=device, q=4, p=1)\n",
    "node2vec.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "gae = GAEModel(data_rest, device=device, encoder=GCNEncoder, emb_dim=128)\n",
    "gae.load_model(\"../model_states/gaegcn/model_base.pt\")\n",
    "srn = SRN2VecModel(None, device, network, remove_highway_label=False)\n",
    "srn.load_dataset(\"./srn2vec-traindata-porto.json\")\n",
    "srn.load_model(\"../model_states/srn2vec/model_base.pt\")\n",
    "\n",
    "\n",
    "init_emb = torch.Tensor(np.concatenate([gtc.load_emb(), traj2vec.load_emb()], axis=1))\n",
    "add_emb = torch.Tensor(gtc.load_emb() + traj2vec.load_emb())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "# init GTN Model\n",
    "model = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=512)\n",
    "model.load_model(\"../model_states/gtn/model_base_69.pt\")\n",
    "# gtn_add = GTNModel(data_rest, device, network, train, traj_features, add_emb, adj_sample, batch_size=32, emb_dim=128, hidden_dim=128)\n",
    "# gtn_add.load_model(\"../model_states/gtn/model_base_add.pt\")\n",
    "# gtn_con = GTNModel(data_rest, device, network, train, traj_features, init_emb, adj_sample, batch_size=32)\n",
    "# gtn_con.load_model(\"../model_states/gtn/model_base_concat.pt\")\n",
    "# gtn_trans = GTNModel(data_rest, device, network, train, traj_features, None, adj_sample, batch_size=32, emb_dim=128, hidden_dim=128)\n",
    "# gtn_trans.load_model(\"../model_states/gtn/model_base_only_trans.pt\")\n",
    "# gtn_con_25 = GTNModel(data_rest, device, network, train, traj_features, init_emb, adj_sample, batch_size=32)\n",
    "# gtn_con_25.load_model(\"../model_states/gtn/model_base.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "h = model.model.transformer(torch.tensor([[2,3,4,5,6,7]]).to(device), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bee9985e13409283981141360f70a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/370616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4c15141d9546bf929c9adbbfb055fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/370616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7e9e98e4464319a135daad123273df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/92655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b052dd51564646a3be807c99fb626586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/92655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [04:18<00:00,  2.80it/s]\n",
      " 17%|█▋        | 1/6 [04:18<21:32, 258.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 7.326306860091278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [04:18<00:00,  2.81it/s]\n",
      " 33%|███▎      | 2/6 [08:36<17:12, 258.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 6.868975094010158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 169/724 [01:00<03:17,  2.81it/s]\n",
      " 33%|███▎      | 2/6 [09:36<19:13, 288.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal03/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevaluation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtasks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m init_destination\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal03/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m task \u001b[39m=\u001b[39m init_destination({\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m6\u001b[39m}, traj_test, network, device, seed\u001b[39m=\u001b[39m\u001b[39m69\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal03/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtn_construction.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m stats \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39;49mevaluate(emb\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtransformer)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/evaluation/tasks/destination.py:86\u001b[0m, in \u001b[0;36mDestinationPrediciton.evaluate\u001b[0;34m(self, emb, coord_sys)\u001b[0m\n\u001b[1;32m     66\u001b[0m model \u001b[39m=\u001b[39m DP_LSTM(\n\u001b[1;32m     67\u001b[0m     out_dim\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\n\u001b[1;32m     68\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mline_graph\u001b[39m.\u001b[39mnodes\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[39m# train on x trajectories\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(loader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loader, emb\u001b[39m=\u001b[39;49memb, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs)\n\u001b[1;32m     88\u001b[0m \u001b[39m# eval on test set using distance loss\u001b[39;00m\n\u001b[1;32m     89\u001b[0m yh, y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(loader\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_loader, emb\u001b[39m=\u001b[39memb)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/evaluation/tasks/destination.py:270\u001b[0m, in \u001b[0;36mDP_LSTM.train_model\u001b[0;34m(self, loader, emb, epochs)\u001b[0m\n\u001b[1;32m    268\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(yh\u001b[39m.\u001b[39msqueeze(), y)\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 270\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    272\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluation.tasks.task_loader import init_destination\n",
    "\n",
    "task = init_destination({\"epochs\": 6}, traj_test, network, device, seed=69)\n",
    "stats = task.evaluate(emb=model.model.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.003939344881549836}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "model2 = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=256)\n",
    "model2.load_model(\"../model_states/gtn/model_base_gtc_k2_10e_noutil_noautoreg_32_batch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "model3 = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=512)\n",
    "model3.load_model(\"../model_states/gtn/model_base_gtc_k2_10e_noutil_noautoreg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "model4 = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=512)\n",
    "model4.load_model(\"../model_states/gtn/model_base_gtc_k2_20e_noutil_autoreg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "model5 = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=512)\n",
    "model5.load_model(\"../model_states/gtn/model_base_gtc_k2_20e_noutil_noautoreg_512_batch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right insert\n"
     ]
    }
   ],
   "source": [
    "model6 = GTNModel(data_rest, device, network, traj_train, traj_features, init_emb, adj_sample, batch_size=512, hidden_dim=512)\n",
    "model6.load_model(\"../model_states/gtn/model_base_gtc_k2_30e_noutil_noautoreg_512_batch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter 0 loss: 1.0847514867782593, masked traj loss 0.577, judge traj loss 0.508\n",
      "Epoch: 0, iter 10 loss: 1.0973563194274902, masked traj loss 0.599, judge traj loss 0.498\n",
      "Epoch: 0, iter 20 loss: 1.1238110065460205, masked traj loss 0.631, judge traj loss 0.493\n",
      "Epoch 0 avg_loss=1.3245706991715864 total_acc= 73.14285714285714\n",
      "Epoch: 1, iter 0 loss: 1.3249919414520264, masked traj loss 0.871, judge traj loss 0.454\n",
      "Epoch: 1, iter 10 loss: 1.2418620586395264, masked traj loss 0.756, judge traj loss 0.486\n",
      "Epoch: 1, iter 20 loss: 1.712965726852417, masked traj loss 1.154, judge traj loss 0.559\n",
      "Epoch 1 avg_loss=1.3454584370959888 total_acc= 74.57142857142857\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model.load_emb()[2:]\n",
    "emb2 = model2.load_emb()[2:]\n",
    "emb3 = model3.load_emb()[2:]\n",
    "emb4 = model4.load_emb()[2:]\n",
    "emb5 = model5.load_emb()[2:]\n",
    "emb6 = model6.load_emb()[2:]\n",
    "# emb2 = model2.load_emb()\n",
    "# emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11331, 256)\n"
     ]
    }
   ],
   "source": [
    "print(emb6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_emb = node2vec.load_emb()\n",
    "gae_emb = gae.load_emb()\n",
    "srn_emb = srn.load_emb()\n",
    "n2v_emb = node2vec.load_emb()\n",
    "# gtn_add_emb = gtn_add.load_emb()\n",
    "# gtn_concat_emb = gtn_con.load_emb()\n",
    "# gtn_only_trans_emb = gtn_trans.load_emb()\n",
    "# gtn_con_25_emb = gtn_con_25.load_emb()\n",
    "rand_emb = np.random.randn(*emb3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), os.path.join(\"../model_states/gtn/\" + \"/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7836262167247774\n",
      "0.7768205967059234\n",
      "0.85607575965873\n",
      "0.6261817759851643\n",
      "0.8517336485185958\n",
      "0.2239445968724524\n",
      "0.055446008285913215\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "# train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# z = emb\n",
    "emb_full = np.concatenate((init_emb, emb3), axis=1)\n",
    "# emb_full2 = np.concatenate((init_emb, emb2), axis=1)\n",
    "# emb_gtc = np.concatenate((gtc.load_emb(), emb), axis=1)\n",
    "# zadd = np.add(emb, init_emb)\n",
    "# zcnn = np.concatenate((zn, z4), axis=1)\n",
    "# zctn = np.concatenate((zn, z5), axis=1)\n",
    "# X = z # embedding for each node\n",
    "eva = [emb5, emb6, init_emb, gae_emb, srn_emb, n2v_emb, rand_emb]\n",
    "for X in eva:\n",
    "    # X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    # lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.266369952847308\n",
      "12.3138748424747\n",
      "12.724326544038089\n",
      "14.236604496291301\n",
      "15.861414443131949\n",
      "14.285923659867086\n",
      "17.839338931717034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "# z = emb\n",
    "# zct = np.concatenate((init_emb, emb), axis=1)\n",
    "# zadd = np.add(emb, init_emb)\n",
    "# emb_full = np.concatenate((init_emb, emb), axis=1)\n",
    "# emb_full2 = np.concatenate((init_emb, emb2), axis=1)\n",
    "# emb_gtc = np.concatenate((gtc.load_emb(), emb), axis=1)\n",
    "eva = [emb5, emb6, init_emb, gae_emb, srn_emb, n2v_emb, rand_emb]\n",
    "for X in eva:\n",
    "    decoder = MLPRegressor(hidden_layer_sizes=(1024), random_state=88, max_iter=30)\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    # decoder.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.mean_absolute_error)\n",
    "    print(np.mean(cross_val_score(estimator=decoder, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 75.68767885430262}\n",
      "{'MAE': 76.16525251575713}\n",
      "{'MAE': 75.57562885135384}\n",
      "{'MAE': 78.68336486311374}\n",
      "{'MAE': 76.10248517295007}\n",
      "{'MAE': 80.14496336806562}\n"
     ]
    }
   ],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=traj_test,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "# travel_time_est.register_metric(\n",
    "#     name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    "# )\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "# z = emb\n",
    "zct = np.concatenate((init_emb, emb3), axis=1)\n",
    "# zadd = np.add(emb, init_emb)\n",
    "# emb_full = np.concatenate((init_emb, emb), axis=1)\n",
    "# emb_gtc = np.concatenate((gtc.load_emb(), emb), axis=1)\n",
    "eva = [emb5, emb6, init_emb, gae_emb, srn_emb, n2v_emb]\n",
    "for X in eva:\n",
    "    print(travel_time_est.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae01adceb3405b83aeff2bb6667b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/324289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4f9c7f2b42441f82d0202ff9ddedbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/324289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856d16722b3414fa3ad8b9ab6c181ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/138982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967dc31b22a24121b995ad27b0f74a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/138982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 64.1776114021566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 29.95768808190379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 22.062768059198035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 18.137576253632265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 15.9652257777915\n",
      "{'accuracy': 0.6250305794995036}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 106.25378229038948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 101.396855050457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 93.98275962612982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 81.5304538474098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 68.9096606401991\n",
      "{'accuracy': 0.2600840396598121}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 67.8003768559886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 33.295734291197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 25.011373507863716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 21.20470808883571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 19.079350609884653\n",
      "{'accuracy': 0.6056467744024406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 58.3942295399374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 26.257069139450508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 19.0066166315169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 15.441738206881453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 13.429345633329277\n",
      "{'accuracy': 0.6416946079348405}\n"
     ]
    }
   ],
   "source": [
    "nextlocation_pred = NextLocationPrediciton(\n",
    "    traj_dataset=traj_test,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "nextlocation_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "# z = emb\n",
    "# zctn = np.concatenate((init_emb, emb), axis=1)\n",
    "# zadd = np.add(emb, init_emb)\n",
    "# emb_full = np.concatenate((init_emb, emb), axis=1)\n",
    "# emb_full2 = np.concatenate((init_emb, emb2), axis=1)\n",
    "# emb_gtc = np.concatenate((gtc.load_emb(), emb), axis=1)\n",
    "eva = [emb5, n2v_emb, srn_emb, emb6]\n",
    "for X in eva:\n",
    "    print(nextlocation_pred.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358313e3ac4340eda5e01dac598a29d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2fb2ea5cd74dfcb80b360018381c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558000c22b1f4b07b72f603802984751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b830032776054ce5a0bf63e97faef5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 7.412824636077881\n",
      "Average training loss in episode 1: 6.142995080566406\n",
      "Average training loss in episode 2: 5.437318682098389\n",
      "Average training loss in episode 3: 4.99011307220459\n",
      "Average training loss in episode 4: 4.66860934638977\n",
      "{'accuracy': 0.14615}\n",
      "Average training loss in episode 0: 6.536014373016357\n",
      "Average training loss in episode 1: 5.085628775787353\n",
      "Average training loss in episode 2: 4.6572041358947756\n",
      "Average training loss in episode 3: 4.413045981216431\n",
      "Average training loss in episode 4: 4.245047995376587\n",
      "{'accuracy': 0.15835}\n",
      "Average training loss in episode 0: 6.5510960357666015\n",
      "Average training loss in episode 1: 5.102572080230713\n",
      "Average training loss in episode 2: 4.635688545227051\n",
      "Average training loss in episode 3: 4.3731794322967525\n",
      "Average training loss in episode 4: 4.18681318359375\n",
      "{'accuracy': 0.1603}\n",
      "Average training loss in episode 0: 6.565308332061767\n",
      "Average training loss in episode 1: 5.095686183929443\n",
      "Average training loss in episode 2: 4.635004696273803\n",
      "Average training loss in episode 3: 4.384142107772827\n",
      "Average training loss in episode 4: 4.205455271148682\n",
      "{'accuracy': 0.16315}\n",
      "Average training loss in episode 0: 6.509251563262939\n",
      "Average training loss in episode 1: 5.009183653259277\n",
      "Average training loss in episode 2: 4.541478307342529\n",
      "Average training loss in episode 3: 4.281755558776855\n",
      "Average training loss in episode 4: 4.125745105361938\n",
      "{'accuracy': 0.17}\n",
      "Average training loss in episode 0: 6.651467004394531\n",
      "Average training loss in episode 1: 5.121658686828614\n",
      "Average training loss in episode 2: 4.620731534576416\n",
      "Average training loss in episode 3: 4.354780445098877\n",
      "Average training loss in episode 4: 4.185916682434082\n",
      "{'accuracy': 0.1649}\n",
      "Average training loss in episode 0: 8.024266912841798\n",
      "Average training loss in episode 1: 7.478649576568603\n",
      "Average training loss in episode 2: 7.334471621704101\n",
      "Average training loss in episode 3: 7.190319743347168\n",
      "Average training loss in episode 4: 6.981961977386475\n",
      "{'accuracy': 0.0401}\n"
     ]
    }
   ],
   "source": [
    "dest_pred = DestinationPrediciton(\n",
    "    traj_dataset=traj_test[:100000],\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "dest_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "# emb_full = np.concatenate((init_emb, emb), axis=1)\n",
    "# emb_full2 = np.concatenate((init_emb, emb2), axis=1)\n",
    "# emb_gtc = np.concatenate((gtc.load_emb(), emb), axis=1)\n",
    "eva = [emb, emb2, emb3, emb4, emb5, emb6, n2v_emb]\n",
    "for X in eva:\n",
    "    print(dest_pred.evaluate(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

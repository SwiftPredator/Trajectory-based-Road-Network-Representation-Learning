{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import GTNModel, GTCModel, GAEModel, Node2VecModel, GCNEncoder, Traj2VecModel\n",
    "from evaluation.tasks import TravelTimeEstimation, NextLocationPrediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e703a2390a984faf9ad93deb0341e268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1585fa7c094da4ae1cb553768ae1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b781f4939cd2446b8c820c166b0e29c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14efd31404234d8ca799ed711cceee3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd933289a9004ea895cbc28026439b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "trajectory = Trajectory(\"../../datasets/trajectories/Porto/road_segment_map_final.csv\", nrows=100000000).generate_TTE_datatset()\n",
    "\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "# data = network.generate_road_segment_pyg_dataset(drop_labels=[\"highway_enc\"])\n",
    "data_roadclf = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=None)\n",
    "data_meanspeed = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"avg_speed\"], traj_data=traj_features.copy())\n",
    "data_rest = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_bi = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_2.gz\") # for traj2vec 'traj_adj_k_1_False_no_selfloops_smoothed'\n",
    "adj_bi_3 = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_3.gz\")\n",
    "# adj_for = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj[108, 130:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = Traj2Vec.traj_walk(adj, 5, 10000*[0], 10)\n",
    "print(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _walker import random_walks as _random_walks\n",
    "from scipy import sparse\n",
    "\n",
    "A = sparse.csr_matrix(adj)\n",
    "indptr = A.indptr.astype(np.uint32)\n",
    "indices = A.indices.astype(np.uint32)\n",
    "weights = A.data.astype(np.float32)\n",
    "\n",
    "_random_walks(indptr, indices, weights, [100,100,100], 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(traj2vec.state_dict(), \"modelt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = None\n",
    "data = T.OneHotDegree(128)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# precalc adj matrices\n",
    "GTCModel(data_rest, device, network, trajectory, k=6, bidirectional=False, add_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GTCModel(data_roadclf, device, network, adj=adj_bi)\n",
    "# model2 = GTCModel(data_roadclf, device, network, trajectory, adj=adj_for)\n",
    "# model2 = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\", norm=True)\n",
    "# model3 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model4 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model5 = Node2VecModel(data_roadclf, device=device, q=4, p=1)\n",
    "#model6 = Traj2VecModel(data_roadclf, network, adj, device=device, emb_dim=128, walk_length=30, context_size=5, walks_per_node=25, num_neg=10)\n",
    "\n",
    "# models.extend([(model, 5000), (model2, 5000)]) # (model3, 5000), (model4, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11331, 33])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.108349953532219\n",
      "Epoch: 2000, avg_loss: 1.0935820901989937\n",
      "Epoch: 3000, avg_loss: 1.0865380076964697\n",
      "Epoch: 4000, avg_loss: 1.0817484531402588\n",
      "Epoch: 5000, avg_loss: 1.0784950746774673\n",
      "Epoch: 6000, avg_loss: 1.076286903699239\n",
      "Epoch: 7000, avg_loss: 1.0746554876736232\n",
      "Epoch: 8000, avg_loss: 1.0734245615601539\n",
      "Epoch: 9000, avg_loss: 1.0724296962155235\n",
      "Epoch: 10000, avg_loss: 1.0716193663477898\n",
      "Epoch: 11000, avg_loss: 1.0709444018602372\n",
      "Epoch: 12000, avg_loss: 1.0703609810769559\n",
      "Epoch: 13000, avg_loss: 1.0698584491748075\n",
      "Epoch: 14000, avg_loss: 1.0693966476832117\n",
      "Epoch: 15000, avg_loss: 1.0689894316752753\n",
      "Epoch: 16000, avg_loss: 1.0686044336780907\n",
      "Epoch: 17000, avg_loss: 1.0682511512321584\n",
      "Epoch: 18000, avg_loss: 1.0679153449866507\n",
      "Epoch: 19000, avg_loss: 1.067601022362709\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for k in [1]:\n",
    "#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\n",
    "#     model.train(epochs=1000)\n",
    "#     models.append(model)\n",
    "\n",
    "model.train(epochs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11331, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.load_emb()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gtc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.norm import LayerNorm\n",
    "# load node2vec emb\n",
    "model5.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "z2 = model5.load_emb()\n",
    "model6.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z3 = model6.load_emb()\n",
    "\n",
    "norm = LayerNorm(z3.shape[1], affine=False)\n",
    "z4 = norm(torch.Tensor(z2)).detach().cpu().numpy()\n",
    "z5 = norm(torch.Tensor(z3)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GAE:\n\tsize mismatch for encoder.layers.0.lin.weight: copying a param with shape torch.Size([256, 33]) from checkpoint, the shape in current model is torch.Size([256, 21]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m gae \u001b[39m=\u001b[39m GAEModel(data_roadclf, device\u001b[39m=\u001b[39mdevice, encoder\u001b[39m=\u001b[39mGCNEncoder, emb_dim\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, layers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m gae\u001b[39m.\u001b[39;49mload_model(\u001b[39m\"\u001b[39;49m\u001b[39m../model_states/gaegcn/model_base.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m gae_emb \u001b[39m=\u001b[39m gae\u001b[39m.\u001b[39mload_emb()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000017vscode-remote?line=3'>4</a>\u001b[0m gtc \u001b[39m=\u001b[39m GTCModel(data_roadclf, device, network, adj\u001b[39m=\u001b[39madj_bi)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/gae.py:42\u001b[0m, in \u001b[0;36mGAEModel.load_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, path):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(path, map_location\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice))\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1493\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1494\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1498\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1499\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GAE:\n\tsize mismatch for encoder.layers.0.lin.weight: copying a param with shape torch.Size([256, 33]) from checkpoint, the shape in current model is torch.Size([256, 21])."
     ]
    }
   ],
   "source": [
    "gae = GAEModel(data_roadclf, device=device, encoder=GCNEncoder, emb_dim=128, layers=2)\n",
    "gae.load_model(\"../model_states/gaegcn/model_base.pt\")\n",
    "gae_emb = gae.load_emb()\n",
    "gtc = GTCModel(data_roadclf, device, network, adj=adj_bi)\n",
    "gtc.load_model(\"../model_states/gtc/model_base.pt\")\n",
    "# gtc2 = GTCModel(data_rest, device, network, adj=adj_bi_3)\n",
    "# gtc2.load_model(\"../model_states/gtc/model_base_k3_20k.pt\")\n",
    "t2v = Traj2VecModel(data_rest, network, adj_bi, device=device)\n",
    "t2v.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z = np.concatenate([gtc.load_emb(), t2v.load_emb()], axis=1)\n",
    "# z2 = np.concatenate([gtc2.load_emb(), t2v.load_emb()], axis=1)\n",
    "rand_emb = np.random.randn(*z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03461973 -0.7446656  -0.36518294 ... -0.12940633 -0.19541745\n",
      "  -0.41113168]\n",
      " [-0.06902651 -0.30286184 -0.42417783 ... -0.11377949 -0.24691841\n",
      "  -0.15814777]\n",
      " [-0.10037328 -0.67797256 -0.45901316 ... -0.14502342 -0.143866\n",
      "  -0.5151305 ]\n",
      " ...\n",
      " [-0.03662838  0.23067358  0.02284841 ...  0.09844947 -0.02313899\n",
      "   0.28437442]\n",
      " [-0.52729726 -0.24934813  0.35677475 ... -0.5402291  -0.09656639\n",
      "   0.44079298]\n",
      " [-0.52729726 -0.24934813  0.35677475 ... -0.5402291  -0.09656639\n",
      "   0.44079298]]\n",
      "--------\n",
      "[[ 0.14195527  0.71312606  0.27853405 ...  0.08516737 -0.62053263\n",
      "   0.17841183]\n",
      " [ 0.00569221  0.5116822   0.06596196 ...  0.01285282 -0.41922888\n",
      "   0.14586426]\n",
      " [ 0.00964291  0.76392955  0.12494162 ... -0.02320814 -0.6379421\n",
      "   0.17545395]\n",
      " ...\n",
      " [ 0.00233091  0.13886695  0.01223819 ...  0.01058747 -0.02673449\n",
      "  -0.24037123]\n",
      " [-0.40296662 -0.1827692   0.13607268 ...  0.56599444  0.04516564\n",
      "  -0.09180278]\n",
      " [-0.44287586 -0.19512364  0.13986318 ...  0.57609206  0.10952294\n",
      "  -0.09739541]]\n"
     ]
    }
   ],
   "source": [
    "print(gtc.load_emb())\n",
    "print(\"--------\")\n",
    "print(t2v.load_emb())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(trajectory, test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4652928742256364\n",
      "0.34928147803563026\n",
      "0.25823137610760594\n",
      "0.05440272810234651\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    # lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))\n",
    "    #print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.68308312660881\n",
      "13.492779042323273\n",
      "14.231388514448602\n",
      "17.7632361509869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "# idxs = np.arange(len(network.line_graph.nodes))\n",
    "#train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "# for m, e in models:\n",
    "#     m.train(epochs=e)\n",
    "    \n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb] # z, z2, gtc.load_emb(), gtc2.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    decoder = MLPRegressor(hidden_layer_sizes=(1024), random_state=88, max_iter=30)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    # decoder.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.mean_absolute_error)\n",
    "    print(np.mean(cross_val_score(estimator=decoder, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07796444 -0.55997896 -0.34868354 ...  0.08516737 -0.62053263\n",
      "   0.17841183]\n",
      " [-0.17300586 -0.313582   -0.3508929  ...  0.01285282 -0.41922888\n",
      "   0.14586426]\n",
      " [-0.08473617 -0.48305732 -0.47893226 ... -0.02320814 -0.6379421\n",
      "   0.17545395]\n",
      " ...\n",
      " [-0.03662838  0.23067358  0.02284841 ...  0.01058747 -0.02673449\n",
      "  -0.24037123]\n",
      " [-0.52729726 -0.24934813  0.35677475 ...  0.56599444  0.04516564\n",
      "  -0.09180278]\n",
      " [-0.52729726 -0.24934813  0.35677475 ...  0.57609206  0.10952294\n",
      "  -0.09739541]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current task: 100%|██████████| 1/1 [02:10<00:00, 130.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('meanspeed',                 MSE        MAE       RMSE\n",
      "concat   366.677423  12.915396  19.113661\n",
      "concat2  369.236217  12.931941  19.173809)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation.tasks.task_loader import *\n",
    "from evaluation.evaluation import Evaluation\n",
    "from models import ConcateAdapterModel\n",
    "\n",
    "eva = Evaluation()\n",
    "eva.register_task(\"meanspeed\", init_meanspeed(None, network, 88))\n",
    "\n",
    "model = ConcateAdapterModel(None, None, models=[gtc, t2v], aggregator=\"concate\")\n",
    "model2 = ConcateAdapterModel(None, None, models=[gtc2, t2v], aggregator=\"concate\")\n",
    "\n",
    "eva.register_model(\"concat\", model)\n",
    "eva.register_model(\"concat2\", model2)\n",
    "res = eva.run()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 9949.570608700878, 'MAE': 71.89226948661805}\n",
      "{'MSE': 11646.49069475799, 'MAE': 81.10363915457725}\n",
      "{'MSE': 10092.045623252046, 'MAE': 72.39778632850647}\n"
     ]
    }
   ],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=3,\n",
    "    seed=88,\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "# m.train(epochs=e)\n",
    "# zn = m.load_emb()\n",
    "# zcn = np.concatenate((zn, z2), axis=1)\n",
    "# zct = np.concatenate((zn, z3), axis=1)\n",
    "# X = z # embedding for each node\n",
    "eva = [z, z2, gtc.load_emb(), gtc2.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(travel_time_est.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52657f3e9e2c406983ea3940fedf1411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/108096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7c3433ba4c45189f400fc67fb59ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/108096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ea7c3530864f2dbc1106cb5c8ac398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/46328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efd01c9660f4091a12564d2163acbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/46328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 93.13604711136728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 60.42360982355082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 42.60375679663892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 33.21575438301518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 27.45381045791338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 23.018663941689258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 19.585921386502825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 17.329670883574575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 15.814587629066324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 14.090249111067575\n",
      "{'accuracy': 0.6325116560179589}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 99.54299696436468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 76.37419421717806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 59.97953197191347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 49.218008239314244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 41.48823459193392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 36.14445158220687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 31.431394756964917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 28.38374802751361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 25.533734420560442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 23.22743212501958\n",
      "{'accuracy': 0.5691374546710413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 95.28560181383817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 65.81340795193078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 48.93731500517647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 39.55925354867611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 33.625449108627606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 29.306134313907265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 26.167263624803077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 23.8469948858585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 21.672283620204567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 20.182108267298286\n",
      "{'accuracy': 0.5863192885512002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 71.99475444937652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 41.86305915184741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 32.94744706603716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 28.265848897538095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 25.153848009289437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 23.122095629854023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 22.05950561559425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 20.81006624563685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 19.88060889603957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 19.166528063000374\n",
      "{'accuracy': 0.6014721118977724}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nextlocation_pred = NextLocationPrediciton(\n",
    "    traj_dataset=test,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "nextlocation_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "#     m.train(epochs=e)\n",
    "#     zn = m.load_emb()\n",
    "#     zcn = np.concatenate((zn, z2), axis=1)\n",
    "#     zct = np.concatenate((zn, z3), axis=1)\n",
    "#     zcnn = np.concatenate((zn, z4), axis=1)\n",
    "#     zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(nextlocation_pred.evaluate(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

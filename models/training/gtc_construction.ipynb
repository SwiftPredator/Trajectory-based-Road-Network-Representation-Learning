{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import GTNModel, GTCModel, GAEModel, Node2VecModel, GCNEncoder, Traj2VecModel\n",
    "from evaluation.tasks import TravelTimeEstimation, NextLocationPrediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc35e6b7fab34f8d875718156f146683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed584eee71544097b1594de4ae45c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549c22cad46a4bda9dd60855e0b68b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f22ec60dd74c8e939acd1c29e61bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03af0812661f4b7985c3823d5694dc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/swifter/swifter.py:242\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    240\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_apply(\n\u001b[0;32m--> 242\u001b[0m         np\u001b[39m.\u001b[39marray_equal(sample_df, tmp_df) \u001b[39m&\u001b[39m (\u001b[39mhasattr\u001b[39m(tmp_df, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m&\u001b[39m (sample_df\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m tmp_df\u001b[39m.\u001b[39;49mshape),\n\u001b[1;32m    243\u001b[0m         error_message\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mVectorized function sample doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match pandas apply sample.\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000001vscode-remote?line=0'>1</a>\u001b[0m network \u001b[39m=\u001b[39m RoadNetwork()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m network\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m../../osm_data/porto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m trajectory \u001b[39m=\u001b[39m Trajectory(\u001b[39m\"\u001b[39;49m\u001b[39m../../datasets/trajectories/Porto/road_segment_map_final.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, nrows\u001b[39m=\u001b[39;49m\u001b[39m10000000\u001b[39;49m)\u001b[39m.\u001b[39;49mgenerate_TTE_datatset()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m traj_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../../datasets/trajectories/Porto/speed_features_unnormalized.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/gtc_construction.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m traj_features\u001b[39m.\u001b[39mset_index([\u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/generator/trajectory.py:51\u001b[0m, in \u001b[0;36mTrajectory.generate_TTE_datatset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m tte \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     50\u001b[0m tte[\u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tte[\u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mswifter\u001b[39m.\u001b[39mapply(literal_eval)\n\u001b[0;32m---> 51\u001b[0m tte[\u001b[39m\"\u001b[39m\u001b[39mtravel_time\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tte[\u001b[39m\"\u001b[39;49m\u001b[39mduration\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(np\u001b[39m.\u001b[39;49msum)\n\u001b[1;32m     52\u001b[0m tte\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m tte\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcpath\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mseg_seq\u001b[39m\u001b[39m\"\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/swifter/swifter.py:259\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar:\n\u001b[1;32m    258\u001b[0m     tqdm\u001b[39m.\u001b[39mpandas(desc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar_desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mPandas Apply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj\u001b[39m.\u001b[39;49mprogress_apply(func, convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/tqdm/std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1138\u001b[0m             values,\n\u001b[1;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1141\u001b[0m         )\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/tqdm/std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2296\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2294\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2296\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2297\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/numpy/core/fromnumeric.py:69\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     70\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     71\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "trajectory = Trajectory(\"../../datasets/trajectories/Porto/road_segment_map_final.csv\", nrows=10000000).generate_TTE_datatset()\n",
    "\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "# data = network.generate_road_segment_pyg_dataset(drop_labels=[\"highway_enc\"])\n",
    "data_roadclf = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=None)\n",
    "data_meanspeed = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"avg_speed\"], traj_data=traj_features.copy())\n",
    "data_rest = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_bi = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_3.gz\") # for traj2vec 'traj_adj_k_1_False_no_selfloops_smoothed'\n",
    "# adj_for = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj[108, 130:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = Traj2Vec.traj_walk(adj, 5, 10000*[0], 10)\n",
    "print(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _walker import random_walks as _random_walks\n",
    "from scipy import sparse\n",
    "\n",
    "A = sparse.csr_matrix(adj)\n",
    "indptr = A.indptr.astype(np.uint32)\n",
    "indices = A.indices.astype(np.uint32)\n",
    "weights = A.data.astype(np.float32)\n",
    "\n",
    "_random_walks(indptr, indices, weights, [100,100,100], 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(traj2vec.state_dict(), \"modelt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = None\n",
    "data = T.OneHotDegree(128)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# precalc adj matrices\n",
    "GTCModel(data_rest, device, network, trajectory, k=6, bidirectional=False, add_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GTCModel(data_rest, device, network, trajectory, adj=adj_bi)\n",
    "# model2 = GTCModel(data_roadclf, device, network, trajectory, adj=adj_for)\n",
    "# model2 = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\", norm=True)\n",
    "# model3 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model4 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model5 = Node2VecModel(data_roadclf, device=device, q=4, p=1)\n",
    "#model6 = Traj2VecModel(data_roadclf, network, adj, device=device, emb_dim=128, walk_length=30, context_size=5, walks_per_node=25, num_neg=10)\n",
    "\n",
    "# models.extend([(model, 5000), (model2, 5000)]) # (model3, 5000), (model4, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11331, 33])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.067290608048439\n",
      "Epoch: 2000, avg_loss: 1.0501294767856597\n",
      "Epoch: 3000, avg_loss: 1.0425132358074187\n",
      "Epoch: 4000, avg_loss: 1.0379318472743035\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for k in [1]:\n",
    "#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\n",
    "#     model.train(epochs=1000)\n",
    "#     models.append(model)\n",
    "\n",
    "model.train(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11331, 128)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.load_emb()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gtc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.norm import LayerNorm\n",
    "# load node2vec emb\n",
    "model5.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "z2 = model5.load_emb()\n",
    "model6.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z3 = model6.load_emb()\n",
    "\n",
    "norm = LayerNorm(z3.shape[1], affine=False)\n",
    "z4 = norm(torch.Tensor(z2)).detach().cpu().numpy()\n",
    "z5 = norm(torch.Tensor(z3)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae = GAEModel(data_rest, device=device, encoder=GCNEncoder, emb_dim=128, layers=2)\n",
    "gae.load_model(\"../model_states/gaegcn/model_base.pt\")\n",
    "gae_emb = gae.load_emb()\n",
    "gtc = GTCModel(data_rest, device, network, trajectory, adj=adj_bi)\n",
    "gtc.load_model(\"../model_states/gtc/model_k3.pt\")\n",
    "t2v = Traj2VecModel(data_roadclf, network, adj_bi, device=device)\n",
    "t2v.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z = gtc.load_emb() + t2v.load_emb()\n",
    "rand_emb = np.random.randn(*z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7891448585793378\n",
      "0.6101262337702813\n",
      "0.05217859890304014\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    # lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))\n",
    "    #print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.800262631844811\n",
      "13.979628785756239\n",
      "15.661938068991324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "# for m, e in models:\n",
    "#     m.train(epochs=e)\n",
    "    \n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    decoder = linear_model.LinearRegression(fit_intercept=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    # decoder.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.mean_absolute_error)\n",
    "    print(np.mean(cross_val_score(estimator=decoder, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 9949.570608700878, 'MAE': 71.89226948661805}\n",
      "{'MSE': 11646.49069475799, 'MAE': 81.10363915457725}\n",
      "{'MSE': 10092.045623252046, 'MAE': 72.39778632850647}\n"
     ]
    }
   ],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=3,\n",
    "    seed=88,\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "# m.train(epochs=e)\n",
    "# zn = m.load_emb()\n",
    "# zcn = np.concatenate((zn, z2), axis=1)\n",
    "# zct = np.concatenate((zn, z3), axis=1)\n",
    "# X = z # embedding for each node\n",
    "eva = [z, gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(travel_time_est.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdcb458a98346b896f3a0cc3aa26f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d8d84ab9fa495d9584019dbf1c998f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751009f1e18f4f5a9af6b634a1b5a33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b3735c148643dc9c288fd7c10be225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 104.00620584213695\n",
      "Average training loss in episode 1: 90.98275513085314\n",
      "Average training loss in episode 2: 73.96600678172736\n",
      "{'accuracy': 0.2464}\n",
      "Average training loss in episode 0: 106.01926556181984\n",
      "Average training loss in episode 1: 91.70118247815215\n",
      "Average training loss in episode 2: 76.58374203812961\n",
      "{'accuracy': 0.2223}\n",
      "Average training loss in episode 0: 96.02736768631128\n",
      "Average training loss in episode 1: 57.71753060094084\n",
      "Average training loss in episode 2: 39.92700451250655\n",
      "{'accuracy': 0.49315}\n"
     ]
    }
   ],
   "source": [
    "nextlocation_pred = NextLocationPrediciton(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=256,\n",
    "    epochs=3,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "nextlocation_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "#     m.train(epochs=e)\n",
    "#     zn = m.load_emb()\n",
    "#     zcn = np.concatenate((zn, z2), axis=1)\n",
    "#     zct = np.concatenate((zn, z3), axis=1)\n",
    "#     zcnn = np.concatenate((zn, z4), axis=1)\n",
    "#     zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(nextlocation_pred.evaluate(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

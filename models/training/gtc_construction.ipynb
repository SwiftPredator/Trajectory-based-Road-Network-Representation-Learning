{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import GTNModel, GTCModel, GAEModel, Node2VecModel, GCNEncoder, Traj2VecModel\n",
    "from evaluation.tasks import TravelTimeEstimation, NextLocationPrediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d36efb1d5d14026aa91ace8ab520c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781674d61a7248d697dc680bd0ab635d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7d76916a3e448f86360a034fc97e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94735303f2ed4a04bf03759743817481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf1417687054b80acb6dc494dccb36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "trajectory = Trajectory(\"../../datasets/trajectories/Porto/road_segment_map_final.csv\", nrows=10000).generate_TTE_datatset()\n",
    "\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "# data = network.generate_road_segment_pyg_dataset(drop_labels=[\"highway_enc\"])\n",
    "data_roadclf = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=traj_features.copy())\n",
    "data_meanspeed = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"avg_speed\"], traj_data=traj_features.copy())\n",
    "data_rest = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_bi = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1.gz\") # for traj2vec 'traj_adj_k_1_False_no_selfloops_smoothed'\n",
    "adj_for = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj[108, 130:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = Traj2Vec.traj_walk(adj, 5, 10000*[0], 10)\n",
    "print(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _walker import random_walks as _random_walks\n",
    "from scipy import sparse\n",
    "\n",
    "A = sparse.csr_matrix(adj)\n",
    "indptr = A.indptr.astype(np.uint32)\n",
    "indices = A.indices.astype(np.uint32)\n",
    "weights = A.data.astype(np.float32)\n",
    "\n",
    "_random_walks(indptr, indices, weights, [100,100,100], 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(traj2vec.state_dict(), \"modelt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = None\n",
    "data = T.OneHotDegree(128)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# precalc adj matrices\n",
    "GTCModel(data_rest, device, network, trajectory, k=6, bidirectional=False, add_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GTCModel(data_rest, device, network, trajectory, adj=adj_bi)\n",
    "# model2 = GTCModel(data_roadclf, device, network, trajectory, adj=adj_for)\n",
    "# model2 = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\", norm=True)\n",
    "# model3 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model4 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model5 = Node2VecModel(data_roadclf, device=device, q=4, p=1)\n",
    "#model6 = Traj2VecModel(data_roadclf, network, adj, device=device, emb_dim=128, walk_length=30, context_size=5, walks_per_node=25, num_neg=10)\n",
    "\n",
    "# models.extend([(model, 5000), (model2, 5000)]) # (model3, 5000), (model4, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 0.9901394048929214\n",
      "Epoch: 2000, avg_loss: 0.9750332573354245\n",
      "Epoch: 3000, avg_loss: 0.9693118772705396\n",
      "Epoch: 4000, avg_loss: 0.9662222523540258\n",
      "Epoch: 5000, avg_loss: 0.9640684484362603\n",
      "Epoch: 6000, avg_loss: 0.9623641260464986\n",
      "Epoch: 7000, avg_loss: 0.9609341534035546\n",
      "Epoch: 8000, avg_loss: 0.9597380672097207\n",
      "Epoch: 9000, avg_loss: 0.9587665875487857\n",
      "Epoch: 10000, avg_loss: 0.9579744104862213\n",
      "Epoch: 11000, avg_loss: 0.9573174765814434\n",
      "Epoch: 12000, avg_loss: 0.9567617003222306\n",
      "Epoch: 13000, avg_loss: 0.9562859253608263\n",
      "Epoch: 14000, avg_loss: 0.9558805715399129\n",
      "Epoch: 15000, avg_loss: 0.955516168220838\n",
      "Epoch: 16000, avg_loss: 0.9551985378339887\n",
      "Epoch: 17000, avg_loss: 0.9549163103664623\n",
      "Epoch: 18000, avg_loss: 0.9546608121130201\n",
      "Epoch: 19000, avg_loss: 0.9544345917795833\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for k in [1]:\n",
    "#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\n",
    "#     model.train(epochs=1000)\n",
    "#     models.append(model)\n",
    "\n",
    "model.train(epochs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.model(model.train_data.x, model.train_data.edge_traj_index, model.train_data.edge_weight)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gtc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.norm import LayerNorm\n",
    "# load node2vec emb\n",
    "model5.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "z2 = model5.load_emb()\n",
    "model6.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z3 = model6.load_emb()\n",
    "\n",
    "norm = LayerNorm(z3.shape[1], affine=False)\n",
    "z4 = norm(torch.Tensor(z2)).detach().cpu().numpy()\n",
    "z5 = norm(torch.Tensor(z3)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.0774289163351058\n",
      "Epoch: 2000, avg_loss: 1.0660206062197686\n",
      "Epoch: 3000, avg_loss: 1.0605279933214187\n",
      "Epoch: 4000, avg_loss: 1.0570466541051864\n",
      "0.325987306905676\n",
      "Epoch: 1000, avg_loss: 1.0772264443635942\n",
      "Epoch: 2000, avg_loss: 1.0660602782964705\n",
      "Epoch: 3000, avg_loss: 1.0605764306783676\n",
      "Epoch: 4000, avg_loss: 1.0571666072010995\n",
      "0.32591392748425024\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "for m, e in models:\n",
    "    m.train(epochs=e)\n",
    "    zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "    eva = [zn]\n",
    "    for X in eva:\n",
    "        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "        lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "        # lm.fit(X_train, y_train)\n",
    "        scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "        print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))\n",
    "    #print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, avg_loss: 1.0717286483049393\n",
      "Epoch: 2000, avg_loss: 1.0711429191231727\n",
      "Epoch: 3000, avg_loss: 1.0709215581417084\n",
      "Epoch: 4000, avg_loss: 1.0708074048757552\n",
      "40.1198052070357\n",
      "Epoch: 1000, avg_loss: 1.0717793021202087\n",
      "Epoch: 2000, avg_loss: 1.0710813256502152\n",
      "Epoch: 3000, avg_loss: 1.0709160551627477\n",
      "Epoch: 4000, avg_loss: 1.0707399646043778\n",
      "40.13626079127839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "for m, e in models:\n",
    "    m.train(epochs=e)\n",
    "    \n",
    "    zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "    eva = [zn]\n",
    "    for X in eva:\n",
    "        decoder = linear_model.LinearRegression(fit_intercept=True)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "        # decoder.fit(X_train, y_train)\n",
    "        scorer = make_scorer(metrics.mean_absolute_error)\n",
    "        print(np.mean(cross_val_score(estimator=decoder, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "for i, (m, e) in enumerate(models):\n",
    "    m.train(epochs=e)\n",
    "    zn = m.load_emb()\n",
    "    zcn = np.concatenate((zn, z2), axis=1)\n",
    "    zct = np.concatenate((zn, z3), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "    eva = [zn, zcn, zct]\n",
    "    for X in eva:\n",
    "        print(travel_time_est.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextlocation_pred = NextLocationPrediciton(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=256,\n",
    "    epochs=5,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "nextlocation_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "for i, (m, e) in enumerate(models):\n",
    "    m.train(epochs=e)\n",
    "    zn = m.load_emb()\n",
    "    zcn = np.concatenate((zn, z2), axis=1)\n",
    "    zct = np.concatenate((zn, z3), axis=1)\n",
    "    zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "    eva = [zn, zcn, zct, zcnn, zctn]\n",
    "    for X in eva:\n",
    "        print(nextlocation_pred.evaluate(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

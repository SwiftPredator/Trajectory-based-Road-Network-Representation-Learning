{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import GTNModel, GTCModel, GAEModel, Node2VecModel, GCNEncoder, Traj2VecModel\n",
    "from evaluation.tasks import TravelTimeEstimation, NextLocationPrediciton, DestinationPrediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\n",
    "        f\"../../datasets/trajectories/Porto/traj_train_test_split/test_69.pkl\"\n",
    "    )\n",
    "test[\"seg_seq\"] = test[\"seg_seq\"].map(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seg_seq</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694632</th>\n",
       "      <td>928184</td>\n",
       "      <td>[5645, 5589, 5572, 5585, 6933, 5550, 10106, 11...</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88672</th>\n",
       "      <td>153896</td>\n",
       "      <td>[7989, 5763, 5769, 5761, 6909, 6905, 6906, 799...</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693966</th>\n",
       "      <td>928038</td>\n",
       "      <td>[846, 849, 5786, 10671, 752, 748, 743, 5219, 7...</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317979</th>\n",
       "      <td>1840009</td>\n",
       "      <td>[698, 9112, 10662, 10663, 703, 6360, 5895, 704...</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383406</th>\n",
       "      <td>589651</td>\n",
       "      <td>[6905, 6906, 7992, 6577, 869, 868, 6917, 8138,...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153375</th>\n",
       "      <td>1684054</td>\n",
       "      <td>[769, 807, 1728, 7929, 805, 7930, 6905, 6906, ...</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496878</th>\n",
       "      <td>2097587</td>\n",
       "      <td>[10730, 10732, 1517, 1427, 172, 175, 1473, 170...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336161</th>\n",
       "      <td>1809666</td>\n",
       "      <td>[10431, 1387, 10423, 10433, 623, 10421, 934, 1...</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801093</th>\n",
       "      <td>1169706</td>\n",
       "      <td>[10459, 1579, 4088, 4083, 1573, 1488, 4066, 40...</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783366</th>\n",
       "      <td>1049452</td>\n",
       "      <td>[3522, 1534, 3523, 1529, 1527, 3526, 3530, 106...</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463271 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            seg_seq  \\\n",
       "694632    928184  [5645, 5589, 5572, 5585, 6933, 5550, 10106, 11...   \n",
       "88672     153896  [7989, 5763, 5769, 5761, 6909, 6905, 6906, 799...   \n",
       "693966    928038  [846, 849, 5786, 10671, 752, 748, 743, 5219, 7...   \n",
       "1317979  1840009  [698, 9112, 10662, 10663, 703, 6360, 5895, 704...   \n",
       "383406    589651  [6905, 6906, 7992, 6577, 869, 868, 6917, 8138,...   \n",
       "...          ...                                                ...   \n",
       "1153375  1684054  [769, 807, 1728, 7929, 805, 7930, 6905, 6906, ...   \n",
       "1496878  2097587  [10730, 10732, 1517, 1427, 172, 175, 1473, 170...   \n",
       "1336161  1809666  [10431, 1387, 10423, 10433, 623, 10421, 934, 1...   \n",
       "801093   1169706  [10459, 1579, 4088, 4083, 1573, 1488, 4066, 40...   \n",
       "783366   1049452  [3522, 1534, 3523, 1529, 1527, 3526, 3530, 106...   \n",
       "\n",
       "         travel_time  \n",
       "694632           270  \n",
       "88672            360  \n",
       "693966           750  \n",
       "1317979          465  \n",
       "383406           330  \n",
       "...              ...  \n",
       "1153375          630  \n",
       "1496878          180  \n",
       "1336161          540  \n",
       "801093           795  \n",
       "783366           315  \n",
       "\n",
       "[463271 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f348bbe8ea8d48b4aa2079a1430d5d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ca732fff1d4beb9b3204d47fbe72f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7aedafe09d4c6b955dca37a3b63a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c3fa0317c24a2bb973a4a579307bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219e89a16c6947fc8930612cf94d659c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1544234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "trajectory = Trajectory(\"../../datasets/trajectories/Porto/road_segment_map_final.csv\", nrows=100000000).generate_TTE_datatset()\n",
    "\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)\n",
    "\n",
    "# data = network.generate_road_segment_pyg_dataset(drop_labels=[\"highway_enc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roadclf_normal = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"])\n",
    "# data_meanspeed = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"avg_speed\"], traj_data=traj_features.copy())\n",
    "data_rest_normal = network.generate_road_segment_pyg_dataset(include_coords=True)\n",
    "data_roadclf_traj_all = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=traj_features.copy())\n",
    "data_rest_traj_all = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=traj_features.copy())\n",
    "data_roadclf_traj_speed = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=traj_features[[\"id\", \"avg_speed\"]].copy())\n",
    "data_rest_traj_speed = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=traj_features[[\"id\", \"avg_speed\"]].copy())\n",
    "data_roadclf_traj_util = network.generate_road_segment_pyg_dataset(include_coords=True, drop_labels=[\"highway_enc\"], traj_data=traj_features[[\"id\", \"util\"]].copy())\n",
    "data_rest_traj_util = network.generate_road_segment_pyg_dataset(include_coords=True, traj_data=traj_features[[\"id\", \"util\"]].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11331, 35])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_bi = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_2.gz\") # for traj2vec 'traj_adj_k_1_False_no_selfloops_smoothed'\n",
    "# adj_bi_3 = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_3.gz\")\n",
    "# adj_for = np.loadtxt(\"./gtn_precalc_adj/traj_adj_k_1_False.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = Traj2Vec.traj_walk(adj, 5, 10000*[0], 10)\n",
    "print(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _walker import random_walks as _random_walks\n",
    "from scipy import sparse\n",
    "\n",
    "A = sparse.csr_matrix(adj)\n",
    "indptr = A.indptr.astype(np.uint32)\n",
    "indices = A.indices.astype(np.uint32)\n",
    "weights = A.data.astype(np.float32)\n",
    "\n",
    "_random_walks(indptr, indices, weights, [100,100,100], 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(traj2vec.state_dict(), \"modelt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = None\n",
    "data = T.OneHotDegree(128)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# precalc adj matrices\n",
    "GTCModel(data_rest, device, network, trajectory, k=6, bidirectional=False, add_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model = GTCModel(data_roadclf_traj_speed, device, network, adj=adj_bi)\n",
    "# model2 = GTCModel(data_roadclf, device, network, trajectory, adj=adj_for)\n",
    "# model2 = GTNModel(data2, device, network, trajectory, load_traj_adj_path=\"./gtn_precalc_adj/traj_adj_k_1.gz\", norm=True)\n",
    "# model3 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model4 = GAEModel(data2, device=device, encoder=GCNEncoder, emb_dim=128, layers=1)\n",
    "# model5 = Node2VecModel(data_roadclf, device=device, q=4, p=1)\n",
    "#model6 = Traj2VecModel(data_roadclf, network, adj, device=device, emb_dim=128, walk_length=30, context_size=5, walks_per_node=25, num_neg=10)\n",
    "\n",
    "# models.extend([(model, 5000), (model2, 5000)]) # (model3, 5000), (model4, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# for k in [1]:\n",
    "#     model = GTNModel(data, device, network, trajectory, load_traj_adj_path=\"./traj_adj_k_{}.gz\".format(k))\n",
    "#     model.train(epochs=1000)\n",
    "#     models.append(model)\n",
    "\n",
    "model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11331, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.load_emb()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gtc/feature_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.norm import LayerNorm\n",
    "# load node2vec emb\n",
    "model5.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "z2 = model5.load_emb()\n",
    "model6.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z3 = model6.load_emb()\n",
    "\n",
    "norm = LayerNorm(z3.shape[1], affine=False)\n",
    "z4 = norm(torch.Tensor(z2)).detach().cpu().numpy()\n",
    "z5 = norm(torch.Tensor(z3)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae = GAEModel(data_rest, device=device, encoder=GCNEncoder, emb_dim=128, layers=2)\n",
    "gae.load_model(\"../model_states/gaegcn/model_base.pt\")\n",
    "node2vec = Node2VecModel(data_rest, device=device, q=4, p=1)\n",
    "node2vec.load_model(\"../model_states/node2vec/model_base.pt\")\n",
    "n2v_emb = node2vec.load_emb()\n",
    "gae_emb = gae.load_emb()\n",
    "gtc = GTCModel(data_rest, device, network, adj=adj_bi)\n",
    "gtc.load_model(\"../model_states/gtc/model_base.pt\")\n",
    "# gtc2 = GTCModel(data_rest, device, network, adj=adj_bi_3)\n",
    "# gtc2.load_model(\"../model_states/gtc/model_base_k3_20k.pt\")\n",
    "t2v = Traj2VecModel(data_rest, network, adj_bi, device=device)\n",
    "t2v.load_model(\"../model_states/traj2vec/model_base.pt\")\n",
    "z = np.concatenate([gtc.load_emb(), t2v.load_emb()], axis=1)\n",
    "# z2 = np.concatenate([gtc2.load_emb(), t2v.load_emb()], axis=1)\n",
    "rand_emb = np.random.randn(*z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03461973 -0.7446656  -0.36518294 ... -0.12940633 -0.19541745\n",
      "  -0.41113168]\n",
      " [-0.06902651 -0.30286184 -0.42417783 ... -0.11377949 -0.24691841\n",
      "  -0.15814777]\n",
      " [-0.10037328 -0.67797256 -0.45901316 ... -0.14502342 -0.143866\n",
      "  -0.5151305 ]\n",
      " ...\n",
      " [-0.03662838  0.23067358  0.02284841 ...  0.09844947 -0.02313899\n",
      "   0.28437442]\n",
      " [-0.52729726 -0.24934813  0.35677475 ... -0.5402291  -0.09656639\n",
      "   0.44079298]\n",
      " [-0.52729726 -0.24934813  0.35677475 ... -0.5402291  -0.09656639\n",
      "   0.44079298]]\n",
      "--------\n",
      "[[ 0.14195527  0.71312606  0.27853405 ...  0.08516737 -0.62053263\n",
      "   0.17841183]\n",
      " [ 0.00569221  0.5116822   0.06596196 ...  0.01285282 -0.41922888\n",
      "   0.14586426]\n",
      " [ 0.00964291  0.76392955  0.12494162 ... -0.02320814 -0.6379421\n",
      "   0.17545395]\n",
      " ...\n",
      " [ 0.00233091  0.13886695  0.01223819 ...  0.01058747 -0.02673449\n",
      "  -0.24037123]\n",
      " [-0.40296662 -0.1827692   0.13607268 ...  0.56599444  0.04516564\n",
      "  -0.09180278]\n",
      " [-0.44287586 -0.19512364  0.13986318 ...  0.57609206  0.10952294\n",
      "  -0.09739541]]\n"
     ]
    }
   ],
   "source": [
    "print(gtc.load_emb())\n",
    "print(\"--------\")\n",
    "print(t2v.load_emb())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(trajectory, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463271, 3) (1080963, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape, train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle(\"../../datasets/trajectories/Porto/traj_train_test_split/test_69.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4652928742256364\n",
      "0.34928147803563026\n",
      "0.25823137610760594\n",
      "0.05440272810234651\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    # lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))\n",
    "    #print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.68308312660881\n",
      "13.492779042323273\n",
      "14.231388514448602\n",
      "17.7632361509869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "\n",
    "# idxs = np.arange(len(network.line_graph.nodes))\n",
    "#train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "y = y.values\n",
    "\n",
    "# for m, e in models:\n",
    "#     m.train(epochs=e)\n",
    "    \n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb] # z, z2, gtc.load_emb(), gtc2.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    decoder = MLPRegressor(hidden_layer_sizes=(1024), random_state=88, max_iter=30)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    # decoder.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.mean_absolute_error)\n",
    "    print(np.mean(cross_val_score(estimator=decoder, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07796444 -0.55997896 -0.34868354 ...  0.08516737 -0.62053263\n",
      "   0.17841183]\n",
      " [-0.17300586 -0.313582   -0.3508929  ...  0.01285282 -0.41922888\n",
      "   0.14586426]\n",
      " [-0.08473617 -0.48305732 -0.47893226 ... -0.02320814 -0.6379421\n",
      "   0.17545395]\n",
      " ...\n",
      " [-0.03662838  0.23067358  0.02284841 ...  0.01058747 -0.02673449\n",
      "  -0.24037123]\n",
      " [-0.52729726 -0.24934813  0.35677475 ...  0.56599444  0.04516564\n",
      "  -0.09180278]\n",
      " [-0.52729726 -0.24934813  0.35677475 ...  0.57609206  0.10952294\n",
      "  -0.09739541]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current task: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('meanspeed',                 MSE        MAE       RMSE\n",
      "concat   366.677423  12.915396  19.113661\n",
      "concat2  369.236217  12.931941  19.173809)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation.tasks.task_loader import *\n",
    "from evaluation.evaluation import Evaluation\n",
    "from models import ConcateAdapterModel\n",
    "\n",
    "eva = Evaluation()\n",
    "eva.register_task(\"meanspeed\", init_meanspeed(None, network, 88))\n",
    "\n",
    "model = ConcateAdapterModel(None, None, models=[gtc, t2v], aggregator=\"concate\")\n",
    "model2 = ConcateAdapterModel(None, None, models=[gtc2, t2v], aggregator=\"concate\")\n",
    "\n",
    "eva.register_model(\"concat\", model)\n",
    "eva.register_model(\"concat2\", model2)\n",
    "res = eva.run()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 9949.570608700878, 'MAE': 71.89226948661805}\n",
      "{'MSE': 11646.49069475799, 'MAE': 81.10363915457725}\n",
      "{'MSE': 10092.045623252046, 'MAE': 72.39778632850647}\n"
     ]
    }
   ],
   "source": [
    "travel_time_est = TravelTimeEstimation(\n",
    "    traj_dataset=trajectory,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=128,\n",
    "    epochs=3,\n",
    "    seed=88,\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MSE\", metric_func=metrics.mean_squared_error, args={}\n",
    ")\n",
    "travel_time_est.register_metric(\n",
    "    name=\"MAE\", metric_func=metrics.mean_absolute_error, args={}\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "# m.train(epochs=e)\n",
    "# zn = m.load_emb()\n",
    "# zcn = np.concatenate((zn, z2), axis=1)\n",
    "# zct = np.concatenate((zn, z3), axis=1)\n",
    "# X = z # embedding for each node\n",
    "eva = [z, z2, gtc.load_emb(), gtc2.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(travel_time_est.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52657f3e9e2c406983ea3940fedf1411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/108096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7c3433ba4c45189f400fc67fb59ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/108096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ea7c3530864f2dbc1106cb5c8ac398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/46328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efd01c9660f4091a12564d2163acbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/46328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 93.13604711136728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 60.42360982355082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 42.60375679663892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 33.21575438301518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 27.45381045791338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 23.018663941689258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 19.585921386502825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 17.329670883574575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 15.814587629066324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 14.090249111067575\n",
      "{'accuracy': 0.6325116560179589}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 99.54299696436468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 76.37419421717806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 59.97953197191347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 49.218008239314244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 41.48823459193392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 36.14445158220687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 31.431394756964917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 28.38374802751361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 25.533734420560442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 23.22743212501958\n",
      "{'accuracy': 0.5691374546710413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 95.28560181383817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 65.81340795193078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 48.93731500517647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 39.55925354867611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 33.625449108627606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 29.306134313907265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 26.167263624803077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 23.8469948858585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 21.672283620204567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 20.182108267298286\n",
      "{'accuracy': 0.5863192885512002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 71.99475444937652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 1: 41.86305915184741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 2: 32.94744706603716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 3: 28.265848897538095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 4: 25.153848009289437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 5: 23.122095629854023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 6: 22.05950561559425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 7: 20.81006624563685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 8: 19.88060889603957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 9: 19.166528063000374\n",
      "{'accuracy': 0.6014721118977724}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nextlocation_pred = NextLocationPrediciton(\n",
    "    traj_dataset=test,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "nextlocation_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "# for i, (m, e) in enumerate(models):\n",
    "#     m.train(epochs=e)\n",
    "#     zn = m.load_emb()\n",
    "#     zcn = np.concatenate((zn, z2), axis=1)\n",
    "#     zct = np.concatenate((zn, z3), axis=1)\n",
    "#     zcnn = np.concatenate((zn, z4), axis=1)\n",
    "#     zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z, gtc.load_emb(), gae_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(nextlocation_pred.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff00ee58d914a26bd5860f26f78c1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/123539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad903222ee5416399212217de33ce01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/123539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178b221888d14626acf24c31de7f5d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/30885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f2676cd55c4736977135ab960ac6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/30885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss in episode 0: 6.2683917234751805\n",
      "Average training loss in episode 1: 4.742232066540678\n",
      "Average training loss in episode 2: 4.220941295308515\n",
      "Average training loss in episode 3: 3.9358672327246547\n",
      "Average training loss in episode 4: 3.7397250705514073\n",
      "Average training loss in episode 5: 3.5961661328954144\n",
      "Average training loss in episode 6: 3.4801360575620794\n",
      "Average training loss in episode 7: 3.38823694828128\n",
      "Average training loss in episode 8: 3.305245636908476\n",
      "Average training loss in episode 9: 3.23989734373802\n",
      "{'accuracy': 0.22379796017484216}\n",
      "Average training loss in episode 0: 7.007847854913759\n",
      "Average training loss in episode 1: 5.371428521211482\n",
      "Average training loss in episode 2: 4.630616056032418\n",
      "Average training loss in episode 3: 4.208322242271802\n",
      "Average training loss in episode 4: 3.923272815617648\n",
      "Average training loss in episode 5: 3.7201888344504614\n",
      "Average training loss in episode 6: 3.554557291929387\n",
      "Average training loss in episode 7: 3.4300487179401493\n",
      "Average training loss in episode 8: 3.320073540545692\n",
      "Average training loss in episode 9: 3.2232929970607285\n",
      "{'accuracy': 0.22389509470616803}\n",
      "Average training loss in episode 0: 6.918336346129741\n",
      "Average training loss in episode 1: 5.294326926065871\n",
      "Average training loss in episode 2: 4.577869322674333\n",
      "Average training loss in episode 3: 4.176272491778224\n",
      "Average training loss in episode 4: 3.906866460792289\n",
      "Average training loss in episode 5: 3.706249051842808\n",
      "Average training loss in episode 6: 3.5478444917142884\n",
      "Average training loss in episode 7: 3.4190413922317755\n",
      "Average training loss in episode 8: 3.3121756019671103\n",
      "Average training loss in episode 9: 3.2179376418925516\n",
      "{'accuracy': 0.22735955965679133}\n",
      "Average training loss in episode 0: 6.200944669975722\n",
      "Average training loss in episode 1: 4.674991424418678\n",
      "Average training loss in episode 2: 4.156577164476568\n",
      "Average training loss in episode 3: 3.85529058334256\n",
      "Average training loss in episode 4: 3.658902547576211\n",
      "Average training loss in episode 5: 3.5071448235472373\n",
      "Average training loss in episode 6: 3.383146968754855\n",
      "Average training loss in episode 7: 3.2776759350595395\n",
      "Average training loss in episode 8: 3.188526904287417\n",
      "Average training loss in episode 9: 3.1071624952899524\n",
      "{'accuracy': 0.23639307107009874}\n",
      "Average training loss in episode 0: 6.7243845502207105\n",
      "Average training loss in episode 1: 5.1345663208606815\n",
      "Average training loss in episode 2: 4.578179363376838\n",
      "Average training loss in episode 3: 4.2820696150961\n",
      "Average training loss in episode 4: 4.112245539988368\n",
      "Average training loss in episode 5: 3.9778335104303912\n",
      "Average training loss in episode 6: 3.8773331888451064\n",
      "Average training loss in episode 7: 3.811617039451914\n",
      "Average training loss in episode 8: 3.767630442114901\n",
      "Average training loss in episode 9: 3.7373755510188333\n",
      "{'accuracy': 0.2028169014084507}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "dest_pred = DestinationPrediciton(\n",
    "    traj_dataset=test,\n",
    "    network=network,\n",
    "    device=device,\n",
    "    batch_size=512,\n",
    "    epochs=10,\n",
    "    seed=88,\n",
    ")\n",
    "\n",
    "dest_pred.register_metric(\n",
    "    name=\"accuracy\",\n",
    "    metric_func=metrics.accuracy_score,\n",
    "    args={\"normalize\": True},\n",
    ")\n",
    "\n",
    "\n",
    "eva = [z, gtc.load_emb(), gae_emb, n2v_emb, rand_emb]\n",
    "for X in eva:\n",
    "    print(dest_pred.evaluate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

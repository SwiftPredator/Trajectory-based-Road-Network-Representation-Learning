{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SRN2VecModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"sf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRN2VecModel(None, device, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27039/27039 [05:20<00:00, 84.46it/s] \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.generate_data(n_shortest_paths=100, number_negative=3, window_size=900, save_batch_size=100, city=city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f model.extract_pairs model.generate_train_pairs(network, paths, 900, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"srn2vec-traindata-{city}.json\", \"r\") as fp:\n",
    "    a = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build and train model\n",
    "\"\"\"\n",
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRN2VecModel(None, device, network, remove_highway_label=True)\n",
    "model.load_dataset(f\"./srn2vec-traindata-{city}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, sample_loss: 0.7457817792892456, Avg. Loss: 0.7457817792892456\n",
      "Epoch: 0, Iteration: 1000, sample_loss: 0.52885502576828, Avg. Loss: 0.5871139772228904\n",
      "Epoch: 0, Iteration: 2000, sample_loss: 0.41753605008125305, Avg. Loss: 0.5420324301820942\n",
      "Epoch: 0, Iteration: 3000, sample_loss: 0.44189512729644775, Avg. Loss: 0.5227178169246198\n",
      "Epoch: 0, Iteration: 4000, sample_loss: 0.4610782861709595, Avg. Loss: 0.5124071226347032\n",
      "Epoch: 0, Iteration: 5000, sample_loss: 0.4362286627292633, Avg. Loss: 0.5063494576666027\n",
      "Epoch: 0, Iteration: 6000, sample_loss: 0.4377515912055969, Avg. Loss: 0.5021882874183785\n",
      "Epoch: 0, Iteration: 7000, sample_loss: 0.48308855295181274, Avg. Loss: 0.49940201709090326\n",
      "Epoch: 0, Iteration: 8000, sample_loss: 0.38562193512916565, Avg. Loss: 0.4971428117578051\n",
      "Epoch: 0, Iteration: 9000, sample_loss: 0.45629215240478516, Avg. Loss: 0.49559881924298216\n",
      "Epoch: 0, Iteration: 10000, sample_loss: 0.4468163549900055, Avg. Loss: 0.49399206595961515\n",
      "Epoch: 0, Iteration: 11000, sample_loss: 0.4506479501724243, Avg. Loss: 0.4928168561548312\n",
      "Epoch: 0, Iteration: 12000, sample_loss: 0.4472391605377197, Avg. Loss: 0.49179519423990686\n",
      "Epoch: 0, Iteration: 13000, sample_loss: 0.43483176827430725, Avg. Loss: 0.49088123393291677\n",
      "Epoch: 0, Iteration: 14000, sample_loss: 0.5140647888183594, Avg. Loss: 0.4902474503735629\n",
      "Epoch: 0, Iteration: 15000, sample_loss: 0.5168004631996155, Avg. Loss: 0.48959532764727065\n",
      "Epoch: 0, Iteration: 16000, sample_loss: 0.5133748650550842, Avg. Loss: 0.4888985452484499\n",
      "Epoch: 0, Iteration: 17000, sample_loss: 0.5199990272521973, Avg. Loss: 0.48818876332629746\n",
      "Epoch: 0, Iteration: 18000, sample_loss: 0.4654123783111572, Avg. Loss: 0.4871477264078794\n",
      "Epoch: 0, Iteration: 19000, sample_loss: 0.44683587551116943, Avg. Loss: 0.4858998008326075\n",
      "Epoch: 0, Iteration: 20000, sample_loss: 0.37103503942489624, Avg. Loss: 0.48411903318736105\n",
      "Epoch: 0, Iteration: 21000, sample_loss: 0.4570031762123108, Avg. Loss: 0.48161745931663874\n",
      "Epoch: 0, Iteration: 22000, sample_loss: 0.3794878423213959, Avg. Loss: 0.4784095345678711\n",
      "Epoch: 0, Iteration: 23000, sample_loss: 0.44944244623184204, Avg. Loss: 0.47423375357721614\n",
      "Epoch: 0, Iteration: 24000, sample_loss: 0.3545173704624176, Avg. Loss: 0.4693144191282947\n",
      "Epoch: 0, Iteration: 25000, sample_loss: 0.31352418661117554, Avg. Loss: 0.46321738108442445\n",
      "Epoch: 0, Iteration: 26000, sample_loss: 0.28037792444229126, Avg. Loss: 0.4560603973337203\n",
      "Epoch: 0, Iteration: 27000, sample_loss: 0.24080434441566467, Avg. Loss: 0.44805212708520586\n",
      "Epoch: 0, Iteration: 28000, sample_loss: 0.16865284740924835, Avg. Loss: 0.43925248303150205\n",
      "Epoch: 0, Iteration: 29000, sample_loss: 0.11556389927864075, Avg. Loss: 0.4298514689251943\n",
      "Epoch: 0, Iteration: 30000, sample_loss: 0.15715749561786652, Avg. Loss: 0.42008662170707467\n",
      "Epoch: 0, Iteration: 31000, sample_loss: 0.0860152542591095, Avg. Loss: 0.41015349850546434\n",
      "Epoch: 0, Iteration: 32000, sample_loss: 0.058776840567588806, Avg. Loss: 0.400205770271663\n",
      "Epoch: 0, Iteration: 33000, sample_loss: 0.061218660324811935, Avg. Loss: 0.3903934907570356\n",
      "Epoch: 0, Iteration: 34000, sample_loss: 0.09602996706962585, Avg. Loss: 0.3808456899215369\n",
      "Epoch: 0, Iteration: 35000, sample_loss: 0.03613051027059555, Avg. Loss: 0.3715567127412329\n",
      "Epoch: 0, Iteration: 36000, sample_loss: 0.0704389438033104, Avg. Loss: 0.3625502477919384\n",
      "Epoch: 0, Iteration: 37000, sample_loss: 0.10046286880970001, Avg. Loss: 0.3539005206166258\n",
      "Epoch: 0, Iteration: 38000, sample_loss: 0.01742776297032833, Avg. Loss: 0.3455391166329689\n",
      "Epoch: 0, Iteration: 39000, sample_loss: 0.025493523105978966, Avg. Loss: 0.33751874228564555\n",
      "Epoch: 0, Iteration: 40000, sample_loss: 0.01701008528470993, Avg. Loss: 0.3298105098228927\n",
      "Epoch: 0, Iteration: 41000, sample_loss: 0.01149784680455923, Avg. Loss: 0.32236489792632683\n",
      "Epoch: 0, Iteration: 42000, sample_loss: 0.01595156267285347, Avg. Loss: 0.31520459335256323\n",
      "Epoch: 0, Iteration: 43000, sample_loss: 0.016796108335256577, Avg. Loss: 0.3083328108546481\n",
      "Epoch: 0, Iteration: 44000, sample_loss: 0.028833966702222824, Avg. Loss: 0.30168326186373146\n",
      "Epoch: 0, Iteration: 45000, sample_loss: 0.044136956334114075, Avg. Loss: 0.2952978238177363\n",
      "Epoch: 0, Iteration: 46000, sample_loss: 0.014269831590354443, Avg. Loss: 0.28914849874863\n",
      "Epoch: 0, Iteration: 47000, sample_loss: 0.0026107642333954573, Avg. Loss: 0.28323773108702643\n",
      "Epoch: 0, Iteration: 48000, sample_loss: 0.0022626854479312897, Avg. Loss: 0.2775344220554786\n",
      "Epoch: 0, Iteration: 49000, sample_loss: 0.00281479861587286, Avg. Loss: 0.2720276222627134\n",
      "Epoch: 0, Iteration: 50000, sample_loss: 0.0010379715822637081, Avg. Loss: 0.2667300515096351\n",
      "Epoch: 0, Iteration: 51000, sample_loss: 0.0006332005141302943, Avg. Loss: 0.26163237347948637\n",
      "Epoch: 0, Iteration: 52000, sample_loss: 0.00184909556992352, Avg. Loss: 0.25671360848245184\n",
      "Epoch: 0, Iteration: 53000, sample_loss: 0.004179863724857569, Avg. Loss: 0.25196262513919504\n",
      "Epoch: 0, Iteration: 54000, sample_loss: 0.0019094757735729218, Avg. Loss: 0.2473863726125652\n",
      "Epoch: 0, Iteration: 55000, sample_loss: 0.0006679963553324342, Avg. Loss: 0.2429759610330888\n",
      "Epoch: 0, Iteration: 56000, sample_loss: 0.00036238384200260043, Avg. Loss: 0.23870488428175976\n",
      "Epoch: 0, Iteration: 57000, sample_loss: 0.0005531952483579516, Avg. Loss: 0.2345859967329097\n",
      "Epoch: 0, Iteration: 58000, sample_loss: 0.0007027898682281375, Avg. Loss: 0.23059787737397897\n",
      "Epoch: 0, Iteration: 59000, sample_loss: 0.0005078075919300318, Avg. Loss: 0.22674553127299496\n",
      "Epoch: 0, Iteration: 60000, sample_loss: 0.00036241894122213125, Avg. Loss: 0.22302063009648904\n",
      "Epoch: 0, Iteration: 61000, sample_loss: 0.000487540295580402, Avg. Loss: 0.21940924853851387\n",
      "Average training loss in episode 0: 0.21751470101009995\n",
      "Epoch: 1, Iteration: 0, sample_loss: 0.0005182367749512196, Avg. Loss: 0.0005182367749512196\n",
      "Epoch: 1, Iteration: 1000, sample_loss: 0.0001871186977950856, Avg. Loss: 0.002843876560304112\n",
      "Epoch: 1, Iteration: 2000, sample_loss: 0.0001844218058977276, Avg. Loss: 0.0026190653354541443\n",
      "Epoch: 1, Iteration: 3000, sample_loss: 0.000669972796458751, Avg. Loss: 0.002581825523586282\n",
      "Epoch: 1, Iteration: 4000, sample_loss: 0.0014907184522598982, Avg. Loss: 0.0024661540968351444\n",
      "Epoch: 1, Iteration: 5000, sample_loss: 0.0003183541411999613, Avg. Loss: 0.0023804724095713168\n",
      "Epoch: 1, Iteration: 6000, sample_loss: 0.00014720506442245096, Avg. Loss: 0.0023445874785049223\n",
      "Epoch: 1, Iteration: 7000, sample_loss: 0.0004183723358437419, Avg. Loss: 0.002308413024112176\n",
      "Epoch: 1, Iteration: 8000, sample_loss: 0.0003015508991666138, Avg. Loss: 0.0022614860589462906\n",
      "Epoch: 1, Iteration: 9000, sample_loss: 0.00012553538545034826, Avg. Loss: 0.002234689306826181\n",
      "Epoch: 1, Iteration: 10000, sample_loss: 0.0003172780270688236, Avg. Loss: 0.0022239671518532074\n",
      "Epoch: 1, Iteration: 11000, sample_loss: 0.0004415346775203943, Avg. Loss: 0.0022133976257204457\n",
      "Epoch: 1, Iteration: 12000, sample_loss: 0.00021190692496020347, Avg. Loss: 0.002186119625477968\n",
      "Epoch: 1, Iteration: 13000, sample_loss: 0.00020283021149225533, Avg. Loss: 0.002200877676125491\n",
      "Epoch: 1, Iteration: 14000, sample_loss: 0.0004146612191107124, Avg. Loss: 0.00219207362232057\n",
      "Epoch: 1, Iteration: 15000, sample_loss: 0.00015646622341591865, Avg. Loss: 0.0021727782647322693\n",
      "Epoch: 1, Iteration: 16000, sample_loss: 0.0006049072835594416, Avg. Loss: 0.0021917467691365683\n",
      "Epoch: 1, Iteration: 17000, sample_loss: 0.0004569355514831841, Avg. Loss: 0.0022040277559183955\n",
      "Epoch: 1, Iteration: 18000, sample_loss: 0.00028759328415617347, Avg. Loss: 0.0022001253693523536\n",
      "Epoch: 1, Iteration: 19000, sample_loss: 0.00020825093088205904, Avg. Loss: 0.002192564321798346\n",
      "Epoch: 1, Iteration: 20000, sample_loss: 0.00019252010679338127, Avg. Loss: 0.0022030562722813547\n",
      "Epoch: 1, Iteration: 21000, sample_loss: 0.00019753520609810948, Avg. Loss: 0.0022024436048853468\n",
      "Epoch: 1, Iteration: 22000, sample_loss: 0.00020998531545046717, Avg. Loss: 0.002188974578354654\n",
      "Epoch: 1, Iteration: 23000, sample_loss: 0.03141571953892708, Avg. Loss: 0.0021833395330427083\n",
      "Epoch: 1, Iteration: 24000, sample_loss: 0.0003249573346693069, Avg. Loss: 0.0021864483942903973\n",
      "Epoch: 1, Iteration: 25000, sample_loss: 0.000304798741126433, Avg. Loss: 0.00218698744644283\n",
      "Epoch: 1, Iteration: 26000, sample_loss: 0.00022803967294748873, Avg. Loss: 0.002176365594793712\n",
      "Epoch: 1, Iteration: 27000, sample_loss: 0.00010108761489391327, Avg. Loss: 0.0021686572475781533\n",
      "Epoch: 1, Iteration: 28000, sample_loss: 0.0005253618583083153, Avg. Loss: 0.0021783246051119286\n",
      "Epoch: 1, Iteration: 29000, sample_loss: 0.0002824906259775162, Avg. Loss: 0.0021675114358226414\n",
      "Epoch: 1, Iteration: 30000, sample_loss: 0.00034323331783525646, Avg. Loss: 0.002166535996344465\n",
      "Epoch: 1, Iteration: 31000, sample_loss: 0.0005089419428259134, Avg. Loss: 0.002167054454754384\n",
      "Epoch: 1, Iteration: 32000, sample_loss: 0.00016501186473760754, Avg. Loss: 0.0021595998008909754\n",
      "Epoch: 1, Iteration: 33000, sample_loss: 0.00040474371053278446, Avg. Loss: 0.0021543263214541856\n",
      "Epoch: 1, Iteration: 34000, sample_loss: 0.00036871200427412987, Avg. Loss: 0.0021509790812503328\n",
      "Epoch: 1, Iteration: 35000, sample_loss: 0.00027093489188700914, Avg. Loss: 0.0021426236289056\n",
      "Epoch: 1, Iteration: 36000, sample_loss: 0.0001744620531098917, Avg. Loss: 0.0021290320148584355\n",
      "Epoch: 1, Iteration: 37000, sample_loss: 0.0002193519612774253, Avg. Loss: 0.002116017367356993\n",
      "Epoch: 1, Iteration: 38000, sample_loss: 0.00011900857498403639, Avg. Loss: 0.002119371549290917\n",
      "Epoch: 1, Iteration: 39000, sample_loss: 0.00029383960645645857, Avg. Loss: 0.0021172773202478793\n",
      "Epoch: 1, Iteration: 40000, sample_loss: 0.0002490596380084753, Avg. Loss: 0.0021151804910606925\n",
      "Epoch: 1, Iteration: 41000, sample_loss: 0.0004099333891645074, Avg. Loss: 0.002113752122446588\n",
      "Epoch: 1, Iteration: 42000, sample_loss: 0.00015330026508308947, Avg. Loss: 0.0021164597029536074\n",
      "Epoch: 1, Iteration: 43000, sample_loss: 0.00017823645612224936, Avg. Loss: 0.0021106059963870694\n",
      "Epoch: 1, Iteration: 44000, sample_loss: 0.0001565745478728786, Avg. Loss: 0.002098027736132461\n",
      "Epoch: 1, Iteration: 45000, sample_loss: 0.0001391420664731413, Avg. Loss: 0.0020954403330654507\n",
      "Epoch: 1, Iteration: 46000, sample_loss: 0.0004728456260636449, Avg. Loss: 0.0020967776179052723\n",
      "Epoch: 1, Iteration: 47000, sample_loss: 0.00022297841496765614, Avg. Loss: 0.0020947269045902815\n",
      "Epoch: 1, Iteration: 48000, sample_loss: 0.00020190162467770278, Avg. Loss: 0.0020937115344163942\n",
      "Epoch: 1, Iteration: 49000, sample_loss: 0.00014999879931565374, Avg. Loss: 0.002092023928347719\n",
      "Epoch: 1, Iteration: 50000, sample_loss: 0.000283901987131685, Avg. Loss: 0.002086921648188901\n",
      "Epoch: 1, Iteration: 51000, sample_loss: 0.00027609936660155654, Avg. Loss: 0.0020832740194918157\n",
      "Epoch: 1, Iteration: 52000, sample_loss: 0.00011332432040944695, Avg. Loss: 0.0020830223693396525\n",
      "Epoch: 1, Iteration: 53000, sample_loss: 0.0001365098578389734, Avg. Loss: 0.0020793639377070083\n",
      "Epoch: 1, Iteration: 54000, sample_loss: 0.00026139989495277405, Avg. Loss: 0.0020790258405460425\n",
      "Epoch: 1, Iteration: 55000, sample_loss: 0.00013553554890677333, Avg. Loss: 0.0020703028764393547\n",
      "Epoch: 1, Iteration: 56000, sample_loss: 0.00012294187035877258, Avg. Loss: 0.002067715386382876\n",
      "Epoch: 1, Iteration: 57000, sample_loss: 0.00024464968009851873, Avg. Loss: 0.0020625705916100376\n",
      "Epoch: 1, Iteration: 58000, sample_loss: 0.0001964837865671143, Avg. Loss: 0.002056152591326585\n",
      "Epoch: 1, Iteration: 59000, sample_loss: 0.00010464197839610279, Avg. Loss: 0.002048741884571452\n",
      "Epoch: 1, Iteration: 60000, sample_loss: 0.00033007151796482503, Avg. Loss: 0.002046702025235158\n",
      "Epoch: 1, Iteration: 61000, sample_loss: 0.00031698402017354965, Avg. Loss: 0.0020487197247926955\n",
      "Average training loss in episode 1: 0.002044370081662649\n",
      "Epoch: 2, Iteration: 0, sample_loss: 0.00018035982793662697, Avg. Loss: 0.00018035982793662697\n",
      "Epoch: 2, Iteration: 1000, sample_loss: 0.00011036371870432049, Avg. Loss: 0.0015921443123656505\n",
      "Epoch: 2, Iteration: 2000, sample_loss: 0.00018660823116078973, Avg. Loss: 0.001580907437565638\n",
      "Epoch: 2, Iteration: 3000, sample_loss: 0.0002632071846164763, Avg. Loss: 0.0016489042331372962\n",
      "Epoch: 2, Iteration: 4000, sample_loss: 0.00018553054542280734, Avg. Loss: 0.0016740593468499698\n",
      "Epoch: 2, Iteration: 5000, sample_loss: 0.0007930147694423795, Avg. Loss: 0.0016470128449600214\n",
      "Epoch: 2, Iteration: 6000, sample_loss: 0.0001864402584033087, Avg. Loss: 0.001635472339949853\n",
      "Epoch: 2, Iteration: 7000, sample_loss: 0.00015026345499791205, Avg. Loss: 0.0016707855230298535\n",
      "Epoch: 2, Iteration: 8000, sample_loss: 0.00030515252728946507, Avg. Loss: 0.0016726306996339164\n",
      "Epoch: 2, Iteration: 9000, sample_loss: 0.00012762162077706307, Avg. Loss: 0.0016983980846733285\n",
      "Epoch: 2, Iteration: 10000, sample_loss: 0.00013944419333711267, Avg. Loss: 0.0017272027575324107\n",
      "Epoch: 2, Iteration: 11000, sample_loss: 0.00017840086366049945, Avg. Loss: 0.0017091503199968385\n",
      "Epoch: 2, Iteration: 12000, sample_loss: 0.0005927033489570022, Avg. Loss: 0.0016967292813565079\n",
      "Epoch: 2, Iteration: 13000, sample_loss: 0.020616330206394196, Avg. Loss: 0.0017438127750138781\n",
      "Epoch: 2, Iteration: 14000, sample_loss: 0.0003902860335074365, Avg. Loss: 0.0017491777812347524\n",
      "Epoch: 2, Iteration: 15000, sample_loss: 0.00020568049512803555, Avg. Loss: 0.0017451368685346695\n",
      "Epoch: 2, Iteration: 16000, sample_loss: 0.0001358079316560179, Avg. Loss: 0.001757828447813949\n",
      "Epoch: 2, Iteration: 17000, sample_loss: 0.0003214437165297568, Avg. Loss: 0.0017651646349866117\n",
      "Epoch: 2, Iteration: 18000, sample_loss: 0.00019773849635384977, Avg. Loss: 0.0017541968355915469\n",
      "Epoch: 2, Iteration: 19000, sample_loss: 0.00023459440853912383, Avg. Loss: 0.001758993138399051\n",
      "Epoch: 2, Iteration: 20000, sample_loss: 0.00022540245845448226, Avg. Loss: 0.0017530794649030178\n",
      "Epoch: 2, Iteration: 21000, sample_loss: 0.00020748702809214592, Avg. Loss: 0.0017539522213509875\n",
      "Epoch: 2, Iteration: 22000, sample_loss: 0.00020324686192907393, Avg. Loss: 0.001738900863767939\n",
      "Epoch: 2, Iteration: 23000, sample_loss: 0.00014275172725319862, Avg. Loss: 0.0017524232914595953\n",
      "Epoch: 2, Iteration: 24000, sample_loss: 0.00017565212328918278, Avg. Loss: 0.0017485567797891233\n",
      "Epoch: 2, Iteration: 25000, sample_loss: 0.00011939492105739191, Avg. Loss: 0.001747569288775654\n",
      "Epoch: 2, Iteration: 26000, sample_loss: 0.01756639964878559, Avg. Loss: 0.0017602189943309791\n",
      "Epoch: 2, Iteration: 27000, sample_loss: 0.0001488600391894579, Avg. Loss: 0.0017627488476887811\n",
      "Epoch: 2, Iteration: 28000, sample_loss: 0.00015897619596216828, Avg. Loss: 0.0017579487031410105\n",
      "Epoch: 2, Iteration: 29000, sample_loss: 0.00011701590119628236, Avg. Loss: 0.0017438820877383372\n",
      "Epoch: 2, Iteration: 30000, sample_loss: 0.030870480462908745, Avg. Loss: 0.001761959364387415\n",
      "Epoch: 2, Iteration: 31000, sample_loss: 0.0007021423080004752, Avg. Loss: 0.0017687232822892135\n",
      "Epoch: 2, Iteration: 32000, sample_loss: 0.0005110737984068692, Avg. Loss: 0.0017758999620501174\n",
      "Epoch: 2, Iteration: 33000, sample_loss: 0.021741939708590508, Avg. Loss: 0.0017733793816381664\n",
      "Epoch: 2, Iteration: 34000, sample_loss: 0.00032351346453651786, Avg. Loss: 0.00176772080523915\n",
      "Epoch: 2, Iteration: 35000, sample_loss: 0.0004727223131339997, Avg. Loss: 0.0017718938590702696\n",
      "Epoch: 2, Iteration: 36000, sample_loss: 0.00017706894141156226, Avg. Loss: 0.0017683242469740833\n",
      "Epoch: 2, Iteration: 37000, sample_loss: 0.0001932514423970133, Avg. Loss: 0.0017644581960893295\n",
      "Epoch: 2, Iteration: 38000, sample_loss: 0.0001560106175020337, Avg. Loss: 0.0017754205004036285\n",
      "Epoch: 2, Iteration: 39000, sample_loss: 0.0002274802391184494, Avg. Loss: 0.001782791186691619\n",
      "Epoch: 2, Iteration: 40000, sample_loss: 0.00039642193587496877, Avg. Loss: 0.001784078072234177\n",
      "Epoch: 2, Iteration: 41000, sample_loss: 0.0009681591764092445, Avg. Loss: 0.0017923454003179128\n",
      "Epoch: 2, Iteration: 42000, sample_loss: 0.0001795073039829731, Avg. Loss: 0.001802916061720122\n",
      "Epoch: 2, Iteration: 43000, sample_loss: 0.00017578942060936242, Avg. Loss: 0.001798963952690451\n",
      "Epoch: 2, Iteration: 44000, sample_loss: 0.00019673880888149142, Avg. Loss: 0.0018017705183347166\n",
      "Epoch: 2, Iteration: 45000, sample_loss: 0.0001500929065514356, Avg. Loss: 0.0018019917404149815\n",
      "Epoch: 2, Iteration: 46000, sample_loss: 0.00011730296682799235, Avg. Loss: 0.0018058208441365778\n",
      "Epoch: 2, Iteration: 47000, sample_loss: 0.00012966110080014914, Avg. Loss: 0.0018085593352880353\n",
      "Epoch: 2, Iteration: 48000, sample_loss: 6.701725942548364e-05, Avg. Loss: 0.0017973225703609807\n",
      "Epoch: 2, Iteration: 49000, sample_loss: 0.00026771568809635937, Avg. Loss: 0.0018035038822324066\n",
      "Epoch: 2, Iteration: 50000, sample_loss: 0.00043469032971188426, Avg. Loss: 0.001804640732302521\n",
      "Epoch: 2, Iteration: 51000, sample_loss: 0.0001174919234472327, Avg. Loss: 0.0018055638179942813\n",
      "Epoch: 2, Iteration: 52000, sample_loss: 0.00014762961654923856, Avg. Loss: 0.001802660459818727\n",
      "Epoch: 2, Iteration: 53000, sample_loss: 0.0005349621642380953, Avg. Loss: 0.0018059216228695596\n",
      "Epoch: 2, Iteration: 54000, sample_loss: 0.0008433286566287279, Avg. Loss: 0.0018051078430653966\n",
      "Epoch: 2, Iteration: 55000, sample_loss: 0.00017138691328000277, Avg. Loss: 0.0018042761516395753\n",
      "Epoch: 2, Iteration: 56000, sample_loss: 9.60837205639109e-05, Avg. Loss: 0.001803803955339177\n",
      "Epoch: 2, Iteration: 57000, sample_loss: 0.00012792079360224307, Avg. Loss: 0.001801043031900252\n",
      "Epoch: 2, Iteration: 58000, sample_loss: 0.0005286931409500539, Avg. Loss: 0.001796233621819967\n",
      "Epoch: 2, Iteration: 59000, sample_loss: 0.0001287228660658002, Avg. Loss: 0.0017995285131026959\n",
      "Epoch: 2, Iteration: 60000, sample_loss: 0.0002159018476959318, Avg. Loss: 0.0018033661953544813\n",
      "Epoch: 2, Iteration: 61000, sample_loss: 0.00045807252172380686, Avg. Loss: 0.001805189031296438\n",
      "Average training loss in episode 2: 0.0018034506156518154\n",
      "Epoch: 3, Iteration: 0, sample_loss: 0.0006418728735297918, Avg. Loss: 0.0006418728735297918\n",
      "Epoch: 3, Iteration: 1000, sample_loss: 9.288977889809757e-05, Avg. Loss: 0.001781989325503706\n",
      "Epoch: 3, Iteration: 2000, sample_loss: 0.0002847035357262939, Avg. Loss: 0.0017193313303715773\n",
      "Epoch: 3, Iteration: 3000, sample_loss: 0.0002575713733676821, Avg. Loss: 0.0017477684068108077\n",
      "Epoch: 3, Iteration: 4000, sample_loss: 0.023102328181266785, Avg. Loss: 0.001723506408000016\n",
      "Epoch: 3, Iteration: 5000, sample_loss: 8.246538345701993e-05, Avg. Loss: 0.0016580653612352234\n",
      "Epoch: 3, Iteration: 6000, sample_loss: 0.00022724343580193818, Avg. Loss: 0.001632713940480791\n",
      "Epoch: 3, Iteration: 7000, sample_loss: 0.0003443704335950315, Avg. Loss: 0.0016399705279921575\n",
      "Epoch: 3, Iteration: 8000, sample_loss: 0.0004477205511648208, Avg. Loss: 0.001685992854469778\n",
      "Epoch: 3, Iteration: 9000, sample_loss: 0.00018343006377108395, Avg. Loss: 0.0017161419900299378\n",
      "Epoch: 3, Iteration: 10000, sample_loss: 0.00021895299141760916, Avg. Loss: 0.001721970545635521\n",
      "Epoch: 3, Iteration: 11000, sample_loss: 0.0007825909415259957, Avg. Loss: 0.001719459503330869\n",
      "Epoch: 3, Iteration: 12000, sample_loss: 0.00011936754890484735, Avg. Loss: 0.00170984576976862\n",
      "Epoch: 3, Iteration: 13000, sample_loss: 0.0005886797443963587, Avg. Loss: 0.0017108866941479585\n",
      "Epoch: 3, Iteration: 14000, sample_loss: 0.00026787412934936583, Avg. Loss: 0.00173391450890968\n",
      "Epoch: 3, Iteration: 15000, sample_loss: 0.00031769578345119953, Avg. Loss: 0.0017132829145303915\n",
      "Epoch: 3, Iteration: 16000, sample_loss: 0.00031951686833053827, Avg. Loss: 0.0017153141766439997\n",
      "Epoch: 3, Iteration: 17000, sample_loss: 9.86052182270214e-05, Avg. Loss: 0.0017461585403368758\n",
      "Epoch: 3, Iteration: 18000, sample_loss: 0.0002100152341881767, Avg. Loss: 0.0017407665830578825\n",
      "Epoch: 3, Iteration: 19000, sample_loss: 0.00013535108882933855, Avg. Loss: 0.0017568576797708539\n",
      "Epoch: 3, Iteration: 20000, sample_loss: 0.00011197324056411162, Avg. Loss: 0.0017571379889065424\n",
      "Epoch: 3, Iteration: 21000, sample_loss: 0.0009008970810100436, Avg. Loss: 0.0017588349689360307\n",
      "Epoch: 3, Iteration: 22000, sample_loss: 0.0004640780098270625, Avg. Loss: 0.0017559597635434527\n",
      "Epoch: 3, Iteration: 23000, sample_loss: 0.0002895522047765553, Avg. Loss: 0.0017558199368852205\n",
      "Epoch: 3, Iteration: 24000, sample_loss: 4.029521005577408e-05, Avg. Loss: 0.0017483451878987177\n",
      "Epoch: 3, Iteration: 25000, sample_loss: 0.00016628620505798608, Avg. Loss: 0.0017536688267738535\n",
      "Epoch: 3, Iteration: 26000, sample_loss: 0.0001082768285414204, Avg. Loss: 0.001749262196295294\n",
      "Epoch: 3, Iteration: 27000, sample_loss: 9.740353561937809e-05, Avg. Loss: 0.0017497153897230418\n",
      "Epoch: 3, Iteration: 28000, sample_loss: 0.0001975112536456436, Avg. Loss: 0.0017454133011599782\n",
      "Epoch: 3, Iteration: 29000, sample_loss: 4.737138078780845e-05, Avg. Loss: 0.0017423013637429552\n",
      "Epoch: 3, Iteration: 30000, sample_loss: 0.0006222344236448407, Avg. Loss: 0.001737950278316278\n",
      "Epoch: 3, Iteration: 31000, sample_loss: 0.00017482208204455674, Avg. Loss: 0.0017434260764528802\n",
      "Epoch: 3, Iteration: 32000, sample_loss: 0.01723683439195156, Avg. Loss: 0.0017445469303264333\n",
      "Epoch: 3, Iteration: 33000, sample_loss: 0.00011539558181539178, Avg. Loss: 0.0017401910293772538\n",
      "Epoch: 3, Iteration: 34000, sample_loss: 0.020672379061579704, Avg. Loss: 0.0017425639155750716\n",
      "Epoch: 3, Iteration: 35000, sample_loss: 0.0005913203349336982, Avg. Loss: 0.0017493238525951404\n",
      "Epoch: 3, Iteration: 36000, sample_loss: 0.0006180254276841879, Avg. Loss: 0.001751028300011552\n",
      "Epoch: 3, Iteration: 37000, sample_loss: 0.0006645743269473314, Avg. Loss: 0.0017597783469825187\n",
      "Epoch: 3, Iteration: 38000, sample_loss: 0.00014721548359375447, Avg. Loss: 0.001757459054696196\n",
      "Epoch: 3, Iteration: 39000, sample_loss: 0.00016277359100058675, Avg. Loss: 0.0017539300724807058\n",
      "Epoch: 3, Iteration: 40000, sample_loss: 0.00021217233734205365, Avg. Loss: 0.0017585534894956761\n",
      "Epoch: 3, Iteration: 41000, sample_loss: 0.020640358328819275, Avg. Loss: 0.0017549920479580647\n",
      "Epoch: 3, Iteration: 42000, sample_loss: 0.00011314766015857458, Avg. Loss: 0.0017470508144168332\n",
      "Epoch: 3, Iteration: 43000, sample_loss: 0.00015894853277131915, Avg. Loss: 0.0017373344964866525\n",
      "Epoch: 3, Iteration: 44000, sample_loss: 3.9771159208612517e-05, Avg. Loss: 0.0017338756485828788\n",
      "Epoch: 3, Iteration: 45000, sample_loss: 0.0003786930174101144, Avg. Loss: 0.0017376407492694706\n",
      "Epoch: 3, Iteration: 46000, sample_loss: 0.00018979118613060564, Avg. Loss: 0.0017355256436916546\n",
      "Epoch: 3, Iteration: 47000, sample_loss: 0.0001090778605430387, Avg. Loss: 0.0017420237170406188\n",
      "Epoch: 3, Iteration: 48000, sample_loss: 0.000885202141944319, Avg. Loss: 0.0017452413526549717\n",
      "Epoch: 3, Iteration: 49000, sample_loss: 0.00015508715296164155, Avg. Loss: 0.0017364469850840278\n",
      "Epoch: 3, Iteration: 50000, sample_loss: 0.02327326498925686, Avg. Loss: 0.0017369234043487516\n",
      "Epoch: 3, Iteration: 51000, sample_loss: 0.00025211498723365366, Avg. Loss: 0.0017335652959847606\n",
      "Epoch: 3, Iteration: 52000, sample_loss: 0.000137237278977409, Avg. Loss: 0.0017352016894954128\n",
      "Epoch: 3, Iteration: 53000, sample_loss: 0.00021940423175692558, Avg. Loss: 0.0017408197758879216\n",
      "Epoch: 3, Iteration: 54000, sample_loss: 0.00013490859419107437, Avg. Loss: 0.0017439762217246466\n",
      "Epoch: 3, Iteration: 55000, sample_loss: 0.00018705616821534932, Avg. Loss: 0.0017559013838938167\n",
      "Epoch: 3, Iteration: 56000, sample_loss: 9.274800686398521e-05, Avg. Loss: 0.0017657271706621417\n",
      "Epoch: 3, Iteration: 57000, sample_loss: 0.02915167436003685, Avg. Loss: 0.001774779006768677\n",
      "Epoch: 3, Iteration: 58000, sample_loss: 0.00011466852447483689, Avg. Loss: 0.0017740769170173165\n",
      "Epoch: 3, Iteration: 59000, sample_loss: 0.00016038515605032444, Avg. Loss: 0.0017725039755315684\n",
      "Epoch: 3, Iteration: 60000, sample_loss: 0.0008552033104933798, Avg. Loss: 0.0017687111602836783\n",
      "Epoch: 3, Iteration: 61000, sample_loss: 0.00017491077596787363, Avg. Loss: 0.0017689503681164243\n",
      "Average training loss in episode 3: 0.001770355886860409\n",
      "Epoch: 4, Iteration: 0, sample_loss: 0.00022481419728137553, Avg. Loss: 0.00022481419728137553\n",
      "Epoch: 4, Iteration: 1000, sample_loss: 0.00026168074691668153, Avg. Loss: 0.001639753432193736\n",
      "Epoch: 4, Iteration: 2000, sample_loss: 0.00011246999201830477, Avg. Loss: 0.0018596428011581415\n",
      "Epoch: 4, Iteration: 3000, sample_loss: 0.00026104983408004045, Avg. Loss: 0.0017815610339001779\n",
      "Epoch: 4, Iteration: 4000, sample_loss: 0.0003680911613628268, Avg. Loss: 0.0017820796583441795\n",
      "Epoch: 4, Iteration: 5000, sample_loss: 0.00017255968123208731, Avg. Loss: 0.0017884621823502436\n",
      "Epoch: 4, Iteration: 6000, sample_loss: 0.00045808026334270835, Avg. Loss: 0.0017571828652822499\n",
      "Epoch: 4, Iteration: 7000, sample_loss: 0.00034329539630562067, Avg. Loss: 0.0017587958591133714\n",
      "Epoch: 4, Iteration: 8000, sample_loss: 9.195364691549912e-05, Avg. Loss: 0.0017170224822588812\n",
      "Epoch: 4, Iteration: 9000, sample_loss: 0.0006713746697641909, Avg. Loss: 0.0017459053443596108\n",
      "Epoch: 4, Iteration: 10000, sample_loss: 0.00010816051508300006, Avg. Loss: 0.0017424242804899297\n",
      "Epoch: 4, Iteration: 11000, sample_loss: 0.01473168097436428, Avg. Loss: 0.0017250058987480477\n",
      "Epoch: 4, Iteration: 12000, sample_loss: 0.0012439602287486196, Avg. Loss: 0.0017329654382848936\n",
      "Epoch: 4, Iteration: 13000, sample_loss: 0.0004526343836914748, Avg. Loss: 0.0017159697705412171\n",
      "Epoch: 4, Iteration: 14000, sample_loss: 0.00035615460365079343, Avg. Loss: 0.0017085842906337746\n",
      "Epoch: 4, Iteration: 15000, sample_loss: 0.0005079442635178566, Avg. Loss: 0.0017007388655042672\n",
      "Epoch: 4, Iteration: 16000, sample_loss: 8.533880463801324e-05, Avg. Loss: 0.001687554984820831\n",
      "Epoch: 4, Iteration: 17000, sample_loss: 0.0005914607318118215, Avg. Loss: 0.001704619196878845\n",
      "Epoch: 4, Iteration: 18000, sample_loss: 0.00034648150904104114, Avg. Loss: 0.001715424977287658\n",
      "Epoch: 4, Iteration: 19000, sample_loss: 0.00014433718752115965, Avg. Loss: 0.0017149275960165852\n",
      "Epoch: 4, Iteration: 20000, sample_loss: 8.573397644795477e-05, Avg. Loss: 0.001704588009542792\n",
      "Epoch: 4, Iteration: 21000, sample_loss: 0.0002877084771171212, Avg. Loss: 0.0017077932418870924\n",
      "Epoch: 4, Iteration: 22000, sample_loss: 9.021219011629e-05, Avg. Loss: 0.0016965349830161047\n",
      "Epoch: 4, Iteration: 23000, sample_loss: 0.00031732150819152594, Avg. Loss: 0.00170861874847867\n",
      "Epoch: 4, Iteration: 24000, sample_loss: 0.0002304114168509841, Avg. Loss: 0.0017121976590875564\n",
      "Epoch: 4, Iteration: 25000, sample_loss: 0.0004276398103684187, Avg. Loss: 0.0017114936293374805\n",
      "Epoch: 4, Iteration: 26000, sample_loss: 4.624745270120911e-05, Avg. Loss: 0.0017107228904154098\n",
      "Epoch: 4, Iteration: 27000, sample_loss: 0.0001252075016964227, Avg. Loss: 0.0017053041799545855\n",
      "Epoch: 4, Iteration: 28000, sample_loss: 0.00020529102766886353, Avg. Loss: 0.00171609237548685\n",
      "Epoch: 4, Iteration: 29000, sample_loss: 0.00011585249740164727, Avg. Loss: 0.0017157588922224066\n",
      "Epoch: 4, Iteration: 30000, sample_loss: 0.0004322674940340221, Avg. Loss: 0.00171381540542194\n",
      "Epoch: 4, Iteration: 31000, sample_loss: 0.0003798328689299524, Avg. Loss: 0.0017155720447495377\n",
      "Epoch: 4, Iteration: 32000, sample_loss: 0.00010795034904731438, Avg. Loss: 0.001720828023124033\n",
      "Epoch: 4, Iteration: 33000, sample_loss: 0.00011853935575345531, Avg. Loss: 0.0017273232043427179\n",
      "Epoch: 4, Iteration: 34000, sample_loss: 0.00021303676476236433, Avg. Loss: 0.0017291212230484616\n",
      "Epoch: 4, Iteration: 35000, sample_loss: 9.438514825887978e-05, Avg. Loss: 0.0017206491957940384\n",
      "Epoch: 4, Iteration: 36000, sample_loss: 0.00014464640116784722, Avg. Loss: 0.0017268053357178883\n",
      "Epoch: 4, Iteration: 37000, sample_loss: 0.00020149446208961308, Avg. Loss: 0.0017281783722125751\n",
      "Epoch: 4, Iteration: 38000, sample_loss: 0.0003502007166389376, Avg. Loss: 0.001731174072989785\n",
      "Epoch: 4, Iteration: 39000, sample_loss: 0.00034780794521793723, Avg. Loss: 0.0017338068277289492\n",
      "Epoch: 4, Iteration: 40000, sample_loss: 0.0003065790224354714, Avg. Loss: 0.001736798178365502\n",
      "Epoch: 4, Iteration: 41000, sample_loss: 0.0008726185187697411, Avg. Loss: 0.0017341535390367356\n",
      "Epoch: 4, Iteration: 42000, sample_loss: 0.0002112147631123662, Avg. Loss: 0.001728839798926824\n",
      "Epoch: 4, Iteration: 43000, sample_loss: 0.00025835540145635605, Avg. Loss: 0.0017308767126128837\n",
      "Epoch: 4, Iteration: 44000, sample_loss: 8.571488433517516e-05, Avg. Loss: 0.0017329761011413817\n",
      "Epoch: 4, Iteration: 45000, sample_loss: 0.00026954177883453667, Avg. Loss: 0.0017323704692954157\n",
      "Epoch: 4, Iteration: 46000, sample_loss: 0.00026596608222462237, Avg. Loss: 0.0017350214836165186\n",
      "Epoch: 4, Iteration: 47000, sample_loss: 0.0003406378091312945, Avg. Loss: 0.0017368881313710365\n",
      "Epoch: 4, Iteration: 48000, sample_loss: 0.0007082654046826065, Avg. Loss: 0.0017408535411162667\n",
      "Epoch: 4, Iteration: 49000, sample_loss: 2.972043330373708e-05, Avg. Loss: 0.0017371713988367714\n",
      "Epoch: 4, Iteration: 50000, sample_loss: 0.031884752213954926, Avg. Loss: 0.0017405480843344517\n",
      "Epoch: 4, Iteration: 51000, sample_loss: 0.00023732916451990604, Avg. Loss: 0.0017483511833641682\n",
      "Epoch: 4, Iteration: 52000, sample_loss: 0.000993745168671012, Avg. Loss: 0.0017413645100924399\n",
      "Epoch: 4, Iteration: 53000, sample_loss: 0.00041739485459402204, Avg. Loss: 0.0017408497115309997\n",
      "Epoch: 4, Iteration: 54000, sample_loss: 0.00015263547538779676, Avg. Loss: 0.0017429229166582582\n",
      "Epoch: 4, Iteration: 55000, sample_loss: 0.0002873124903999269, Avg. Loss: 0.001740105148682042\n",
      "Epoch: 4, Iteration: 56000, sample_loss: 4.615863144863397e-05, Avg. Loss: 0.0017440807310005\n",
      "Epoch: 4, Iteration: 57000, sample_loss: 0.00026606846950016916, Avg. Loss: 0.0017430180682175133\n",
      "Epoch: 4, Iteration: 58000, sample_loss: 0.00032776655280031264, Avg. Loss: 0.0017437956920589247\n",
      "Epoch: 4, Iteration: 59000, sample_loss: 0.0002132691297447309, Avg. Loss: 0.0017461881585708516\n",
      "Epoch: 4, Iteration: 60000, sample_loss: 0.000246717274421826, Avg. Loss: 0.0017486120516716668\n",
      "Epoch: 4, Iteration: 61000, sample_loss: 0.000373414863133803, Avg. Loss: 0.0017476192686310841\n",
      "Average training loss in episode 4: 0.0017487802817776142\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/srn2vec/\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

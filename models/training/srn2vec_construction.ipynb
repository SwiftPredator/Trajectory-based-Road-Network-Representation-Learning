{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SRN2VecModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"hanover\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRN2VecModel(None, device, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27039/27039 [05:20<00:00, 84.46it/s] \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.generate_data(n_shortest_paths=100, number_negative=3, window_size=900, save_batch_size=100, city=city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f model.extract_pairs model.generate_train_pairs(network, paths, 900, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"srn2vec-traindata-{city}.json\", \"r\") as fp:\n",
    "    a = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build and train model\n",
    "\"\"\"\n",
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRN2VecModel(None, device, network, remove_highway_label=True)\n",
    "model.load_dataset(f\"./srn2vec-traindata-{city}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, sample_loss: 0.70181804895401, Avg. Loss: 0.70181804895401\n",
      "Epoch: 0, Iteration: 1000, sample_loss: 0.42624327540397644, Avg. Loss: 0.5330494427002155\n",
      "Epoch: 0, Iteration: 2000, sample_loss: 0.3482593595981598, Avg. Loss: 0.4579063818372529\n",
      "Epoch: 0, Iteration: 3000, sample_loss: 0.3280641436576843, Avg. Loss: 0.41688991114819934\n",
      "Epoch: 0, Iteration: 4000, sample_loss: 0.3461648225784302, Avg. Loss: 0.39428554661152987\n",
      "Epoch: 0, Iteration: 5000, sample_loss: 0.2526435852050781, Avg. Loss: 0.3799369432608668\n",
      "Epoch: 0, Iteration: 6000, sample_loss: 0.34531858563423157, Avg. Loss: 0.3704917191306942\n",
      "Epoch: 0, Iteration: 7000, sample_loss: 0.3511354923248291, Avg. Loss: 0.36375156377846984\n",
      "Epoch: 0, Iteration: 8000, sample_loss: 0.31269240379333496, Avg. Loss: 0.35869034763284513\n",
      "Epoch: 0, Iteration: 9000, sample_loss: 0.3508126139640808, Avg. Loss: 0.3545463475359505\n",
      "Epoch: 0, Iteration: 10000, sample_loss: 0.3209928870201111, Avg. Loss: 0.3514116883751703\n",
      "Epoch: 0, Iteration: 11000, sample_loss: 0.30628055334091187, Avg. Loss: 0.3487075151811783\n",
      "Epoch: 0, Iteration: 12000, sample_loss: 0.27705118060112, Avg. Loss: 0.3464492339708837\n",
      "Epoch: 0, Iteration: 13000, sample_loss: 0.32550176978111267, Avg. Loss: 0.3444067864094906\n",
      "Epoch: 0, Iteration: 14000, sample_loss: 0.2876157760620117, Avg. Loss: 0.3426650182827142\n",
      "Epoch: 0, Iteration: 15000, sample_loss: 0.32322371006011963, Avg. Loss: 0.3411879669260275\n",
      "Epoch: 0, Iteration: 16000, sample_loss: 0.30680081248283386, Avg. Loss: 0.3397557609312669\n",
      "Epoch: 0, Iteration: 17000, sample_loss: 0.2465316355228424, Avg. Loss: 0.33825991880114686\n",
      "Epoch: 0, Iteration: 18000, sample_loss: 0.2975774109363556, Avg. Loss: 0.3366405023860505\n",
      "Epoch: 0, Iteration: 19000, sample_loss: 0.2918989956378937, Avg. Loss: 0.3349264293201697\n",
      "Epoch: 0, Iteration: 20000, sample_loss: 0.2788715958595276, Avg. Loss: 0.3330542644550369\n",
      "Epoch: 0, Iteration: 21000, sample_loss: 0.24502292275428772, Avg. Loss: 0.33080606383145705\n",
      "Epoch: 0, Iteration: 22000, sample_loss: 0.2735508978366852, Avg. Loss: 0.3281172717725909\n",
      "Epoch: 0, Iteration: 23000, sample_loss: 0.3064647614955902, Avg. Loss: 0.3248935082851143\n",
      "Epoch: 0, Iteration: 24000, sample_loss: 0.2759685814380646, Avg. Loss: 0.3210137027353551\n",
      "Epoch: 0, Iteration: 25000, sample_loss: 0.17699910700321198, Avg. Loss: 0.31642709431628085\n",
      "Epoch: 0, Iteration: 26000, sample_loss: 0.20126982033252716, Avg. Loss: 0.3111841642004055\n",
      "Epoch: 0, Iteration: 27000, sample_loss: 0.0830342173576355, Avg. Loss: 0.30521730502440236\n",
      "Epoch: 0, Iteration: 28000, sample_loss: 0.10519662499427795, Avg. Loss: 0.2987952499385434\n",
      "Epoch: 0, Iteration: 29000, sample_loss: 0.08738569915294647, Avg. Loss: 0.29193880030513014\n",
      "Epoch: 0, Iteration: 30000, sample_loss: 0.04473038762807846, Avg. Loss: 0.2849577550111454\n",
      "Epoch: 0, Iteration: 31000, sample_loss: 0.042389772832393646, Avg. Loss: 0.27793722949754573\n",
      "Epoch: 0, Iteration: 32000, sample_loss: 0.03527861833572388, Avg. Loss: 0.27104050942766567\n",
      "Epoch: 0, Iteration: 33000, sample_loss: 0.03852217271924019, Avg. Loss: 0.2642613274051582\n",
      "Epoch: 0, Iteration: 34000, sample_loss: 0.01461875531822443, Avg. Loss: 0.2576657343083188\n",
      "Epoch: 0, Iteration: 35000, sample_loss: 0.010402210056781769, Avg. Loss: 0.25123375440521417\n",
      "Epoch: 0, Iteration: 36000, sample_loss: 0.0031539835035800934, Avg. Loss: 0.24499362732321878\n",
      "Epoch: 0, Iteration: 37000, sample_loss: 0.011580918915569782, Avg. Loss: 0.23897691254676517\n",
      "Epoch: 0, Iteration: 38000, sample_loss: 0.006706984713673592, Avg. Loss: 0.23318249554952714\n",
      "Epoch: 0, Iteration: 39000, sample_loss: 0.02439435012638569, Avg. Loss: 0.22762792134217022\n",
      "Epoch: 0, Iteration: 40000, sample_loss: 0.018179360777139664, Avg. Loss: 0.22229400544672104\n",
      "Epoch: 0, Iteration: 41000, sample_loss: 0.019703799858689308, Avg. Loss: 0.21717220833196324\n",
      "Epoch: 0, Iteration: 42000, sample_loss: 0.0015684720128774643, Avg. Loss: 0.21224383151073947\n",
      "Epoch: 0, Iteration: 43000, sample_loss: 0.0021905400790274143, Avg. Loss: 0.20751398420236203\n",
      "Epoch: 0, Iteration: 44000, sample_loss: 0.03911183029413223, Avg. Loss: 0.20299029749098155\n",
      "Epoch: 0, Iteration: 45000, sample_loss: 0.002632835879921913, Avg. Loss: 0.19863352699007988\n",
      "Epoch: 0, Iteration: 46000, sample_loss: 0.02689049392938614, Avg. Loss: 0.19446286323188577\n",
      "Average training loss in episode 0: 0.19198272484485143\n",
      "Epoch: 1, Iteration: 0, sample_loss: 0.0013895073207095265, Avg. Loss: 0.0013895073207095265\n",
      "Epoch: 1, Iteration: 1000, sample_loss: 0.0006539601017720997, Avg. Loss: 0.005021668488612644\n",
      "Epoch: 1, Iteration: 2000, sample_loss: 0.0007998414803296328, Avg. Loss: 0.004797847357128623\n",
      "Epoch: 1, Iteration: 3000, sample_loss: 0.0005318125477060676, Avg. Loss: 0.0045399673842910025\n",
      "Epoch: 1, Iteration: 4000, sample_loss: 0.00035634415689855814, Avg. Loss: 0.004499612258070958\n",
      "Epoch: 1, Iteration: 5000, sample_loss: 0.0006737705552950501, Avg. Loss: 0.004345133980641556\n",
      "Epoch: 1, Iteration: 6000, sample_loss: 0.00039220700273290277, Avg. Loss: 0.004267219310262301\n",
      "Epoch: 1, Iteration: 7000, sample_loss: 0.0008834156906232238, Avg. Loss: 0.004113632150587109\n",
      "Epoch: 1, Iteration: 8000, sample_loss: 0.039831191301345825, Avg. Loss: 0.003955421498413414\n",
      "Epoch: 1, Iteration: 9000, sample_loss: 0.0004032040014863014, Avg. Loss: 0.0038594033471057608\n",
      "Epoch: 1, Iteration: 10000, sample_loss: 0.0006212926236912608, Avg. Loss: 0.0037424097879304344\n",
      "Epoch: 1, Iteration: 11000, sample_loss: 0.0006273642648011446, Avg. Loss: 0.0036832161771732804\n",
      "Epoch: 1, Iteration: 12000, sample_loss: 0.0005742717767134309, Avg. Loss: 0.0036321789743160157\n",
      "Epoch: 1, Iteration: 13000, sample_loss: 0.0005744678783230484, Avg. Loss: 0.0035564239382677915\n",
      "Epoch: 1, Iteration: 14000, sample_loss: 0.0004035518504679203, Avg. Loss: 0.0035170780715320397\n",
      "Epoch: 1, Iteration: 15000, sample_loss: 0.00015351113688666373, Avg. Loss: 0.0034778390651173667\n",
      "Epoch: 1, Iteration: 16000, sample_loss: 0.00047664568410255015, Avg. Loss: 0.0034485776265096527\n",
      "Epoch: 1, Iteration: 17000, sample_loss: 0.00038585843867622316, Avg. Loss: 0.003422890268402587\n",
      "Epoch: 1, Iteration: 18000, sample_loss: 0.0017315061995759606, Avg. Loss: 0.003407280438799234\n",
      "Epoch: 1, Iteration: 19000, sample_loss: 0.0006592234713025391, Avg. Loss: 0.003378355828328494\n",
      "Epoch: 1, Iteration: 20000, sample_loss: 0.00018704187823459506, Avg. Loss: 0.00334241224626996\n",
      "Epoch: 1, Iteration: 21000, sample_loss: 0.00036464486038312316, Avg. Loss: 0.0033452127323606216\n",
      "Epoch: 1, Iteration: 22000, sample_loss: 0.0005528646870516241, Avg. Loss: 0.0033225175245152187\n",
      "Epoch: 1, Iteration: 23000, sample_loss: 0.0003469594812486321, Avg. Loss: 0.003305141008087885\n",
      "Epoch: 1, Iteration: 24000, sample_loss: 0.00039112946251407266, Avg. Loss: 0.003273105510811544\n",
      "Epoch: 1, Iteration: 25000, sample_loss: 0.00020047856378369033, Avg. Loss: 0.003261594158789133\n",
      "Epoch: 1, Iteration: 26000, sample_loss: 0.0004049077397212386, Avg. Loss: 0.0032441410687146484\n",
      "Epoch: 1, Iteration: 27000, sample_loss: 0.032454997301101685, Avg. Loss: 0.0032343899334474277\n",
      "Epoch: 1, Iteration: 28000, sample_loss: 0.00018809144967235625, Avg. Loss: 0.0032038001771781156\n",
      "Epoch: 1, Iteration: 29000, sample_loss: 0.00027085686451755464, Avg. Loss: 0.0031905718955866913\n",
      "Epoch: 1, Iteration: 30000, sample_loss: 0.0002465355210006237, Avg. Loss: 0.003167769677584795\n",
      "Epoch: 1, Iteration: 31000, sample_loss: 0.0007631467888131738, Avg. Loss: 0.0031547297137014567\n",
      "Epoch: 1, Iteration: 32000, sample_loss: 0.00034670328022912145, Avg. Loss: 0.003135941284273426\n",
      "Epoch: 1, Iteration: 33000, sample_loss: 0.025763243436813354, Avg. Loss: 0.003134419769033963\n",
      "Epoch: 1, Iteration: 34000, sample_loss: 0.00033105621696449816, Avg. Loss: 0.003114674205507615\n",
      "Epoch: 1, Iteration: 35000, sample_loss: 0.0005200545419938862, Avg. Loss: 0.0031034448627290856\n",
      "Epoch: 1, Iteration: 36000, sample_loss: 0.00025814224500209093, Avg. Loss: 0.00308115404195996\n",
      "Epoch: 1, Iteration: 37000, sample_loss: 0.00017557921819388866, Avg. Loss: 0.0030707384232589205\n",
      "Epoch: 1, Iteration: 38000, sample_loss: 0.0003490257076919079, Avg. Loss: 0.003060519796740818\n",
      "Epoch: 1, Iteration: 39000, sample_loss: 0.0003551400441210717, Avg. Loss: 0.003052113413296674\n",
      "Epoch: 1, Iteration: 40000, sample_loss: 0.00022297623218037188, Avg. Loss: 0.003040228255794174\n",
      "Epoch: 1, Iteration: 41000, sample_loss: 0.00026254038675688207, Avg. Loss: 0.003036528885499899\n",
      "Epoch: 1, Iteration: 42000, sample_loss: 0.00037799490382894874, Avg. Loss: 0.00302156416752716\n",
      "Epoch: 1, Iteration: 43000, sample_loss: 0.00014522126002702862, Avg. Loss: 0.0030035134429315575\n",
      "Epoch: 1, Iteration: 44000, sample_loss: 0.00039871668559499085, Avg. Loss: 0.0029889851674302663\n",
      "Epoch: 1, Iteration: 45000, sample_loss: 0.00038880290230736136, Avg. Loss: 0.0029861431163037484\n",
      "Epoch: 1, Iteration: 46000, sample_loss: 0.0006504027405753732, Avg. Loss: 0.0029847000067840766\n",
      "Average training loss in episode 1: 0.0029802344026594305\n",
      "Epoch: 2, Iteration: 0, sample_loss: 0.0003006310435011983, Avg. Loss: 0.0003006310435011983\n",
      "Epoch: 2, Iteration: 1000, sample_loss: 0.0005329094710759819, Avg. Loss: 0.0022235424489177253\n",
      "Epoch: 2, Iteration: 2000, sample_loss: 0.0003841314755845815, Avg. Loss: 0.0021636364593881\n",
      "Epoch: 2, Iteration: 3000, sample_loss: 0.0005254138959571719, Avg. Loss: 0.0021099878869135476\n",
      "Epoch: 2, Iteration: 4000, sample_loss: 0.00037084531504660845, Avg. Loss: 0.002210466218006899\n",
      "Epoch: 2, Iteration: 5000, sample_loss: 0.00016290108032990247, Avg. Loss: 0.0022616810540448127\n",
      "Epoch: 2, Iteration: 6000, sample_loss: 0.00019733476801775396, Avg. Loss: 0.002249683689124896\n",
      "Epoch: 2, Iteration: 7000, sample_loss: 0.0001945274561876431, Avg. Loss: 0.002295658125107372\n",
      "Epoch: 2, Iteration: 8000, sample_loss: 0.00013777759158983827, Avg. Loss: 0.0022664760441706857\n",
      "Epoch: 2, Iteration: 9000, sample_loss: 0.00015353932394646108, Avg. Loss: 0.0022492853176096813\n",
      "Epoch: 2, Iteration: 10000, sample_loss: 0.00029837823240086436, Avg. Loss: 0.002217966529849438\n",
      "Epoch: 2, Iteration: 11000, sample_loss: 0.0003762632259167731, Avg. Loss: 0.0022169332489960923\n",
      "Epoch: 2, Iteration: 12000, sample_loss: 0.0005481414264068007, Avg. Loss: 0.002259525892430248\n",
      "Epoch: 2, Iteration: 13000, sample_loss: 0.00034624585532583296, Avg. Loss: 0.002261005089834674\n",
      "Epoch: 2, Iteration: 14000, sample_loss: 0.00042410031892359257, Avg. Loss: 0.0022598126370561244\n",
      "Epoch: 2, Iteration: 15000, sample_loss: 0.0006075244164094329, Avg. Loss: 0.0022981982905587815\n",
      "Epoch: 2, Iteration: 16000, sample_loss: 0.0002468294114805758, Avg. Loss: 0.002326260762613985\n",
      "Epoch: 2, Iteration: 17000, sample_loss: 0.0003149912226945162, Avg. Loss: 0.0023445845553387752\n",
      "Epoch: 2, Iteration: 18000, sample_loss: 0.0001496250624768436, Avg. Loss: 0.00235189321429423\n",
      "Epoch: 2, Iteration: 19000, sample_loss: 0.0003508883237373084, Avg. Loss: 0.0023779600197998776\n",
      "Epoch: 2, Iteration: 20000, sample_loss: 0.0002761250361800194, Avg. Loss: 0.0023833509641429306\n",
      "Epoch: 2, Iteration: 21000, sample_loss: 0.0007748520001769066, Avg. Loss: 0.0023635431872125953\n",
      "Epoch: 2, Iteration: 22000, sample_loss: 0.014027064666152, Avg. Loss: 0.002369238798024054\n",
      "Epoch: 2, Iteration: 23000, sample_loss: 0.01957053877413273, Avg. Loss: 0.0023726160135843326\n",
      "Epoch: 2, Iteration: 24000, sample_loss: 0.0007249517366290092, Avg. Loss: 0.0023854377191694478\n",
      "Epoch: 2, Iteration: 25000, sample_loss: 0.000522403628565371, Avg. Loss: 0.0023795421989523846\n",
      "Epoch: 2, Iteration: 26000, sample_loss: 0.0004283493908587843, Avg. Loss: 0.00237424965022051\n",
      "Epoch: 2, Iteration: 27000, sample_loss: 0.03180130571126938, Avg. Loss: 0.0023772245336849793\n",
      "Epoch: 2, Iteration: 28000, sample_loss: 0.00013882614439353347, Avg. Loss: 0.0023726931069778705\n",
      "Epoch: 2, Iteration: 29000, sample_loss: 0.00044415457523427904, Avg. Loss: 0.002387029989076685\n",
      "Epoch: 2, Iteration: 30000, sample_loss: 0.00027991621755063534, Avg. Loss: 0.002391842897951631\n",
      "Epoch: 2, Iteration: 31000, sample_loss: 0.0008669570088386536, Avg. Loss: 0.0023928852355033156\n",
      "Epoch: 2, Iteration: 32000, sample_loss: 0.0005263308994472027, Avg. Loss: 0.0023983510391271065\n",
      "Epoch: 2, Iteration: 33000, sample_loss: 0.0003161258064210415, Avg. Loss: 0.002403022827237048\n",
      "Epoch: 2, Iteration: 34000, sample_loss: 0.0005144424503669143, Avg. Loss: 0.002404776076960233\n",
      "Epoch: 2, Iteration: 35000, sample_loss: 0.0002652866824064404, Avg. Loss: 0.002417941362051485\n",
      "Epoch: 2, Iteration: 36000, sample_loss: 0.016434451565146446, Avg. Loss: 0.002419895145350026\n",
      "Epoch: 2, Iteration: 37000, sample_loss: 0.000666401581838727, Avg. Loss: 0.0024330520733353415\n",
      "Epoch: 2, Iteration: 38000, sample_loss: 0.00020708410011138767, Avg. Loss: 0.0024385151051426633\n",
      "Epoch: 2, Iteration: 39000, sample_loss: 0.00018174700380768627, Avg. Loss: 0.0024432341855914544\n",
      "Epoch: 2, Iteration: 40000, sample_loss: 0.00048457543016411364, Avg. Loss: 0.0024344875391784397\n",
      "Epoch: 2, Iteration: 41000, sample_loss: 0.00027800636598840356, Avg. Loss: 0.002432545338661574\n",
      "Epoch: 2, Iteration: 42000, sample_loss: 0.0002485309378243983, Avg. Loss: 0.0024257162501679767\n",
      "Epoch: 2, Iteration: 43000, sample_loss: 0.0003797097597271204, Avg. Loss: 0.0024191170997384112\n",
      "Epoch: 2, Iteration: 44000, sample_loss: 0.0010606433497741818, Avg. Loss: 0.002429605416108273\n",
      "Epoch: 2, Iteration: 45000, sample_loss: 0.0002635231940075755, Avg. Loss: 0.002423405061491537\n",
      "Epoch: 2, Iteration: 46000, sample_loss: 0.0003413189551793039, Avg. Loss: 0.002422788933114221\n",
      "Average training loss in episode 2: 0.0024192869297584856\n",
      "Epoch: 3, Iteration: 0, sample_loss: 0.00011825748515548185, Avg. Loss: 0.00011825748515548185\n",
      "Epoch: 3, Iteration: 1000, sample_loss: 0.0002691508852876723, Avg. Loss: 0.0020252950612434555\n",
      "Epoch: 3, Iteration: 2000, sample_loss: 0.00017619434220250696, Avg. Loss: 0.0020925076045903296\n",
      "Epoch: 3, Iteration: 3000, sample_loss: 0.00027088267961516976, Avg. Loss: 0.0021664407448643438\n",
      "Epoch: 3, Iteration: 4000, sample_loss: 0.0003169349511153996, Avg. Loss: 0.0021726980163792506\n",
      "Epoch: 3, Iteration: 5000, sample_loss: 0.00023267223150469363, Avg. Loss: 0.0021012319469456415\n",
      "Epoch: 3, Iteration: 6000, sample_loss: 0.00043471890967339277, Avg. Loss: 0.0021229487004442928\n",
      "Epoch: 3, Iteration: 7000, sample_loss: 0.0005632801912724972, Avg. Loss: 0.0021880200421964865\n",
      "Epoch: 3, Iteration: 8000, sample_loss: 0.00033737701596692204, Avg. Loss: 0.002171504257582799\n",
      "Epoch: 3, Iteration: 9000, sample_loss: 0.0005679639289155602, Avg. Loss: 0.0021939929189593735\n",
      "Epoch: 3, Iteration: 10000, sample_loss: 0.00018421513959765434, Avg. Loss: 0.0021708895828623123\n",
      "Epoch: 3, Iteration: 11000, sample_loss: 0.0006272740429267287, Avg. Loss: 0.0021548969799400266\n",
      "Epoch: 3, Iteration: 12000, sample_loss: 0.0003791715716943145, Avg. Loss: 0.0021405661060247137\n",
      "Epoch: 3, Iteration: 13000, sample_loss: 0.00015541102038696408, Avg. Loss: 0.0021413127408636836\n",
      "Epoch: 3, Iteration: 14000, sample_loss: 0.00027826399309560657, Avg. Loss: 0.0021646308685144\n",
      "Epoch: 3, Iteration: 15000, sample_loss: 0.00017343269428238273, Avg. Loss: 0.0021750380640884444\n",
      "Epoch: 3, Iteration: 16000, sample_loss: 0.0009669695282354951, Avg. Loss: 0.0021866140840125564\n",
      "Epoch: 3, Iteration: 17000, sample_loss: 0.0005537784891203046, Avg. Loss: 0.002173812600804805\n",
      "Epoch: 3, Iteration: 18000, sample_loss: 0.0007881733472459018, Avg. Loss: 0.0021889817136946173\n",
      "Epoch: 3, Iteration: 19000, sample_loss: 0.00039213630952872336, Avg. Loss: 0.0021862522064667648\n",
      "Epoch: 3, Iteration: 20000, sample_loss: 0.0002675472351256758, Avg. Loss: 0.002178738670773673\n",
      "Epoch: 3, Iteration: 21000, sample_loss: 0.00015906168846413493, Avg. Loss: 0.0021915607575865603\n",
      "Epoch: 3, Iteration: 22000, sample_loss: 0.0012464969186112285, Avg. Loss: 0.002189404861911929\n",
      "Epoch: 3, Iteration: 23000, sample_loss: 0.00019164380501024425, Avg. Loss: 0.002220072598413403\n",
      "Epoch: 3, Iteration: 24000, sample_loss: 0.00084645114839077, Avg. Loss: 0.0022238940742541676\n",
      "Epoch: 3, Iteration: 25000, sample_loss: 0.0006375520024448633, Avg. Loss: 0.0022453544522594627\n",
      "Epoch: 3, Iteration: 26000, sample_loss: 0.000318670179694891, Avg. Loss: 0.002249266000898809\n",
      "Epoch: 3, Iteration: 27000, sample_loss: 0.0008066256996244192, Avg. Loss: 0.0022721340982264685\n",
      "Epoch: 3, Iteration: 28000, sample_loss: 0.0009100715396925807, Avg. Loss: 0.0022856436887504733\n",
      "Epoch: 3, Iteration: 29000, sample_loss: 0.00024133843544404954, Avg. Loss: 0.002285440497707462\n",
      "Epoch: 3, Iteration: 30000, sample_loss: 0.0008287150412797928, Avg. Loss: 0.00229599443873962\n",
      "Epoch: 3, Iteration: 31000, sample_loss: 0.0004275754326954484, Avg. Loss: 0.0022936434986493464\n",
      "Epoch: 3, Iteration: 32000, sample_loss: 0.00017022409883793443, Avg. Loss: 0.002302565126014492\n",
      "Epoch: 3, Iteration: 33000, sample_loss: 0.00045976927503943443, Avg. Loss: 0.0023061722367341054\n",
      "Epoch: 3, Iteration: 34000, sample_loss: 7.655135414097458e-05, Avg. Loss: 0.0023011138983448968\n",
      "Epoch: 3, Iteration: 35000, sample_loss: 0.00033843691926449537, Avg. Loss: 0.0022990643398143316\n",
      "Epoch: 3, Iteration: 36000, sample_loss: 0.0018050873186439276, Avg. Loss: 0.0023151347775090337\n",
      "Epoch: 3, Iteration: 37000, sample_loss: 0.0005228351801633835, Avg. Loss: 0.002317132985820191\n",
      "Epoch: 3, Iteration: 38000, sample_loss: 0.00033455080119892955, Avg. Loss: 0.002316792632346244\n",
      "Epoch: 3, Iteration: 39000, sample_loss: 0.00013381097232922912, Avg. Loss: 0.002307774981107659\n",
      "Epoch: 3, Iteration: 40000, sample_loss: 0.0005999210407026112, Avg. Loss: 0.002315089603457037\n",
      "Epoch: 3, Iteration: 41000, sample_loss: 0.00014693754201289266, Avg. Loss: 0.002313869994808413\n",
      "Epoch: 3, Iteration: 42000, sample_loss: 0.00015191701822914183, Avg. Loss: 0.0023080549301229217\n",
      "Epoch: 3, Iteration: 43000, sample_loss: 0.0003434684476815164, Avg. Loss: 0.002315895830175366\n",
      "Epoch: 3, Iteration: 44000, sample_loss: 0.00019155371410306543, Avg. Loss: 0.002325008196014795\n",
      "Epoch: 3, Iteration: 45000, sample_loss: 0.00021922198357060552, Avg. Loss: 0.002325525871569931\n",
      "Epoch: 3, Iteration: 46000, sample_loss: 0.00017744080105330795, Avg. Loss: 0.002329549842427434\n",
      "Average training loss in episode 3: 0.002339434373010893\n",
      "Epoch: 4, Iteration: 0, sample_loss: 0.00011462942347861826, Avg. Loss: 0.00011462942347861826\n",
      "Epoch: 4, Iteration: 1000, sample_loss: 0.00046162406215444207, Avg. Loss: 0.0024108304171129823\n",
      "Epoch: 4, Iteration: 2000, sample_loss: 0.00018964069022331387, Avg. Loss: 0.0023581882450580786\n",
      "Epoch: 4, Iteration: 3000, sample_loss: 0.0003270466404501349, Avg. Loss: 0.00219044899503203\n",
      "Epoch: 4, Iteration: 4000, sample_loss: 0.0008182043093256652, Avg. Loss: 0.00215576221816773\n",
      "Epoch: 4, Iteration: 5000, sample_loss: 0.00020347660756669939, Avg. Loss: 0.0021110392530809888\n",
      "Epoch: 4, Iteration: 6000, sample_loss: 0.0005050243344157934, Avg. Loss: 0.0021267046468989503\n",
      "Epoch: 4, Iteration: 7000, sample_loss: 0.00043589866254478693, Avg. Loss: 0.0021333356960058533\n",
      "Epoch: 4, Iteration: 8000, sample_loss: 0.0005180404987186193, Avg. Loss: 0.0021351317202268974\n",
      "Epoch: 4, Iteration: 9000, sample_loss: 0.00042285225936211646, Avg. Loss: 0.002140657307792632\n",
      "Epoch: 4, Iteration: 10000, sample_loss: 0.009043836034834385, Avg. Loss: 0.002143174753906144\n",
      "Epoch: 4, Iteration: 11000, sample_loss: 0.00048814353067427874, Avg. Loss: 0.0021947607009468167\n",
      "Epoch: 4, Iteration: 12000, sample_loss: 5.689311365131289e-05, Avg. Loss: 0.002163426452675552\n",
      "Epoch: 4, Iteration: 13000, sample_loss: 0.0001437612227164209, Avg. Loss: 0.002172590291927612\n",
      "Epoch: 4, Iteration: 14000, sample_loss: 0.00012918314314447343, Avg. Loss: 0.0021688629077511175\n",
      "Epoch: 4, Iteration: 15000, sample_loss: 0.00024364973069168627, Avg. Loss: 0.0021711921467484907\n",
      "Epoch: 4, Iteration: 16000, sample_loss: 0.0003488074289634824, Avg. Loss: 0.002181722132763892\n",
      "Epoch: 4, Iteration: 17000, sample_loss: 0.0001273138914257288, Avg. Loss: 0.0021667226278893163\n",
      "Epoch: 4, Iteration: 18000, sample_loss: 0.015790607780218124, Avg. Loss: 0.002183420514424752\n",
      "Epoch: 4, Iteration: 19000, sample_loss: 0.02177472598850727, Avg. Loss: 0.002178425766405761\n",
      "Epoch: 4, Iteration: 20000, sample_loss: 0.02955787442624569, Avg. Loss: 0.0021743522865785066\n",
      "Epoch: 4, Iteration: 21000, sample_loss: 0.0003880928852595389, Avg. Loss: 0.0021905862193820967\n",
      "Epoch: 4, Iteration: 22000, sample_loss: 0.00018568641098681837, Avg. Loss: 0.0021977803865404523\n",
      "Epoch: 4, Iteration: 23000, sample_loss: 0.00027197078452445567, Avg. Loss: 0.002209240108971111\n",
      "Epoch: 4, Iteration: 24000, sample_loss: 0.00014035540516488254, Avg. Loss: 0.0022039172838895604\n",
      "Epoch: 4, Iteration: 25000, sample_loss: 0.0002586824120953679, Avg. Loss: 0.002209353160079504\n",
      "Epoch: 4, Iteration: 26000, sample_loss: 0.00030602948390878737, Avg. Loss: 0.0022102389999903937\n",
      "Epoch: 4, Iteration: 27000, sample_loss: 0.000305460998788476, Avg. Loss: 0.0022204279772706607\n",
      "Epoch: 4, Iteration: 28000, sample_loss: 0.00019912354764528573, Avg. Loss: 0.0022217434241758247\n",
      "Epoch: 4, Iteration: 29000, sample_loss: 0.0011083537247031927, Avg. Loss: 0.0022294094306539096\n",
      "Epoch: 4, Iteration: 30000, sample_loss: 9.932492685038596e-05, Avg. Loss: 0.0022330526626186844\n",
      "Epoch: 4, Iteration: 31000, sample_loss: 0.0002939192345365882, Avg. Loss: 0.0022311564513033746\n",
      "Epoch: 4, Iteration: 32000, sample_loss: 0.00029065817943774164, Avg. Loss: 0.002222178579447328\n",
      "Epoch: 4, Iteration: 33000, sample_loss: 0.00023151520872488618, Avg. Loss: 0.002220634893251946\n",
      "Epoch: 4, Iteration: 34000, sample_loss: 0.0007278452976606786, Avg. Loss: 0.0022209793497906787\n",
      "Epoch: 4, Iteration: 35000, sample_loss: 0.000880806939676404, Avg. Loss: 0.0022369729045641938\n",
      "Epoch: 4, Iteration: 36000, sample_loss: 0.00012008090561721474, Avg. Loss: 0.0022374370902594628\n",
      "Epoch: 4, Iteration: 37000, sample_loss: 0.000245830015046522, Avg. Loss: 0.0022533128328335187\n",
      "Epoch: 4, Iteration: 38000, sample_loss: 0.0002681060286704451, Avg. Loss: 0.0022509587081450014\n",
      "Epoch: 4, Iteration: 39000, sample_loss: 0.00048178108409047127, Avg. Loss: 0.002259506509464835\n",
      "Epoch: 4, Iteration: 40000, sample_loss: 0.00030446951859630644, Avg. Loss: 0.002260123806112664\n",
      "Epoch: 4, Iteration: 41000, sample_loss: 0.00039579515578225255, Avg. Loss: 0.0022612019320739827\n",
      "Epoch: 4, Iteration: 42000, sample_loss: 0.017885848879814148, Avg. Loss: 0.0022632963107978342\n",
      "Epoch: 4, Iteration: 43000, sample_loss: 0.016719473525881767, Avg. Loss: 0.002271704706981198\n",
      "Epoch: 4, Iteration: 44000, sample_loss: 0.0002880029787775129, Avg. Loss: 0.0022796956193533485\n",
      "Epoch: 4, Iteration: 45000, sample_loss: 0.00021631913841702044, Avg. Loss: 0.0022824403122043003\n",
      "Epoch: 4, Iteration: 46000, sample_loss: 0.026409674435853958, Avg. Loss: 0.0022852772885125607\n",
      "Average training loss in episode 4: 0.0022930947790152736\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/srn2vec/\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import TemporalGraphTrainer, GTCModel, Traj2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              timestamp  start_stamp  \\\n",
      "3809     0    3   33   38   48   49   53   63   65  ...   1574703171   \n",
      "\n",
      "       end_stamp                                           POLYLINE    id  \n",
      "3809  1574706343  LINESTRING (9.695580489293073 52.3383265887556...  3810  \n",
      "--------\n",
      "     id                   seg_seq  travel_time\n",
      "0  3810  [1575, 7994, 6088, 1283]           12\n"
     ]
    }
   ],
   "source": [
    "unmapped_traj = pd.read_csv(\"../../../datasets/trajectories/hanover/mapped_id_poly_clipped.csv\", \";\")\n",
    "print(unmapped_traj[unmapped_traj[\"id\"]==3810])\n",
    "print(\"--------\")\n",
    "print(traj[traj[\"id\"]==3810])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b08c325868649f49a0c9328fd6bd45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/57996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333fe70b06a04dc284f7ec9059e4f877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/57996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c3f31cc94d428a8e4fe30e6a018d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/57996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      id                                              opath  \\\n",
      "0              59    3810   [1575, 1575, 1575, 6088, 1283, 1283, 1283, 1283]   \n",
      "1             226    1872  [4688, 4688, 6882, 6882, 6882, 6882, 6882, 688...   \n",
      "2             267    3814  [866, 7513, 7513, 7513, 1418, 7776, 8081, 8081...   \n",
      "3             304    1873  [5570, 5570, 7648, 8276, 1353, 1353, 1353, 135...   \n",
      "4             312    1874  [940, 940, 2507, 4699, 6642, 6233, 6233, 227, ...   \n",
      "...           ...     ...                                                ...   \n",
      "57991     2494344  143847  [6432, 6432, 6432, 6432, 6432, 6432, 6432, 643...   \n",
      "57992     2494390  143848  [5195, 5195, 829, 829, 831, 2599, 2599, 2599, ...   \n",
      "57993     2494640  143856  [5905, 5905, 5905, 3178, 3178, 3178, 864, 866,...   \n",
      "57994     2494653  143858  [7010, 7010, 7009, 7009, 7009, 3546, 2864, 780...   \n",
      "57995     2494681  143859  [1146, 1146, 1146, 1146, 1146, 1146, 1146, 114...   \n",
      "\n",
      "                                                  spdist  \\\n",
      "0      0.000388055,0.000257745,0.000561118,0.00046345...   \n",
      "1      0.000911354,0.000955415,0.00056174,0.000469219...   \n",
      "2      0.00441927,9.99345e-05,0.000933509,0.00272656,...   \n",
      "3      0.000611351,0.00100386,0.00164302,0.00145073,0...   \n",
      "4      0.00161065,0.00211556,0.00238259,0.00490686,0....   \n",
      "...                                                  ...   \n",
      "57991  0,0.000276009,0.000983052,0.000861888,0.000784...   \n",
      "57992  0.000108344,0.00234129,0.00116728,0.00489653,0...   \n",
      "57993  0,0,0.000164757,7.02566e-05,0.000470956,0.0003...   \n",
      "57994  1.3122e-07,0.000191215,0.000457459,0.000222733...   \n",
      "57995  0,0,0,0,0,0,0.000210984,0.0021198,6.64816e-05,...   \n",
      "\n",
      "                                                   pgeom  \\\n",
      "0      LINESTRING(9.6956028481 52.3383023826,9.695317...   \n",
      "1      LINESTRING(9.63002577495 52.4212081598,9.62911...   \n",
      "2      LINESTRING(9.72750167075 52.3669981882,9.73135...   \n",
      "3      LINESTRING(9.6300123399 52.4212255596,9.630526...   \n",
      "4      LINESTRING(9.76247293044 52.3700582896,9.76361...   \n",
      "...                                                  ...   \n",
      "57991  LINESTRING(9.7192556 52.4459265,9.7192556 52.4...   \n",
      "57992  LINESTRING(9.70941530768 52.4412607767,9.70930...   \n",
      "57993  LINESTRING(9.7265262 52.3659705,9.7265262 52.3...   \n",
      "57994  LINESTRING(9.73904352287 52.3825075306,9.73904...   \n",
      "57995  LINESTRING(9.7836567 52.4008738,9.7836567 52.4...   \n",
      "\n",
      "                                                   cpath  \\\n",
      "0                               [1575, 7994, 6088, 1283]   \n",
      "1                               [4688, 6882, 8047, 5570]   \n",
      "2      [866, 4966, 7512, 7513, 5241, 8096, 1415, 1418...   \n",
      "3      [5570, 2771, 7648, 4720, 8276, 1353, 1354, 474...   \n",
      "4      [940, 1543, 1546, 2507, 8368, 4699, 4700, 6642...   \n",
      "...                                                  ...   \n",
      "57991               [6432, 6433, 4750, 4751, 5194, 5195]   \n",
      "57992                  [5195, 6774, 829, 831, 2599, 832]   \n",
      "57993  [5905, 3178, 864, 866, 4966, 7512, 7514, 4102,...   \n",
      "57994  [7010, 7009, 3546, 2864, 7808, 7809, 4256, 425...   \n",
      "57995  [1146, 1147, 5912, 1348, 1351, 7396, 4737, 474...   \n",
      "\n",
      "                                                   mgeom  \\\n",
      "0      LINESTRING(9.6956028481 52.3383023826,9.695007...   \n",
      "1      LINESTRING(9.63002577495 52.4212081598,9.62947...   \n",
      "2      LINESTRING(9.72750167075 52.3669981882,9.72797...   \n",
      "3      LINESTRING(9.6300123399 52.4212255596,9.630393...   \n",
      "4      LINESTRING(9.76247293044 52.3700582896,9.76249...   \n",
      "...                                                  ...   \n",
      "57991  LINESTRING(9.7192556 52.4459265,9.7192322 52.4...   \n",
      "57992  LINESTRING(9.70941530768 52.4412607767,9.70895...   \n",
      "57993  LINESTRING(9.7265262 52.3659705,9.7266076 52.3...   \n",
      "57994  LINESTRING(9.73904352287 52.3825075306,9.73903...   \n",
      "57995  LINESTRING(9.7836567 52.4008738,9.7831467 52.4...   \n",
      "\n",
      "                               duration  \\\n",
      "0                               5,3,2,2   \n",
      "1                                 15,30   \n",
      "2                              15,15,15   \n",
      "3                                 15,30   \n",
      "4            15,14,31,30,15,14,16,14,15   \n",
      "...                                 ...   \n",
      "57991         5,5,5,5,5,10,5,5,10,5,5,5   \n",
      "57992         5,5,5,5,5,10,5,5,10,5,5,5   \n",
      "57993                     5,5,3,6,1,5,5   \n",
      "57994                    10,5,5,10,5,10   \n",
      "57995  60,15,17,13,15,15,15,15,15,15,15   \n",
      "\n",
      "                                                   speed  speed_mean  \n",
      "0      [7.76110359154e-05, 8.59150556766e-05, 0.00028...    0.000169  \n",
      "1                  [6.0756949851e-05, 3.18471622339e-05]    0.000046  \n",
      "2      [0.000294617793478, 6.66230010839e-06, 6.22339...    0.000121  \n",
      "3                 [4.07567095563e-05, 3.34618819608e-05]    0.000037  \n",
      "4      [0.000107376539031, 0.000151111743942, 7.68577...    0.000107  \n",
      "...                                                  ...         ...  \n",
      "57991  [0.0, 5.52017820134e-05, 0.000196610343167, 0....    0.000139  \n",
      "57992  [2.16687839242e-05, 0.000468258915828, 0.00023...    0.000232  \n",
      "57993  [0.0, 0.0, 5.49189475223e-05, 1.17094290272e-0...    0.000110  \n",
      "57994  [1.31220309967e-08, 3.82430634142e-05, 9.14917...    0.000042  \n",
      "57995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.40655887335e-...    0.000027  \n",
      "\n",
      "[57996 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46ff182516e404a9361f8726f377707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/57996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb67f002e9a445cc8106f086098746c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/57996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b64fc07d044e289dd6139ca90e61c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate traj-adj matrix for gtc\n",
    "# 1. Load required data\n",
    "traj = Trajectory(\"../../../datasets/trajectories/hanover/temporal/road_segment_map_final.csv\", nrows=100000000).generate_TTE_datatset()\n",
    "traj[\"seg_seq\"] = traj[\"seg_seq\"].map(np.array)\n",
    "network = RoadNetwork()\n",
    "network.load_hanover_temporal(path=\"../../../datasets/trajectories/hanover/temporal/hannover_streetgraph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57996/57996 [00:26<00:00, 2162.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# precalc adj matrices\n",
    "adj = GTCModel.generate_node_traj_adj(network=network, traj_data=traj, k=1, bidirectional=False, add_self_loops=False)\n",
    "np.savetxt(\"./traj_adj_k_1_for_temporal_tsd.gz\", X=adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8620, 8620)\n",
      "Epoch: 1, avg_loss: 8.289206834400401\n",
      "Epoch: 2, avg_loss: 5.029554535360897\n",
      "Epoch: 3, avg_loss: 3.7701260535156025\n",
      "Epoch: 4, avg_loss: 3.081674549947767\n",
      "Epoch: 5, avg_loss: 2.6459378025111033\n",
      "Epoch: 6, avg_loss: 2.3453161246051977\n",
      "Epoch: 7, avg_loss: 2.12550759115139\n",
      "Epoch: 8, avg_loss: 1.9578257440863287\n",
      "Epoch: 9, avg_loss: 1.8257293034028383\n",
      "Epoch: 10, avg_loss: 1.718999320268631\n",
      "Epoch: 11, avg_loss: 1.6309666211273581\n",
      "Epoch: 12, avg_loss: 1.5571258721836643\n",
      "Epoch: 13, avg_loss: 1.4943010152330227\n",
      "Epoch: 14, avg_loss: 1.4402011797583405\n",
      "Epoch: 15, avg_loss: 1.3931278799678768\n",
      "Epoch: 16, avg_loss: 1.3517971623908074\n",
      "Epoch: 17, avg_loss: 1.3152203686200215\n",
      "Epoch: 18, avg_loss: 1.2826225056367764\n",
      "Epoch: 19, avg_loss: 1.2533872964396935\n",
      "Epoch: 20, avg_loss: 1.227023006975651\n",
      "Epoch: 21, avg_loss: 1.203123044608688\n",
      "Epoch: 22, avg_loss: 1.1813626874258176\n",
      "Epoch: 23, avg_loss: 1.1614641379517365\n",
      "Epoch: 24, avg_loss: 1.1431990923250426\n",
      "Epoch: 25, avg_loss: 1.1263754868507387\n",
      "Epoch: 26, avg_loss: 1.1108280884531831\n",
      "Epoch: 27, avg_loss: 1.0964190545684633\n",
      "Epoch: 28, avg_loss: 1.0830255957523816\n",
      "Epoch: 29, avg_loss: 1.0705451395279497\n"
     ]
    }
   ],
   "source": [
    "# Pretrain tsd model \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "adj_t2v = np.loadtxt(\"./traj_adj_k_1_for_temporal_tsd.gz\")\n",
    "print(adj_t2v.shape)\n",
    "data = network.generate_road_segment_pyg_dataset(only_edge_index=True)\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj=adj_t2v,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj2vec.save_model(path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gtc adj\n",
    "adj = np.loadtxt(\"./traj_adj_k_2_bi_temporal.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8620, 8620)\n"
     ]
    }
   ],
   "source": [
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load tsd pre emb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mgenerate_road_segment_pyg_dataset(only_edge_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tsd \u001b[39m=\u001b[39m Traj2VecModel(data, network, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tsd\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mmodel_tsd.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m tsd_emb \u001b[39m=\u001b[39m tsd\u001b[39m.\u001b[39mload_emb()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# load tsd pre emb\n",
    "data = network.generate_road_segment_pyg_dataset(only_edge_index=True)\n",
    "tsd = Traj2VecModel(data, network, device=device)\n",
    "tsd.load_model(\"model_tsd.pt\")\n",
    "tsd_emb = tsd.load_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 8620, 4)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# load train data\n",
    "data = torch.load(\"../../../datasets/trajectories/hanover/temporal/temporal_data.pt\")\n",
    "data = torch.swapaxes(data, 0, 1)\n",
    "data = data.numpy()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_index = network.generate_road_segment_pyg_dataset(only_edge_index=True).edge_index\n",
    "# initialize model\n",
    "model = TemporalGraphTrainer(data=data, adj=adj, edge_index=edge_index, struc_emb=None, device=device, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 133, in forward\n    recon = self.decoder(z, X.shape[1])\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 155, in forward\n    x, _ = self._tdecoder(z)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 942, in forward\n    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\nRuntimeError: CUDA out of memory. Tried to allocate 910.00 MiB (GPU 0; 10.92 GiB total capacity; 2.87 GiB already allocated; 334.44 MiB free; 2.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py:92\u001b[0m, in \u001b[0;36mTemporalGraphTrainer.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     struc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_struc_emb)\n\u001b[1;32m     91\u001b[0m     X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((X, struc\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m z, seq_recon \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X)\n\u001b[1;32m     93\u001b[0m z \u001b[39m=\u001b[39m (z\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     95\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[39m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         output\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m     87\u001b[0m     outputs\u001b[39m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 133, in forward\n    recon = self.decoder(z, X.shape[1])\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 155, in forward\n    x, _ = self._tdecoder(z)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 942, in forward\n    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\nRuntimeError: CUDA out of memory. Tried to allocate 910.00 MiB (GPU 0; 10.92 GiB total capacity; 2.87 GiB already allocated; 334.44 MiB free; 2.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), os.path.join(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 8620, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8620, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sequence encoding \n",
    "z, _ = model.model(torch.Tensor(data[:12]).unsqueeze(0))\n",
    "z = z.squeeze()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6420217717818654\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z.detach().cpu().numpy()] # gtc.load_emb(), gae_emb, rand_emb\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on traveltime task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.tasks.destination import DP_Dataset\n",
    "from evaluation.tasks.next_location import NL_Dataset\n",
    "from evaluation.tasks.travel_time import TTE_Dataset\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "train, test = model_selection.train_test_split(\n",
    "            traj_test, test_size=0.2, random_state=69\n",
    "        )\n",
    "train_loader = DataLoader(\n",
    "    NL_Dataset(train, network),\n",
    "    collate_fn=NL_Dataset.collate_fn_padd,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_loader = DataLoader(\n",
    "    NL_Dataset(test, network),\n",
    "    collate_fn=NL_Dataset.collate_fn_padd,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Init \n",
    "class Test(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_dim: int,\n",
    "        device,\n",
    "        plugin: nn.Module=None, \n",
    "        emb_dim: int = 128,\n",
    "        hidden_units: int = 256,\n",
    "        layers: int = 2,\n",
    "        batch_size: int = 128,\n",
    "    ):\n",
    "        super(Test, self).__init__()\n",
    "        self.encoder = nn.LSTM(\n",
    "            emb_dim, hidden_units, num_layers=layers, batch_first=True, dropout=0.5\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_units, hidden_units * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units * 2, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, out_dim),\n",
    "        )\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        self.device = device\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.plugin = plugin\n",
    "        self.encoder.to(device)\n",
    "        self.decoder.to(device)\n",
    "\n",
    "    def forward(self, x, lengths, neigh_masks, mode):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # encode static embedding\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)\n",
    "\n",
    "        x, _ = self.encoder(x)\n",
    "\n",
    "        x, plengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            x, batch_first=True, padding_value=0\n",
    "        )\n",
    "        x = x.contiguous()  # batch x seq x hidden\n",
    "        # x = x.view(-1, x.shape[2])\n",
    "        x = torch.stack(\n",
    "            [x[b, plengths[b] - 1] for b in range(batch_size)]\n",
    "        )  # get last valid item per batch batch x hidden\n",
    "        \n",
    "        if self.plugin is not None:\n",
    "            x = self.plugin(x)\n",
    "\n",
    "        yh = self.decoder(x)\n",
    "        if mode == \"train\":\n",
    "            yh = self.masked_out(yh, neigh_masks)\n",
    "\n",
    "        return yh  # (batch x len(possible nodes))\n",
    "    \n",
    "    def predict(self, loader, emb_stat_full):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            yhs, ys = [], []\n",
    "            for X, y, neigh_masks, lengths, mask, map in loader:\n",
    "                # get static\n",
    "                emb_static = self.get_embedding(emb_stat_full, X.clone(), mask, map)\n",
    "                emb_static = emb_static.to(self.device)\n",
    "                # get dynamic \n",
    "                if self.plugin is not None:\n",
    "                    self.plugin.register_id_seq(X, mask, map, lengths)\n",
    "\n",
    "                mask = mask.to(self.device)\n",
    "    \n",
    "                y = y.to(self.device)\n",
    "                yh = self.soft(self.forward(emb_static, lengths.cpu().detach(), neigh_masks, \"test\")).argmax(dim=1)\n",
    "                yhs.extend(yh.tolist())\n",
    "                ys.extend(y.tolist())\n",
    "\n",
    "            return np.array(yhs), np.array(ys)\n",
    "\n",
    "    def train_model(self, loader, emb_stat_full, epochs=100):\n",
    "        self.train()\n",
    "        for e in tqdm(range(epochs)):\n",
    "            total_loss = 0\n",
    "            for X, y, neigh_masks, lengths, mask, map in tqdm(loader, leave=False):\n",
    "                # get static\n",
    "                emb_static = self.get_embedding(emb_stat_full, X.clone(), mask, map)\n",
    "                emb_static = emb_static.to(self.device)\n",
    "                # get dynamic \n",
    "                if self.plugin is not None:\n",
    "                    self.plugin.register_id_seq(X, mask, map, lengths)\n",
    "                mask = mask.to(device)\n",
    "                # emb_batch = emb.activ1(emb.fc(traj_h))\n",
    "\n",
    "                    # print(emb_batch.shape)\n",
    "                y = y.to(self.device)\n",
    "                yh = self.forward(emb_static, lengths.cpu().detach(), neigh_masks, \"train\")\n",
    "\n",
    "                loss = self.loss(yh.squeeze(), y)\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f\"Average training loss in episode {e}: {total_loss/len(loader)}\")\n",
    "\n",
    "    def get_embedding(self, emb, batch, mask, map):\n",
    "        \"\"\"\n",
    "        Transform batch_size, seq_length, 1 to batch_size, seq_length, emb_size\n",
    "        \"\"\"\n",
    "        res = torch.zeros((batch.shape[0], batch.shape[1], emb.shape[1]))\n",
    "        for i, seq in enumerate(batch):\n",
    "            emb_ids = itemgetter(*seq[mask[i]].tolist())(map)\n",
    "            res[i, mask[i], :] = torch.Tensor(emb[emb_ids, :]).float()\n",
    "\n",
    "        return res\n",
    "\n",
    "    def masked_out(self, x, idxs):\n",
    "        mask = torch.ones_like(x)\n",
    "        for row, idx in zip(mask, idxs):\n",
    "            row[idx] = 0\n",
    "        x = x + (mask + 1e-44).log()\n",
    "        # divider = torch.sum(torch.exp(x) * mask, axis=1).reshape(-1, 1)\n",
    "\n",
    "        return x  # torch.log(torch.div(torch.exp(x) * mask, divider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Test(\n",
    "            out_dim=len(\n",
    "                network.line_graph.nodes\n",
    "            ),\n",
    "            plugin=plugin,\n",
    "            device=device,\n",
    "            emb_dim=model.model.transformer.embed.tok_embed.weight.shape[1],\n",
    "            batch_size=128,\n",
    "        )\n",
    "\n",
    "task.train_model(loader=train_loader, emb_stat_full=model.load_emb(), epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

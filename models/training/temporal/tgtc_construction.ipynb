{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import TemporalGraphTrainer, GTCModel, Traj2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e91e4b515a49dcba075da986c28dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7911dfd4c54dac8c31af0a8fb3956b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25be46b5926e4abbb3a34179c2beb3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854ebdd857c8468d8d99bfdc56891b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f28d055f25424ba7ff27d0247b8b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/61717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c9da9700074758a9eddbc4c06c18ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/8620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load required data\n",
    "unmapped_traj = pd.read_csv(\"../../../datasets/trajectories/hanover/temporal/mapped_id_poly_clipped.csv\", \";\")\n",
    "traj = Trajectory(\"../../../datasets/trajectories/hanover/temporal/road_segment_map_final.csv\", nrows=100000000).generate_TTE_datatset()\n",
    "traj[\"seg_seq\"] = traj[\"seg_seq\"].map(np.array)\n",
    "traj = traj.join(unmapped_traj[[\"start_stamp\", \"end_stamp\", \"id\"]].set_index(\"id\"), on=\"id\", how=\"left\")\n",
    "network = RoadNetwork()\n",
    "network.load_hanover_temporal(path=\"../../../datasets/trajectories/hanover/temporal/hannover_streetgraph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = network.subsample_graph(ratio=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium Heat Map\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from collections import defaultdict\n",
    "import branca.colormap\n",
    "\n",
    "m = folium.Map(location=[52.37052, 9.73322],\n",
    "                    zoom_start = 8)\n",
    "\n",
    "sub_df[\"coords\"] = sub_df[\"geometry\"].swifter.apply(lambda x: list(x.coords))\n",
    "coords = sub_df.loc[:, \"coords\"].values\n",
    "\n",
    "for line in coords:\n",
    "    data = [(c[1], c[0]) for c in line]\n",
    "    folium.PolyLine(data, color=\"red\", weight=2.5, opacity=0.8).add_to(m)\n",
    "\n",
    "# coords = gdf[\"coords\"].values\n",
    "# for line in coords:\n",
    "#     data = [(c[1], c[0]) for c in line]\n",
    "#     folium.PolyLine(data, color=\"green\", weight=2.5, opacity=0.8).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "#map_porto.save(\"heatmap_gps_points_porto.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seg_seq</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>start_stamp</th>\n",
       "      <th>end_stamp</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>end_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[8539, 7659, 6474, 8423, 3849, 7554, 975, 976,...</td>\n",
       "      <td>120</td>\n",
       "      <td>2019-11-25 22:18:49</td>\n",
       "      <td>2019-11-26 01:00:46</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66668</td>\n",
       "      <td>[7808, 7809, 4257, 4721, 7376, 7390, 8100, 797...</td>\n",
       "      <td>285</td>\n",
       "      <td>2019-11-03 16:18:34</td>\n",
       "      <td>2019-11-03 17:28:51</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66669</td>\n",
       "      <td>[1205, 896, 894, 3833, 4613, 416, 1285, 2818, ...</td>\n",
       "      <td>285</td>\n",
       "      <td>2019-11-03 16:18:34</td>\n",
       "      <td>2019-11-03 17:28:51</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66670</td>\n",
       "      <td>[1537, 1538, 4709, 5167, 6960, 7749]</td>\n",
       "      <td>142</td>\n",
       "      <td>2019-11-03 16:18:34</td>\n",
       "      <td>2019-11-03 17:28:51</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[3444, 3445, 1516, 1517, 3470, 3517, 3522, 296...</td>\n",
       "      <td>724</td>\n",
       "      <td>2019-11-15 11:45:02</td>\n",
       "      <td>2019-11-15 13:33:42</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61712</th>\n",
       "      <td>118937</td>\n",
       "      <td>[6183, 3053, 3055, 3479, 4806, 1045, 1047, 366...</td>\n",
       "      <td>197</td>\n",
       "      <td>2019-08-28 06:40:31</td>\n",
       "      <td>2019-08-28 07:21:36</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61713</th>\n",
       "      <td>118943</td>\n",
       "      <td>[89, 90, 7172, 8178, 6721, 3462, 3463, 8047, 5...</td>\n",
       "      <td>75</td>\n",
       "      <td>2019-08-17 08:38:15</td>\n",
       "      <td>2019-08-17 09:22:24</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61714</th>\n",
       "      <td>118945</td>\n",
       "      <td>[2139, 5747, 2836, 2837, 3747, 3748, 7584, 445...</td>\n",
       "      <td>84</td>\n",
       "      <td>2019-08-17 08:38:15</td>\n",
       "      <td>2019-08-17 09:22:24</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61715</th>\n",
       "      <td>118950</td>\n",
       "      <td>[8103, 245, 248, 788, 785, 459, 462, 6515, 518...</td>\n",
       "      <td>479</td>\n",
       "      <td>2019-08-19 15:15:23</td>\n",
       "      <td>2019-08-19 15:57:59</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61716</th>\n",
       "      <td>118951</td>\n",
       "      <td>[2147, 1282, 1280, 1305, 7653, 7526, 1717, 171...</td>\n",
       "      <td>436</td>\n",
       "      <td>2019-08-19 15:15:23</td>\n",
       "      <td>2019-08-19 15:57:59</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61717 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            seg_seq  travel_time  \\\n",
       "0           1  [8539, 7659, 6474, 8423, 3849, 7554, 975, 976,...          120   \n",
       "1       66668  [7808, 7809, 4257, 4721, 7376, 7390, 8100, 797...          285   \n",
       "2       66669  [1205, 896, 894, 3833, 4613, 416, 1285, 2818, ...          285   \n",
       "3       66670               [1537, 1538, 4709, 5167, 6960, 7749]          142   \n",
       "4           3  [3444, 3445, 1516, 1517, 3470, 3517, 3522, 296...          724   \n",
       "...       ...                                                ...          ...   \n",
       "61712  118937  [6183, 3053, 3055, 3479, 4806, 1045, 1047, 366...          197   \n",
       "61713  118943  [89, 90, 7172, 8178, 6721, 3462, 3463, 8047, 5...           75   \n",
       "61714  118945  [2139, 5747, 2836, 2837, 3747, 3748, 7584, 445...           84   \n",
       "61715  118950  [8103, 245, 248, 788, 785, 459, 462, 6515, 518...          479   \n",
       "61716  118951  [2147, 1282, 1280, 1305, 7653, 7526, 1717, 171...          436   \n",
       "\n",
       "              start_stamp           end_stamp  dayofweek  start_hour  end_hour  \n",
       "0     2019-11-25 22:18:49 2019-11-26 01:00:46          0          22         1  \n",
       "1     2019-11-03 16:18:34 2019-11-03 17:28:51          6          16        17  \n",
       "2     2019-11-03 16:18:34 2019-11-03 17:28:51          6          16        17  \n",
       "3     2019-11-03 16:18:34 2019-11-03 17:28:51          6          16        17  \n",
       "4     2019-11-15 11:45:02 2019-11-15 13:33:42          4          11        13  \n",
       "...                   ...                 ...        ...         ...       ...  \n",
       "61712 2019-08-28 06:40:31 2019-08-28 07:21:36          2           6         7  \n",
       "61713 2019-08-17 08:38:15 2019-08-17 09:22:24          5           8         9  \n",
       "61714 2019-08-17 08:38:15 2019-08-17 09:22:24          5           8         9  \n",
       "61715 2019-08-19 15:15:23 2019-08-19 15:57:59          0          15        15  \n",
       "61716 2019-08-19 15:15:23 2019-08-19 15:57:59          0          15        15  \n",
       "\n",
       "[61717 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract relevant time data from time stamp\n",
    "traj[\"start_stamp\"] = pd.to_datetime(traj[\"start_stamp\"], unit=\"s\")\n",
    "traj[\"end_stamp\"] = pd.to_datetime(traj[\"end_stamp\"], unit=\"s\")\n",
    "\n",
    "traj[\"dayofweek\"] = traj[\"start_stamp\"].dt.dayofweek\n",
    "traj[\"start_hour\"] = traj[\"start_stamp\"].dt.hour\n",
    "traj[\"end_hour\"] = traj[\"end_stamp\"].dt.hour\n",
    "\n",
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61717 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8539",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# precalc adj matrices\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m adj \u001b[39m=\u001b[39m GTCModel\u001b[39m.\u001b[39;49mgenerate_node_traj_adj(network\u001b[39m=\u001b[39;49mnetwork, traj_data\u001b[39m=\u001b[39;49mtraj, k\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, bidirectional\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, add_self_loops\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m np\u001b[39m.\u001b[39msavetxt(\u001b[39m\"\u001b[39m\u001b[39m./traj_adj_k_2_bi_temporal_gtc.gz\u001b[39m\u001b[39m\"\u001b[39m, X\u001b[39m=\u001b[39madj)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/gtc.py:120\u001b[0m, in \u001b[0;36mGTCModel.generate_node_traj_adj\u001b[0;34m(traj_data, network, k, bidirectional, add_self_loops)\u001b[0m\n\u001b[1;32m    118\u001b[0m traj_nodes \u001b[39m=\u001b[39m traj[(i \u001b[39m-\u001b[39m left_slice) : (i \u001b[39m+\u001b[39m right_slice)]\n\u001b[1;32m    119\u001b[0m \u001b[39m# convert traj_nodes to graph_nodes\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m target \u001b[39m=\u001b[39m itemgetter(traj_node)(traj_to_node)\n\u001b[1;32m    121\u001b[0m context \u001b[39m=\u001b[39m itemgetter(\u001b[39m*\u001b[39mtraj_nodes)(traj_to_node)\n\u001b[1;32m    122\u001b[0m adj[target, context] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 8539"
     ]
    }
   ],
   "source": [
    "# precalc adj matrices\n",
    "adj = GTCModel.generate_node_traj_adj(network=network, traj_data=traj, k=2, bidirectional=True, add_self_loops=True)\n",
    "np.savetxt(\"./traj_adj_k_2_bi_temporal_gtc.gz\", X=adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8620, 8620)\n",
      "Epoch: 1, avg_loss: 8.289206834400401\n",
      "Epoch: 2, avg_loss: 5.029554535360897\n",
      "Epoch: 3, avg_loss: 3.7701260535156025\n",
      "Epoch: 4, avg_loss: 3.081674549947767\n",
      "Epoch: 5, avg_loss: 2.6459378025111033\n",
      "Epoch: 6, avg_loss: 2.3453161246051977\n",
      "Epoch: 7, avg_loss: 2.12550759115139\n",
      "Epoch: 8, avg_loss: 1.9578257440863287\n",
      "Epoch: 9, avg_loss: 1.8257293034028383\n",
      "Epoch: 10, avg_loss: 1.718999320268631\n",
      "Epoch: 11, avg_loss: 1.6309666211273581\n",
      "Epoch: 12, avg_loss: 1.5571258721836643\n",
      "Epoch: 13, avg_loss: 1.4943010152330227\n",
      "Epoch: 14, avg_loss: 1.4402011797583405\n",
      "Epoch: 15, avg_loss: 1.3931278799678768\n",
      "Epoch: 16, avg_loss: 1.3517971623908074\n",
      "Epoch: 17, avg_loss: 1.3152203686200215\n",
      "Epoch: 18, avg_loss: 1.2826225056367764\n",
      "Epoch: 19, avg_loss: 1.2533872964396935\n",
      "Epoch: 20, avg_loss: 1.227023006975651\n",
      "Epoch: 21, avg_loss: 1.203123044608688\n",
      "Epoch: 22, avg_loss: 1.1813626874258176\n",
      "Epoch: 23, avg_loss: 1.1614641379517365\n",
      "Epoch: 24, avg_loss: 1.1431990923250426\n",
      "Epoch: 25, avg_loss: 1.1263754868507387\n",
      "Epoch: 26, avg_loss: 1.1108280884531831\n",
      "Epoch: 27, avg_loss: 1.0964190545684633\n",
      "Epoch: 28, avg_loss: 1.0830255957523816\n",
      "Epoch: 29, avg_loss: 1.0705451395279497\n"
     ]
    }
   ],
   "source": [
    "# Pretrain tsd model \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "adj_t2v = np.loadtxt(\"./traj_adj_k_1_for_temporal_tsd.gz\")\n",
    "print(adj_t2v.shape)\n",
    "data = network.generate_road_segment_pyg_dataset(only_edge_index=True)\n",
    "traj2vec = Traj2VecModel(\n",
    "            data,\n",
    "            network,\n",
    "            adj=adj_t2v,\n",
    "            device=device,\n",
    "            emb_dim=128,\n",
    "            walk_length=30,\n",
    "            context_size=5,\n",
    "            walks_per_node=25,\n",
    "            num_neg=10,\n",
    "        )\n",
    "traj2vec.train(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj2vec.save_model(path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gtc adj\n",
    "adj = np.loadtxt(\"./traj_adj_k_2_bi_temporal_gtc.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8620, 8620)\n"
     ]
    }
   ],
   "source": [
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load tsd pre emb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mgenerate_road_segment_pyg_dataset(only_edge_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tsd \u001b[39m=\u001b[39m Traj2VecModel(data, network, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tsd\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mmodel_tsd.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m tsd_emb \u001b[39m=\u001b[39m tsd\u001b[39m.\u001b[39mload_emb()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# load tsd pre emb\n",
    "data = network.generate_road_segment_pyg_dataset(only_edge_index=True)\n",
    "tsd = Traj2VecModel(data, network, device=device)\n",
    "tsd.load_model(\"model_tsd.pt\")\n",
    "tsd_emb = tsd.load_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5952, 8620, 4)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# load train data\n",
    "data = torch.load(\"../../../datasets/trajectories/hanover/temporal/temporal_data.pt\")\n",
    "data = torch.swapaxes(data, 0, 1)\n",
    "data = data.numpy()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_index = network.generate_road_segment_pyg_dataset(only_edge_index=True).edge_index\n",
    "# initialize model\n",
    "model = TemporalGraphTrainer(data=data, adj=adj, edge_index=edge_index, struc_emb=None, device=device, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+------------+\n",
      "|                   Modules                   | Parameters |\n",
      "+---------------------------------------------+------------+\n",
      "| module.encoder._encoder.graph_conv1.weights |   33792    |\n",
      "|  module.encoder._encoder.graph_conv1.biases |    256     |\n",
      "| module.encoder._encoder.graph_conv2.weights |   16896    |\n",
      "|  module.encoder._encoder.graph_conv2.biases |    128     |\n",
      "|    module.decoder._tdecoder.weight_ih_l0    |   49152    |\n",
      "|    module.decoder._tdecoder.weight_hh_l0    |   49152    |\n",
      "|     module.decoder._tdecoder.bias_ih_l0     |    384     |\n",
      "|     module.decoder._tdecoder.bias_hh_l0     |    384     |\n",
      "|        module.decoder.dense.0.weight        |    8192    |\n",
      "|         module.decoder.dense.0.bias         |     64     |\n",
      "|        module.decoder.dense.2.weight        |     64     |\n",
      "|         module.decoder.dense.2.bias         |     1      |\n",
      "+---------------------------------------------+------------+\n",
      "Total Trainable Params: 158465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), os.path.join(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 8620, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8620, 128])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sequence encoding \n",
    "# z, _ = model.model(torch.Tensor(data[100:112]).unsqueeze(0))\n",
    "z = z.squeeze()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542513908639789\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z.detach().cpu().numpy()] # gtc.load_emb(), gae_emb, rand_emb\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on traveltime task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "class TemporalDataset(Dataset):\n",
    "    def __init__(self, data, network):\n",
    "        self.X = data[\"seg_seq\"].values\n",
    "        self.y = data[\"travel_time\"].values\n",
    "        self.time = data[[\"dayofweek\", \"start_hour\", \"end_hour\"]].values\n",
    "        self.network = network\n",
    "        self.map = self.create_edge_emb_mapping()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=int), self.y[idx], self.time[idx], self.map\n",
    "\n",
    "    # tested index mapping is correct\n",
    "    def create_edge_emb_mapping(self):\n",
    "        # map from trajectory edge id to embedding id\n",
    "        # edge_ids = np.array(self.network.gdf_edges.index, dtype=\"i,i,i\")\n",
    "        # traj_edge_idx = np.array(self.network.gdf_edges.fid)\n",
    "        # node_ids = np.array(self.network.line_graph.nodes, dtype=\"i,i,i\")\n",
    "        # sort_idx = node_ids.argsort()\n",
    "        # emb_ids = sort_idx[np.searchsorted(node_ids, edge_ids, sorter=sort_idx)]\n",
    "        # map = dict(zip(traj_edge_idx, emb_ids))\n",
    "\n",
    "        map = {}\n",
    "        nodes = list(self.network.line_graph.nodes)\n",
    "        for index, id in zip(self.network.gdf_edges.index, self.network.gdf_edges.fid):\n",
    "            map[id] = nodes.index(index)\n",
    "        # print(map == map2) # yields true\n",
    "\n",
    "        return map\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn_padd(batch):\n",
    "        \"\"\"\n",
    "        Padds batch of variable length\n",
    "        \"\"\"\n",
    "        data, label, time,  map = zip(*batch)\n",
    "        # seq length for each input in batch\n",
    "        lengths_old = torch.tensor([t.shape[0] for t in data])\n",
    "\n",
    "        # sort data for pad packet, since biggest sequence should be first and then descending order\n",
    "        sort_idxs = torch.argsort(lengths_old, descending=True, dim=0)\n",
    "        lengths = lengths_old[sort_idxs]\n",
    "        data = [\n",
    "            x\n",
    "            for _, x in sorted(\n",
    "                zip(lengths_old.tolist(), data), key=lambda pair: pair[0], reverse=True\n",
    "            )\n",
    "        ]\n",
    "        label = [\n",
    "            x\n",
    "            for _, x in sorted(\n",
    "                zip(lengths_old.tolist(), label), key=lambda pair: pair[0], reverse=True\n",
    "            )\n",
    "        ]\n",
    "        time = [\n",
    "            x\n",
    "            for _, x in sorted(\n",
    "                zip(lengths_old.tolist(), time), key=lambda pair: pair[0], reverse=True\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # pad\n",
    "        data = torch.nn.utils.rnn.pad_sequence(data, padding_value=0, batch_first=True)\n",
    "        # compute mask\n",
    "        mask = data != 0\n",
    "\n",
    "        return data, torch.Tensor(label), torch.tensor(time, dtype=int), lengths, mask, map[0]\n",
    "\n",
    "\n",
    "train, test = model_selection.train_test_split(\n",
    "            traj, test_size=0.2, random_state=69\n",
    "        )\n",
    "train_loader = DataLoader(\n",
    "    TemporalDataset(train, network),\n",
    "    collate_fn=TemporalDataset.collate_fn_padd,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "eval_loader = DataLoader(\n",
    "    TemporalDataset(test, network),\n",
    "    collate_fn=TemporalDataset.collate_fn_padd,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Init \n",
    "class TemporalTest(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        emb_dim: int = 128,\n",
    "        hidden_units: int = 128,\n",
    "        layers: int = 2,\n",
    "        batch_size: int = 128,\n",
    "        plugin=None,\n",
    "    ):\n",
    "        super(TemporalTest, self).__init__()\n",
    "        self.encoder = nn.LSTM(\n",
    "            emb_dim, hidden_units, num_layers=layers, batch_first=True, dropout=0.5\n",
    "        )\n",
    "        if plugin is not None:\n",
    "            hidden_units = hidden_units * 2\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_units, hidden_units * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units * 2, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 1),\n",
    "        )\n",
    "        self.hidden_units = hidden_units\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.plugin = plugin\n",
    "\n",
    "        self.encoder.to(device)\n",
    "        self.decoder.to(device)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        self.hidden = self.init_hidden(batch_size=batch_size)\n",
    "\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True)\n",
    "\n",
    "        x, _ = self.encoder(x)\n",
    "\n",
    "        x, plengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            x, batch_first=True, padding_value=0\n",
    "        )\n",
    "        x = x.contiguous()  # batch x seq x hidden\n",
    "        # x = x.view(-1, x.shape[2])\n",
    "        x = torch.stack(\n",
    "            [x[b, plengths[b] - 1] for b in range(batch_size)]\n",
    "        )  # get last valid item per batch batch x hidden\n",
    "\n",
    "        if self.plugin is not None:\n",
    "            x = self.plugin(x)\n",
    "\n",
    "        yh = self.decoder(x)\n",
    "\n",
    "        return yh  # (batch x 1)\n",
    "\n",
    "    def train_model(self, loader, epochs=100):\n",
    "        self.train()\n",
    "        for e in range(epochs):\n",
    "            total_loss = 0\n",
    "            for X, y, time, lengths, mask, map in loader:\n",
    "\n",
    "                emb = self.plugin.generate_emb(time)\n",
    "    \n",
    "                emb_batch = self.get_embedding(emb, X.clone(), mask, map)\n",
    "                emb_batch = emb_batch.to(self.device)\n",
    "\n",
    "                y = y.to(self.device)\n",
    "                yh = self.forward(emb_batch, lengths)\n",
    "                loss = self.loss(yh.squeeze(), y)\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                break\n",
    "            break\n",
    "\n",
    "            # print(f\"Average training loss in episode {e}: {total_loss/len(loader)}\")\n",
    "\n",
    "    def predict(self, loader, emb):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            yhs, ys = [], []\n",
    "            for X, y, lengths, mask, map in loader:\n",
    "                emb_batch = self.get_embedding(emb, X.clone(), mask, map)\n",
    "                emb_batch = emb_batch.to(self.device)\n",
    "\n",
    "                if self.plugin is not None:\n",
    "                    self.plugin.register_id_seq(X, mask, map, lengths)\n",
    "\n",
    "                y = y.to(self.device)\n",
    "                yh = self.forward(emb_batch, lengths)\n",
    "                yhs.extend(yh.tolist())\n",
    "                ys.extend(y.tolist())\n",
    "\n",
    "            return np.array(yhs), np.array(ys)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_a = torch.randn(self.layers, batch_size, self.hidden_units)\n",
    "        hidden_b = torch.randn(self.layers, batch_size, self.hidden_units)\n",
    "\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        hidden_a = hidden_a.to(self.device)\n",
    "        hidden_b = hidden_b.to(self.device)\n",
    "\n",
    "        return (hidden_a, hidden_b)\n",
    "\n",
    "    def get_embedding(self, emb, batch, mask, map):\n",
    "        \"\"\"\n",
    "        Transform batch_size, seq_length, 1 to batch_size, seq_length, emb_size\n",
    "        \"\"\"\n",
    "        res = torch.zeros((batch.shape[0], batch.shape[1], emb.shape[1]))\n",
    "        for i, seq in enumerate(batch):\n",
    "            emb_ids = itemgetter(*seq[mask[i]].tolist())(map)\n",
    "            res[i, mask[i], :] = torch.Tensor(emb[emb_ids, :]).float()\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load temporal sensor data \n",
    "temporal = pd.read_csv(\"../../../datasets/trajectories/hanover/temporal/hannover_traffic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize temporal plugin \n",
    "from evaluation.tasks import TemporalEmbeddingPlugin\n",
    "\n",
    "plugin = TemporalEmbeddingPlugin(model.model, network, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin.load_data(\"plugin_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([672, 8620, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plugin.processed_temp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed \n",
    "torch.save(plugin.processed_temp_data, 'plugin_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_traj = traj.iloc[0, [-1, -2, -3]].values\n",
    "\n",
    "z, _ = plugin.generate_emb(test_traj[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TemporalTest(\n",
    "            plugin=plugin,\n",
    "            device=device,\n",
    "            batch_size=4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 133, in forward\n    recon = self.decoder(z, X.shape[1])\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 155, in forward\n    x, _ = self._tdecoder(z)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 942, in forward\n    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\nRuntimeError: CUDA out of memory. Tried to allocate 6.89 GiB (GPU 0; 10.92 GiB total capacity; 7.93 GiB already allocated; 1.67 GiB free; 8.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m task\u001b[39m.\u001b[39;49mtrain_model(loader\u001b[39m=\u001b[39;49mtrain_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb Cell 29\u001b[0m in \u001b[0;36mTemporalTest.train_model\u001b[0;34m(self, loader, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, y, time, lengths, mask, \u001b[39mmap\u001b[39m \u001b[39min\u001b[39;00m loader:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplugin\u001b[39m.\u001b[39;49mgenerate_emb(time)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m     emb_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_embedding(emb, X\u001b[39m.\u001b[39mclone(), mask, \u001b[39mmap\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/temporal/tgtc_construction.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     emb_batch \u001b[39m=\u001b[39m emb_batch\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/evaluation/tasks/temporal_plugin.py:32\u001b[0m, in \u001b[0;36mTemporalEmbeddingPlugin.generate_emb\u001b[0;34m(self, times)\u001b[0m\n\u001b[1;32m     29\u001b[0m     timeframe_batch[i, :, :, :] \u001b[39m=\u001b[39m timeframe\n\u001b[1;32m     31\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(timeframe_batch\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice))\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[39m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         output\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m     87\u001b[0m     outputs\u001b[39m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/road/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 133, in forward\n    recon = self.decoder(z, X.shape[1])\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/tgtc.py\", line 155, in forward\n    x, _ = self._tdecoder(z)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/pheinemeyer/miniconda3/envs/road/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 942, in forward\n    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\nRuntimeError: CUDA out of memory. Tried to allocate 6.89 GiB (GPU 0; 10.92 GiB total capacity; 7.93 GiB already allocated; 1.67 GiB free; 8.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "task.train_model(loader=train_loader, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import GAEModel, GCNEncoder, GATEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(\"../../osm_data/porto\")\n",
    "# df = pd.read_csv(\"../datasets/trajectories/Porto/road_segment_map_final.csv\", sep=\";\", usecols=[\"id\", \"cpath\"])\n",
    "traj_features = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "traj_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 11331 entries, (25503936, 4722746638, 0) to (9709007543, 415754684, 0)\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         11331 non-null  int64  \n",
      " 1   util       11331 non-null  float64\n",
      " 2   avg_speed  11331 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 662.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(2)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "print(traj_features.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = network.generate_road_segment_pyg_dataset(traj_data=None, include_coords=True, drop_labels=[\"highway_enc\"]) # traj_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11331, 21])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training without features\n",
    "# data.x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11331, 21])\n",
      "Epoch: 500, avg_loss: 0.979432095170021\n",
      "Epoch: 1000, avg_loss: 0.9389632423520088\n",
      "Epoch: 1500, avg_loss: 0.9185743187268575\n",
      "Epoch: 2000, avg_loss: 0.9061920402050019\n",
      "Epoch: 2500, avg_loss: 0.8975091202259063\n",
      "Epoch: 3000, avg_loss: 0.8909486925403277\n",
      "Epoch: 3500, avg_loss: 0.8855186921698707\n",
      "Epoch: 4000, avg_loss: 0.8809734211564064\n",
      "Epoch: 4500, avg_loss: 0.8770406175454457\n",
      "Epoch: 5000, avg_loss: 0.8735740212321281\n",
      "Epoch: 5500, avg_loss: 0.8704851040189916\n",
      "Epoch: 6000, avg_loss: 0.8676321873366832\n",
      "Epoch: 6500, avg_loss: 0.865113131413093\n",
      "Epoch: 7000, avg_loss: 0.8627527216076851\n",
      "Epoch: 7500, avg_loss: 0.8605937406539917\n",
      "Epoch: 8000, avg_loss: 0.8586001276895404\n",
      "Epoch: 8500, avg_loss: 0.8567462715751984\n",
      "Epoch: 9000, avg_loss: 0.8550302124089665\n",
      "Epoch: 9500, avg_loss: 0.8534289087559047\n",
      "Epoch: 10000, avg_loss: 0.8519359570860863\n",
      "Epoch: 10500, avg_loss: 0.850536069205829\n",
      "Epoch: 11000, avg_loss: 0.8492084951129827\n",
      "Epoch: 11500, avg_loss: 0.8479676373523215\n",
      "Epoch: 12000, avg_loss: 0.8467741668373346\n",
      "Epoch: 12500, avg_loss: 0.8456363961982727\n",
      "Epoch: 13000, avg_loss: 0.8445396989171322\n",
      "Epoch: 13500, avg_loss: 0.8435011997531962\n",
      "Epoch: 14000, avg_loss: 0.8425115870492799\n",
      "Epoch: 14500, avg_loss: 0.8415426882053244\n",
      "Epoch: 15000, avg_loss: 0.840623652223746\n",
      "Epoch: 15500, avg_loss: 0.8397408027648926\n",
      "Epoch: 16000, avg_loss: 0.8388798118084669\n",
      "Epoch: 16500, avg_loss: 0.8380670428203814\n",
      "Epoch: 17000, avg_loss: 0.837268919355729\n",
      "Epoch: 17500, avg_loss: 0.8364951528719493\n",
      "Epoch: 18000, avg_loss: 0.8357590570416715\n",
      "Epoch: 18500, avg_loss: 0.8350353677756077\n",
      "Epoch: 19000, avg_loss: 0.8343487399534175\n",
      "Epoch: 19500, avg_loss: 0.8336684591647906\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# create pyg dataset\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    # T.OneHotDegree(128), # training without features\n",
    "    T.ToDevice(device),\n",
    "])\n",
    "data = transform(data)\n",
    "print(data.x.shape)\n",
    "model = GAEModel(data, device=device, encoder=GATEncoder, emb_dim=128)\n",
    "model.train(epochs=20000)\n",
    "# model.save_model(path=\"../model_states/gaegcn/\")\n",
    "# model.save_emb(path=\"../model_states/gaegcn/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.model.encode(data.x, data.edge_index)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gaegat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.load_emb(\"../../model_states/gaegcn/embedding.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = z.detach().cpu().numpy() # embedding for each node\n",
    "# train simple classifier on 80% of data with cross validation\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# mask = ((y==11) | (y==10) | (y==9) | (y==4) | (y==1) | (y==2) | (y==12) | (y==7)) # remove uncommon tags\n",
    "# X = X[~mask, :]\n",
    "# y = y[~mask]\n",
    "# print(np.unique(y, return_counts=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_test dimension= ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "decoder = linear_model.LinearRegression(fit_intercept=True)\n",
    "X = z.detach().cpu().numpy()\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_test dimension= ', y_test.shape)\n",
    "\n",
    "decoder.fit(X_train, y_train)\n",
    "scorer = make_scorer(metrics.mean_absolute_error)\n",
    "print(np.mean(cross_val_score(estimator=decoder, X=X_test, y=y_test, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    "dataset = Planetoid(\".\", \"Cora\", transform=transform)\n",
    "t,v, te = dataset[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import train_test_split_edges\n",
    "device = torch.device('cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=False)\n",
    "])\n",
    "print(data)\n",
    "transform(data)\n",
    "test = train_test_split_edges(data)\n",
    "\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

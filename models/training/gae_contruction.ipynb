{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import GAEModel, GCNEncoder, GATEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"sf\"\n",
    "city_traj = \"SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")\n",
    "# df = pd.read_csv(\"../datasets/trajectories/Porto/road_segment_map_final.csv\", sep=\";\", usecols=[\"id\", \"cpath\"])\n",
    "# traj_features = pd.read_csv(f\"../../datasets/trajectories/{city_traj}/speed_features_unnormalized.csv\")\n",
    "# traj_features.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "# traj_features[\"util\"] = (traj_features[\"util\"] - traj_features[\"util\"].min()) / (traj_features[\"util\"].max() - traj_features[\"util\"].min())  # min max normalization\n",
    "# traj_features[\"avg_speed\"] = (traj_features[\"avg_speed\"] - traj_features[\"avg_speed\"].min()) / (traj_features[\"avg_speed\"].max() - traj_features[\"avg_speed\"].min())  # min max normalization\n",
    "# traj_features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = network.generate_road_segment_pyg_dataset(traj_data=None, include_coords=True, drop_labels=[\"highway_enc\"], dataset=city) # traj_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27039, 33])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training without features\n",
    "# data.x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, avg_loss: 1.2450322754383087\n",
      "Epoch: 1000, avg_loss: 1.2119571328163148\n",
      "Epoch: 1500, avg_loss: 1.1923513511816661\n",
      "Epoch: 2000, avg_loss: 1.1652192149162293\n",
      "Epoch: 2500, avg_loss: 1.1459539885520935\n",
      "Epoch: 3000, avg_loss: 1.131425383925438\n",
      "Epoch: 3500, avg_loss: 1.1190789311953953\n",
      "Epoch: 4000, avg_loss: 1.108261032551527\n",
      "Epoch: 4500, avg_loss: 1.0997302146487766\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# create pyg dataset\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    # T.OneHotDegree(128), # training without features\n",
    "    T.ToDevice(device),\n",
    "])\n",
    "data = transform(data)\n",
    "model = GAEModel(data, device=device, encoder=GATEncoder, emb_dim=128)\n",
    "model.train(epochs=5000)\n",
    "# model.save_model(path=\"../model_states/gaegcn/\")\n",
    "# model.save_emb(path=\"../model_states/gaegcn/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27039, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.model.encode(data.x, data.edge_index)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(path=\"../model_states/gaegat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimension=  (21631, 128)\n",
      "X_test dimension=  (5408, 128)\n",
      "y_train dimension=  (21631,)\n",
      "y_test dimension=  (5408,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = z.detach().cpu().numpy() # embedding for each node\n",
    "# train simple classifier on 80% of data with cross validation\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# mask = ((y==11) | (y==10) | (y==9) | (y==4) | (y==1) | (y==2) | (y==12) | (y==7)) # remove uncommon tags\n",
    "# X = X[~mask, :]\n",
    "# y = y[~mask]\n",
    "# print(np.unique(y, return_counts=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_test dimension= ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.47      0.74      0.58        23\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.49      0.61      0.55       246\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.85      0.88      0.87      3574\n",
      "           7       0.63      0.71      0.67       515\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.68      0.58      0.62       779\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.42      0.28      0.34        53\n",
      "          12       0.00      0.00      0.00        10\n",
      "          13       0.66      0.55      0.60       110\n",
      "\n",
      "    accuracy                           0.78      5408\n",
      "   macro avg       0.30      0.31      0.30      5408\n",
      "weighted avg       0.76      0.78      0.77      5408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "tf = pd.read_csv(\"../../datasets/trajectories/Porto/speed_features_unnormalized.csv\")\n",
    "tf.set_index([\"u\", \"v\", \"key\"], inplace=True)\n",
    "map_id = {j: i for i, j in enumerate(network.line_graph.nodes)}\n",
    "tf[\"idx\"] = tf.index.map(map_id)\n",
    "tf.sort_values(by=\"idx\", axis=0, inplace=True)\n",
    "decoder = linear_model.LinearRegression(fit_intercept=True)\n",
    "X = z.detach().cpu().numpy()\n",
    "y = tf[\"avg_speed\"]\n",
    "y.fillna(0, inplace=True)\n",
    "y = y.round(2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_test dimension= ', y_test.shape)\n",
    "\n",
    "decoder.fit(X_train, y_train)\n",
    "scorer = make_scorer(metrics.mean_absolute_error)\n",
    "print(np.mean(cross_val_score(estimator=decoder, X=X_test, y=y_test, scoring=scorer, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "device = torch.device('cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    "dataset = Planetoid(\".\", \"Cora\", transform=transform)\n",
    "t,v, te = dataset[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import train_test_split_edges\n",
    "device = torch.device('cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      split_labels=True, add_negative_train_samples=False)\n",
    "])\n",
    "print(data)\n",
    "transform(data)\n",
    "test = train_test_split_edges(data)\n",
    "\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from generator import RoadNetwork, Trajectory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from models import CLMModel\n",
    "from models.utils import generate_trajid_to_nodeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"sf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RoadNetwork()\n",
    "network.load(f\"../../osm_data/{city}\")\n",
    "trajectory = pd.read_pickle(\n",
    "    f\"../../datasets/trajectories/{city}/traj_train_test_split/train_69.pkl\"\n",
    ")\n",
    "trajectory[\"seg_seq\"] = trajectory[\"seg_seq\"].map(np.array)\n",
    "data = network.generate_road_segment_pyg_dataset(include_coords=True, dataset=city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1080963/1080963 [16:02<00:00, 1123.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# calculate transition matrix \n",
    "traj_map = generate_trajid_to_nodeid(network)\n",
    "trans_mat = np.zeros((data.x.shape[0], data.x.shape[0]))\n",
    "for seq in tqdm(trajectory.seg_seq):\n",
    "    for i, id1 in enumerate(seq):\n",
    "        for id2 in seq[i:]:\n",
    "            node_id1, node_id2 = traj_map[id1], traj_map[id2]\n",
    "            trans_mat[node_id1, node_id2] += 1\n",
    "\n",
    "trans_mat = trans_mat / (trans_mat.max(axis=1, keepdims=True, initial=0.) + 1e-9)\n",
    "row, col = np.diag_indices_from(trans_mat)\n",
    "trans_mat[row, col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"clm_trans_mat.gz\", X=trans_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat = np.loadtxt(f\"./clm_trans_mat_{city}.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat_b = (trans_mat > 0.6)\n",
    "aug_edges = [(i // trans_mat.shape[0] , i % trans_mat.shape[0]) for i, n in enumerate(trans_mat_b.flatten()) if n]\n",
    "aug_edge_index = torch.tensor(np.array(aug_edges).transpose()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "trajectory.rename({\"seg_seq\": \"path\"}, inplace=True, axis=1)\n",
    "model = CLMModel(data, device, network, trans_adj=aug_edge_index, traj_data=trajectory, batch_size=32, emb_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+------------+\n",
      "|                              Modules                               | Parameters |\n",
      "+--------------------------------------------------------------------+------------+\n",
      "|                       node_embedding.weight                        |   865248   |\n",
      "|                  graph_encoder1.layers.0.att_src                   |    128     |\n",
      "|                  graph_encoder1.layers.0.att_dst                   |    128     |\n",
      "|                    graph_encoder1.layers.0.bias                    |    128     |\n",
      "|               graph_encoder1.layers.0.lin_src.weight               |    4096    |\n",
      "|                  graph_encoder1.layers.1.att_src                   |    128     |\n",
      "|                  graph_encoder1.layers.1.att_dst                   |    128     |\n",
      "|                    graph_encoder1.layers.1.bias                    |    128     |\n",
      "|               graph_encoder1.layers.1.lin_src.weight               |   16384    |\n",
      "|                  graph_encoder2.layers.0.att_src                   |    128     |\n",
      "|                  graph_encoder2.layers.0.att_dst                   |    128     |\n",
      "|                    graph_encoder2.layers.0.bias                    |    128     |\n",
      "|               graph_encoder2.layers.0.lin_src.weight               |    4096    |\n",
      "|                  graph_encoder2.layers.1.att_src                   |    128     |\n",
      "|                  graph_encoder2.layers.1.att_dst                   |    128     |\n",
      "|                    graph_encoder2.layers.1.bias                    |    128     |\n",
      "|               graph_encoder2.layers.1.lin_src.weight               |   16384    |\n",
      "| seq_encoder.transformer_encoder.layers.0.self_attn.in_proj_weight  |   49152    |\n",
      "|  seq_encoder.transformer_encoder.layers.0.self_attn.in_proj_bias   |    384     |\n",
      "| seq_encoder.transformer_encoder.layers.0.self_attn.out_proj.weight |   16384    |\n",
      "|  seq_encoder.transformer_encoder.layers.0.self_attn.out_proj.bias  |    128     |\n",
      "|      seq_encoder.transformer_encoder.layers.0.linear1.weight       |   16384    |\n",
      "|       seq_encoder.transformer_encoder.layers.0.linear1.bias        |    128     |\n",
      "|      seq_encoder.transformer_encoder.layers.0.linear2.weight       |   16384    |\n",
      "|       seq_encoder.transformer_encoder.layers.0.linear2.bias        |    128     |\n",
      "|       seq_encoder.transformer_encoder.layers.0.norm1.weight        |    128     |\n",
      "|        seq_encoder.transformer_encoder.layers.0.norm1.bias         |    128     |\n",
      "|       seq_encoder.transformer_encoder.layers.0.norm2.weight        |    128     |\n",
      "|        seq_encoder.transformer_encoder.layers.0.norm2.bias         |    128     |\n",
      "+--------------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 1007328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1007328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:57<00:00, 4380.92it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.72 GiB (GPU 0; 10.92 GiB total capacity; 8.96 GiB already allocated; 777.44 MiB free; 9.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/clm_training.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpascal02/home/pheinemeyer/Road-Network-Embedding-Generator/models/training/clm_training.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/clm.py:246\u001b[0m, in \u001b[0;36mCLMModel.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    245\u001b[0m node_rep1, node_rep2, seq_rep1, seq_rep2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(data_batch)\n\u001b[0;32m--> 246\u001b[0m loss_ss \u001b[39m=\u001b[39m node_node_loss(node_rep1, node_rep2, \u001b[39m\"\u001b[39;49m\u001b[39mjsd\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    247\u001b[0m loss_tt \u001b[39m=\u001b[39m seq_seq_loss(seq_rep1, seq_rep2, \u001b[39m\"\u001b[39m\u001b[39mjsd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m loss_st1 \u001b[39m=\u001b[39m node_seq_loss(node_rep1, seq_rep2, data_batch, \u001b[39m\"\u001b[39m\u001b[39mjsd\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/clm.py:52\u001b[0m, in \u001b[0;36mnode_node_loss\u001b[0;34m(node_rep1, node_rep2, measure)\u001b[0m\n\u001b[1;32m     49\u001b[0m pos_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meye(num_nodes)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m measure \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjsd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m jsd(node_rep1, node_rep2, pos_mask)\n\u001b[1;32m     53\u001b[0m \u001b[39melif\u001b[39;00m measure \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnce\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m nce(node_rep1, node_rep2, pos_mask)\n",
      "File \u001b[0;32m/dstore/home/pheinemeyer/Road-Network-Embedding-Generator/models/clm.py:23\u001b[0m, in \u001b[0;36mjsd\u001b[0;34m(z1, z2, pos_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m neg_mask \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m pos_mask\n\u001b[1;32m     22\u001b[0m sim_mat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(z1, z2\u001b[39m.\u001b[39mt())\n\u001b[0;32m---> 23\u001b[0m E_pos \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(\u001b[39m2.0\u001b[39m) \u001b[39m-\u001b[39m F\u001b[39m.\u001b[39msoftplus(\u001b[39m-\u001b[39;49msim_mat)\n\u001b[1;32m     24\u001b[0m E_neg \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftplus(\u001b[39m-\u001b[39msim_mat) \u001b[39m+\u001b[39m sim_mat \u001b[39m-\u001b[39m math\u001b[39m.\u001b[39mlog(\u001b[39m2.0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m (E_neg \u001b[39m*\u001b[39m neg_mask)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m neg_mask\u001b[39m.\u001b[39msum() \u001b[39m-\u001b[39m (\n\u001b[1;32m     26\u001b[0m     E_pos \u001b[39m*\u001b[39m pos_mask\n\u001b[1;32m     27\u001b[0m )\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m pos_mask\u001b[39m.\u001b[39msum()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.72 GiB (GPU 0; 10.92 GiB total capacity; 8.96 GiB already allocated; 777.44 MiB free; 9.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model.train(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), os.path.join(\"./clm.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.load_emb().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3283721609008289\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# n2v = models[-1]\n",
    "idxs = np.arange(len(network.line_graph.nodes))\n",
    "train_idx, test_idx = model_selection.train_test_split(idxs, test_size=0.2, random_state=69)\n",
    "y = np.array([network.gdf_edges.loc[n][\"highway_enc\"] for n in network.line_graph.nodes])\n",
    "\n",
    "# for m, e in models:\n",
    "    # m.train(epochs=e)\n",
    "    # zn = m.load_emb()\n",
    "    # zcn = np.concatenate((zn, z2), axis=1)\n",
    "    # zct = np.concatenate((zn, z3), axis=1)\n",
    "    # zcnn = np.concatenate((zn, z4), axis=1)\n",
    "    # zctn = np.concatenate((zn, z5), axis=1)\n",
    "    # X = z # embedding for each node\n",
    "eva = [z] # gtc.load_emb(), gae_emb, rand_emb\n",
    "for X in eva:\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "    lm = linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "    # lm.fit(X_train, y_train)\n",
    "    scorer = make_scorer(metrics.f1_score, average=\"macro\")\n",
    "    print(np.mean(cross_val_score(estimator=lm, X=X, y=y, scoring=scorer, cv=5)))\n",
    "    #print(metrics.classification_report(y_test, lm.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('road')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
